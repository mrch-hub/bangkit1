{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SolarPrediction.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrch-hub/bangkit1/blob/test_neuralnet/SolarPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5bF6G8ff6Zq",
        "colab_type": "text"
      },
      "source": [
        "##Solar radiation intensity prediction using TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6pwJrUZ9rYW",
        "colab_type": "code",
        "outputId": "2d965041-d766-4f7c-a54b-c8d0dcab79f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\"\"\"A python code for predicting solar radiation\n",
        "intensity using TensorFlow. Created for \n",
        "5th Bangk!t assignment.\n",
        "Collaborators: Marcellinus Chrisnada, Muhammad\n",
        "Harits Hafidza, Mochammad Randy Caesario H.\"\"\""
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A python code for predicting solar radiation\\nintensity using TensorFlow. Created for \\n5th Bangk!t assignment.\\nCollaborators: Marcellinus Chrisnada, Muhammad\\nHarits Hafidza, Mochammad Randy Caesario H.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yb2tFywNgWIn",
        "colab_type": "text"
      },
      "source": [
        "##Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8ekWJYDbTzp",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Run on TensorFlow 2.x\n",
        "%tensorflow_version 2.x\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPY5vbLWXmKN",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "3aa840a8-d0f7-4866-80f6-ef6d34a504dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#@title Import relevant modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Adjust the granularity of reporting. \n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "\n",
        "print(\"Imported modules.\")"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imported modules.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRlH8pQwbSpE",
        "colab_type": "code",
        "outputId": "96cff910-59cd-41c4-f1cb-33f5fe76a08d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "#@title Load dataset\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/mrch-hub/bangkit1/master/SolarPrediction.csv')\n",
        "data = data.reindex(np.random.permutation(data.index)) # shuffle dataset\n",
        "data.head(40)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UNIXTime</th>\n",
              "      <th>Data</th>\n",
              "      <th>Time</th>\n",
              "      <th>Radiation</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Pressure</th>\n",
              "      <th>Humidity</th>\n",
              "      <th>WindDirection(Degrees)</th>\n",
              "      <th>Speed</th>\n",
              "      <th>TimeSunRise</th>\n",
              "      <th>TimeSunSet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>31405</th>\n",
              "      <td>1480970737</td>\n",
              "      <td>12/5/2016 12:00:00 AM</td>\n",
              "      <td>10:45:37</td>\n",
              "      <td>84.0</td>\n",
              "      <td>45</td>\n",
              "      <td>30.4</td>\n",
              "      <td>93</td>\n",
              "      <td>308.7</td>\n",
              "      <td>4.5</td>\n",
              "      <td>06:44:00</td>\n",
              "      <td>17:43:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25828</th>\n",
              "      <td>1482871540</td>\n",
              "      <td>12/27/2016 12:00:00 AM</td>\n",
              "      <td>10:45:40</td>\n",
              "      <td>771.5</td>\n",
              "      <td>59</td>\n",
              "      <td>30.5</td>\n",
              "      <td>19</td>\n",
              "      <td>167.2</td>\n",
              "      <td>11.2</td>\n",
              "      <td>06:56:00</td>\n",
              "      <td>17:52:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18113</th>\n",
              "      <td>1479918901</td>\n",
              "      <td>11/23/2016 12:00:00 AM</td>\n",
              "      <td>06:35:01</td>\n",
              "      <td>4.7</td>\n",
              "      <td>42</td>\n",
              "      <td>30.4</td>\n",
              "      <td>94</td>\n",
              "      <td>142.7</td>\n",
              "      <td>10.1</td>\n",
              "      <td>06:36:00</td>\n",
              "      <td>17:42:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1021</th>\n",
              "      <td>1474911621</td>\n",
              "      <td>9/26/2016 12:00:00 AM</td>\n",
              "      <td>07:40:21</td>\n",
              "      <td>169.6</td>\n",
              "      <td>50</td>\n",
              "      <td>30.4</td>\n",
              "      <td>95</td>\n",
              "      <td>172.3</td>\n",
              "      <td>5.6</td>\n",
              "      <td>06:12:00</td>\n",
              "      <td>18:15:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10000</th>\n",
              "      <td>1477216817</td>\n",
              "      <td>10/23/2016 12:00:00 AM</td>\n",
              "      <td>00:00:17</td>\n",
              "      <td>1.2</td>\n",
              "      <td>48</td>\n",
              "      <td>30.4</td>\n",
              "      <td>101</td>\n",
              "      <td>106.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>06:20:00</td>\n",
              "      <td>17:54:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1898</th>\n",
              "      <td>1474645521</td>\n",
              "      <td>9/23/2016 12:00:00 AM</td>\n",
              "      <td>05:45:21</td>\n",
              "      <td>1.3</td>\n",
              "      <td>52</td>\n",
              "      <td>30.4</td>\n",
              "      <td>99</td>\n",
              "      <td>113.4</td>\n",
              "      <td>2.2</td>\n",
              "      <td>06:12:00</td>\n",
              "      <td>18:18:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10523</th>\n",
              "      <td>1477059620</td>\n",
              "      <td>10/21/2016 12:00:00 AM</td>\n",
              "      <td>04:20:20</td>\n",
              "      <td>1.1</td>\n",
              "      <td>46</td>\n",
              "      <td>30.4</td>\n",
              "      <td>101</td>\n",
              "      <td>160.2</td>\n",
              "      <td>9.0</td>\n",
              "      <td>06:19:00</td>\n",
              "      <td>17:55:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21517</th>\n",
              "      <td>1478897102</td>\n",
              "      <td>11/11/2016 12:00:00 AM</td>\n",
              "      <td>10:45:02</td>\n",
              "      <td>826.0</td>\n",
              "      <td>63</td>\n",
              "      <td>30.5</td>\n",
              "      <td>25</td>\n",
              "      <td>21.9</td>\n",
              "      <td>5.6</td>\n",
              "      <td>06:29:00</td>\n",
              "      <td>17:44:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24237</th>\n",
              "      <td>1478079917</td>\n",
              "      <td>11/1/2016 12:00:00 AM</td>\n",
              "      <td>23:45:17</td>\n",
              "      <td>1.2</td>\n",
              "      <td>44</td>\n",
              "      <td>30.5</td>\n",
              "      <td>43</td>\n",
              "      <td>179.6</td>\n",
              "      <td>5.6</td>\n",
              "      <td>06:24:00</td>\n",
              "      <td>17:48:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25529</th>\n",
              "      <td>1482961250</td>\n",
              "      <td>12/28/2016 12:00:00 AM</td>\n",
              "      <td>11:40:50</td>\n",
              "      <td>597.6</td>\n",
              "      <td>52</td>\n",
              "      <td>30.4</td>\n",
              "      <td>93</td>\n",
              "      <td>150.2</td>\n",
              "      <td>9.0</td>\n",
              "      <td>06:56:00</td>\n",
              "      <td>17:52:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         UNIXTime                    Data  ... TimeSunRise  TimeSunSet\n",
              "31405  1480970737   12/5/2016 12:00:00 AM  ...    06:44:00    17:43:00\n",
              "25828  1482871540  12/27/2016 12:00:00 AM  ...    06:56:00    17:52:00\n",
              "18113  1479918901  11/23/2016 12:00:00 AM  ...    06:36:00    17:42:00\n",
              "1021   1474911621   9/26/2016 12:00:00 AM  ...    06:12:00    18:15:00\n",
              "10000  1477216817  10/23/2016 12:00:00 AM  ...    06:20:00    17:54:00\n",
              "...           ...                     ...  ...         ...         ...\n",
              "1898   1474645521   9/23/2016 12:00:00 AM  ...    06:12:00    18:18:00\n",
              "10523  1477059620  10/21/2016 12:00:00 AM  ...    06:19:00    17:55:00\n",
              "21517  1478897102  11/11/2016 12:00:00 AM  ...    06:29:00    17:44:00\n",
              "24237  1478079917   11/1/2016 12:00:00 AM  ...    06:24:00    17:48:00\n",
              "25529  1482961250  12/28/2016 12:00:00 AM  ...    06:56:00    17:52:00\n",
              "\n",
              "[40 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c28PYOGaauV0",
        "colab_type": "text"
      },
      "source": [
        "##Adding some features to the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymGkD9ZPaxro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Adding feature is_daylight that define measurement time is either daylight (1) or nighttime (0)\n",
        "is_daylight = [data['Time'].values[x] > data['TimeSunRise'].values[x] and data['Time'].values[x] < data['TimeSunSet'].values[x] for x in range(len(data))]\n",
        "data['is_daylight'] = is_daylight\n",
        "data['is_daylight'] = data['is_daylight'].astype('float')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCCuKjCwBH1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Convert UNIXTime into hour, day, month format\n",
        "data['Time_Convert'] = pd.to_datetime(data['Time'], format = '%H:%M:%S')\n",
        "\n",
        "data['Hour'] = pd.to_datetime(data['Time_Convert'], format = '%H:%M:%S').dt.hour # Get the hour of the day\n",
        "\n",
        "data['Day'] = pd.to_datetime(data['UNIXTime'].astype(int), unit = 's').dt.day # Get the day of the month\n",
        "\n",
        "data['Month'] = pd.to_datetime(data['UNIXTime'].astype(int), unit = 's').dt.month # Get the month of the year"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQeavaKNayAj",
        "colab_type": "text"
      },
      "source": [
        "##Data Preconditioning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbKi6_Xcbn6M",
        "colab_type": "code",
        "outputId": "74fe3a33-2f20-4dc4-c7a3-15ff08b7c669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "#@title Splitting data to train set and test set\n",
        "test_split = 0.2 # percentage of train set to be considered as test set\n",
        "data_test = data[:][0:round((len(data)*test_split))]\n",
        "data_train = data[:][round((len(data)*test_split)):]\n",
        "print('train set length:', str(len(data_train)), '\\ntest set length:', \n",
        "      str(len(data_test)))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train set length: 26149 \n",
            "test set length: 6537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v5LYeP_dECa",
        "colab_type": "code",
        "outputId": "5a761959-d16a-476e-cd63-722353a92ccb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#@title Normalize values \n",
        "\n",
        "# Calculate the Z-scores of each column in the training set:\n",
        "data_train_mean = data_train.select_dtypes(include=['float64', 'int64']).mean()\n",
        "data_train_std = data_train.select_dtypes(include=['float64', 'int64']).std()\n",
        "data_train_norm = (data_train.select_dtypes(include=['float64', 'int64']) \n",
        "                   - data_train_mean)/data_train_std\n",
        "\n",
        "# Calculate the Z-scores of each column in the test set.\n",
        "data_test_mean = data_test.select_dtypes(include=['float64', 'int64']).mean()\n",
        "data_test_std = data_test.select_dtypes(include=['float64', 'int64']).std()\n",
        "data_test_norm = (data_test.select_dtypes(include=['float64', 'int64'])\n",
        "                  - data_test_mean)/data_test_std\n",
        "\n",
        "print(\"Normalized the values.\")"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normalized the values.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKdhPgg5eRFI",
        "colab_type": "text"
      },
      "source": [
        "## Represent data\n",
        "\n",
        "The following code cell creates a feature layer containing these features:\n",
        "\n",
        "* `Temperature`\n",
        "* `Pressure`\n",
        "* `is_daylight`\n",
        "* `Day`\n",
        "* `Hour`\n",
        "* `Month`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bDp6l3KeEgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create empty feature column list\n",
        "feature_columns = []\n",
        "\n",
        "# Represent Temperature as a floating-point value.\n",
        "temperature = tf.feature_column.numeric_column(\"Temperature\")\n",
        "feature_columns.append(temperature)\n",
        "\n",
        "# Represent Pressure as a floating-point value.\n",
        "pressure = tf.feature_column.numeric_column(\"Pressure\")\n",
        "feature_columns.append(pressure)\n",
        "\n",
        "# Represent Daylight as a floating-point value.\n",
        "daylight = tf.feature_column.numeric_column(\"is_daylight\")\n",
        "feature_columns.append(daylight)\n",
        "\n",
        "# Represent Hour as a floating-point value.\n",
        "day = tf.feature_column.numeric_column(\"Day\")\n",
        "feature_columns.append(day)\n",
        "\n",
        "# Represent Hour as a floating-point value.\n",
        "hour = tf.feature_column.numeric_column(\"Hour\")\n",
        "feature_columns.append(hour)\n",
        "\n",
        "# Represent Hour as a floating-point value.\n",
        "month = tf.feature_column.numeric_column(\"Month\")\n",
        "feature_columns.append(month)\n",
        "\n",
        "# Convert the list of feature columns into a layer that will later be fed into\n",
        "# the model. \n",
        "my_feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMAji1PSfPCt",
        "colab_type": "text"
      },
      "source": [
        "## Build a linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyOjMo-7ei25",
        "colab_type": "code",
        "outputId": "3af3ada1-77b4-44ce-8a82-78317fcb2629",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#@title Define plotting function\n",
        "\n",
        "def plot_the_loss_curve(epochs, mse_training, mse_validation):\n",
        "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Root Mean Squared Error\")\n",
        "\n",
        "  plt.plot(epochs[1:], mse_training[1:], label=\"Training Loss\")\n",
        "  plt.plot(epochs[1:], mse_validation[1:], label=\"Validation Loss\")\n",
        "  plt.legend()\n",
        "\n",
        "  merged_mse_lists = mse_training[1:] + mse_validation[1:]\n",
        "  highest_loss = max(merged_mse_lists)\n",
        "  lowest_loss = min(merged_mse_lists)\n",
        "  delta = highest_loss - lowest_loss\n",
        "  print(delta)\n",
        "\n",
        "  top_of_y_axis = highest_loss + (delta * 0.05)\n",
        "  bottom_of_y_axis = lowest_loss - (delta * 0.05)\n",
        "  plt.ylim([bottom_of_y_axis, top_of_y_axis])\n",
        "  plt.show()  \n",
        "\n",
        "print(\"Defined the plot_the_loss_curve function.\")"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defined the plot_the_loss_curve function.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEsYOPPhetG3",
        "colab_type": "code",
        "outputId": "bc971e9f-b66a-41a7-b426-ebb479e3663f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "cellView": "form"
      },
      "source": [
        "#@title Define functions to create and train a linear regression model\n",
        "def create_model(my_learning_rate, feature_layer):\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
        "  # Most simple tf.keras models are sequential.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # Add the layer containing the feature columns to the model.\n",
        "  model.add(feature_layer)\n",
        "\n",
        "  # Add one linear layer to the model to yield a simple linear regressor.\n",
        "  model.add(tf.keras.layers.Dense(units=1, input_shape=(1,)))\n",
        "\n",
        "  # Construct the layers into a model that TensorFlow can execute.\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  return model           \n",
        "\n",
        "\n",
        "def train_model(model, dataset, epochs, batch_size, label_name,validation_split):\n",
        "  \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
        "\n",
        "  # Split the dataset into features and label.\n",
        "  features = {name:np.array(value) for name, value in dataset.items()}\n",
        "  label = np.array(features.pop(label_name))\n",
        "  history = model.fit(x=features, y=label, batch_size=batch_size,\n",
        "                      epochs=epochs, validation_split=validation_split, \n",
        "                      shuffle=True)\n",
        "\n",
        "  # Get details that will be useful for plotting the loss curve.\n",
        "  epochs = history.epoch\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  rmse = hist[\"root_mean_squared_error\"]\n",
        "\n",
        "  return epochs, rmse, history.history   \n",
        "\n",
        "print(\"Defined the create_model and train_model functions.\")"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defined the create_model and train_model functions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAJuzbBmexB4",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "da99f6c2-a063-4a5f-9352-6a8a47bd9a49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#@title Train the model as linear regression\n",
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.01\n",
        "epochs = 50\n",
        "batch_size = 1000\n",
        "validation_split = 0.2\n",
        "label_name = \"Radiation\"\n",
        " \n",
        "\n",
        "# Establish the model's topography.\n",
        "my_model = create_model(learning_rate, my_feature_layer)\n",
        "\n",
        "# Train the model on the normalized training set.\n",
        "epochs, mse, history = train_model(my_model, data_train_norm, epochs, batch_size, label_name, \n",
        "                          validation_split=validation_split)\n",
        "plot_the_loss_curve(epochs, history[\"root_mean_squared_error\"], \n",
        "                    history[\"val_root_mean_squared_error\"])\n",
        "\n",
        "test_features = {name:np.array(value) for name, value in data_test_norm.items()}\n",
        "test_label = np.array(test_features.pop(label_name)) # isolate the label\n",
        "print(\"\\n Evaluate the linear regression model against the test set:\")\n",
        "my_model.evaluate(x = test_features, y = test_label, batch_size=batch_size)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "WARNING:tensorflow:Layer dense_features_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "21/21 [==============================] - 0s 10ms/step - loss: 2.7451 - root_mean_squared_error: 1.6574 - val_loss: 1.9111 - val_root_mean_squared_error: 1.3790\n",
            "Epoch 2/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 1.5715 - root_mean_squared_error: 1.2541 - val_loss: 1.1328 - val_root_mean_squared_error: 1.0625\n",
            "Epoch 3/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.9240 - root_mean_squared_error: 0.9616 - val_loss: 0.6670 - val_root_mean_squared_error: 0.8152\n",
            "Epoch 4/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.5559 - root_mean_squared_error: 0.7459 - val_loss: 0.4327 - val_root_mean_squared_error: 0.6558\n",
            "Epoch 5/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.3919 - root_mean_squared_error: 0.6261 - val_loss: 0.3559 - val_root_mean_squared_error: 0.5943\n",
            "Epoch 6/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3504 - root_mean_squared_error: 0.5919 - val_loss: 0.3481 - val_root_mean_squared_error: 0.5879\n",
            "Epoch 7/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3451 - root_mean_squared_error: 0.5875 - val_loss: 0.3457 - val_root_mean_squared_error: 0.5863\n",
            "Epoch 8/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.3437 - root_mean_squared_error: 0.5865 - val_loss: 0.3439 - val_root_mean_squared_error: 0.5852\n",
            "Epoch 9/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.3442 - root_mean_squared_error: 0.5867 - val_loss: 0.3436 - val_root_mean_squared_error: 0.5847\n",
            "Epoch 10/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3439 - root_mean_squared_error: 0.5864 - val_loss: 0.3449 - val_root_mean_squared_error: 0.5860\n",
            "Epoch 11/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3444 - root_mean_squared_error: 0.5867 - val_loss: 0.3487 - val_root_mean_squared_error: 0.5888\n",
            "Epoch 12/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.3439 - root_mean_squared_error: 0.5865 - val_loss: 0.3445 - val_root_mean_squared_error: 0.5854\n",
            "Epoch 13/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3441 - root_mean_squared_error: 0.5865 - val_loss: 0.3455 - val_root_mean_squared_error: 0.5864\n",
            "Epoch 14/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3440 - root_mean_squared_error: 0.5867 - val_loss: 0.3449 - val_root_mean_squared_error: 0.5858\n",
            "Epoch 15/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.3439 - root_mean_squared_error: 0.5865 - val_loss: 0.3431 - val_root_mean_squared_error: 0.5845\n",
            "Epoch 16/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.3444 - root_mean_squared_error: 0.5869 - val_loss: 0.3439 - val_root_mean_squared_error: 0.5851\n",
            "Epoch 17/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.3439 - root_mean_squared_error: 0.5865 - val_loss: 0.3463 - val_root_mean_squared_error: 0.5869\n",
            "Epoch 18/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.3441 - root_mean_squared_error: 0.5866 - val_loss: 0.3458 - val_root_mean_squared_error: 0.5866\n",
            "Epoch 19/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3440 - root_mean_squared_error: 0.5864 - val_loss: 0.3442 - val_root_mean_squared_error: 0.5851\n",
            "Epoch 20/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.3441 - root_mean_squared_error: 0.5865 - val_loss: 0.3453 - val_root_mean_squared_error: 0.5861\n",
            "Epoch 21/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.3440 - root_mean_squared_error: 0.5865 - val_loss: 0.3444 - val_root_mean_squared_error: 0.5853\n",
            "Epoch 22/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3437 - root_mean_squared_error: 0.5863 - val_loss: 0.3457 - val_root_mean_squared_error: 0.5865\n",
            "Epoch 23/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3440 - root_mean_squared_error: 0.5864 - val_loss: 0.3455 - val_root_mean_squared_error: 0.5860\n",
            "Epoch 24/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.3442 - root_mean_squared_error: 0.5866 - val_loss: 0.3451 - val_root_mean_squared_error: 0.5860\n",
            "Epoch 25/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3440 - root_mean_squared_error: 0.5865 - val_loss: 0.3473 - val_root_mean_squared_error: 0.5878\n",
            "Epoch 26/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3440 - root_mean_squared_error: 0.5864 - val_loss: 0.3447 - val_root_mean_squared_error: 0.5859\n",
            "Epoch 27/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.3441 - root_mean_squared_error: 0.5866 - val_loss: 0.3434 - val_root_mean_squared_error: 0.5848\n",
            "Epoch 28/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3443 - root_mean_squared_error: 0.5866 - val_loss: 0.3441 - val_root_mean_squared_error: 0.5850\n",
            "Epoch 29/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.3439 - root_mean_squared_error: 0.5864 - val_loss: 0.3439 - val_root_mean_squared_error: 0.5850\n",
            "Epoch 30/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.3440 - root_mean_squared_error: 0.5865 - val_loss: 0.3450 - val_root_mean_squared_error: 0.5858\n",
            "Epoch 31/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3438 - root_mean_squared_error: 0.5865 - val_loss: 0.3438 - val_root_mean_squared_error: 0.5848\n",
            "Epoch 32/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.3441 - root_mean_squared_error: 0.5865 - val_loss: 0.3451 - val_root_mean_squared_error: 0.5859\n",
            "Epoch 33/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.3443 - root_mean_squared_error: 0.5867 - val_loss: 0.3440 - val_root_mean_squared_error: 0.5850\n",
            "Epoch 34/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.3442 - root_mean_squared_error: 0.5867 - val_loss: 0.3447 - val_root_mean_squared_error: 0.5856\n",
            "Epoch 35/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.3439 - root_mean_squared_error: 0.5864 - val_loss: 0.3462 - val_root_mean_squared_error: 0.5872\n",
            "Epoch 36/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.3445 - root_mean_squared_error: 0.5868 - val_loss: 0.3451 - val_root_mean_squared_error: 0.5861\n",
            "Epoch 37/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.3437 - root_mean_squared_error: 0.5863 - val_loss: 0.3441 - val_root_mean_squared_error: 0.5852\n",
            "Epoch 38/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3441 - root_mean_squared_error: 0.5866 - val_loss: 0.3458 - val_root_mean_squared_error: 0.5866\n",
            "Epoch 39/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.3438 - root_mean_squared_error: 0.5863 - val_loss: 0.3439 - val_root_mean_squared_error: 0.5852\n",
            "Epoch 40/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.3437 - root_mean_squared_error: 0.5862 - val_loss: 0.3439 - val_root_mean_squared_error: 0.5851\n",
            "Epoch 41/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3441 - root_mean_squared_error: 0.5865 - val_loss: 0.3428 - val_root_mean_squared_error: 0.5843\n",
            "Epoch 42/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.3442 - root_mean_squared_error: 0.5866 - val_loss: 0.3448 - val_root_mean_squared_error: 0.5856\n",
            "Epoch 43/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3438 - root_mean_squared_error: 0.5863 - val_loss: 0.3453 - val_root_mean_squared_error: 0.5858\n",
            "Epoch 44/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3442 - root_mean_squared_error: 0.5867 - val_loss: 0.3445 - val_root_mean_squared_error: 0.5856\n",
            "Epoch 45/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.3438 - root_mean_squared_error: 0.5864 - val_loss: 0.3440 - val_root_mean_squared_error: 0.5852\n",
            "Epoch 46/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3439 - root_mean_squared_error: 0.5864 - val_loss: 0.3432 - val_root_mean_squared_error: 0.5846\n",
            "Epoch 47/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3442 - root_mean_squared_error: 0.5866 - val_loss: 0.3448 - val_root_mean_squared_error: 0.5857\n",
            "Epoch 48/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.3443 - root_mean_squared_error: 0.5868 - val_loss: 0.3440 - val_root_mean_squared_error: 0.5850\n",
            "Epoch 49/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.3442 - root_mean_squared_error: 0.5867 - val_loss: 0.3444 - val_root_mean_squared_error: 0.5854\n",
            "Epoch 50/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3438 - root_mean_squared_error: 0.5864 - val_loss: 0.3449 - val_root_mean_squared_error: 0.5858\n",
            "0.6698552966117859\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMcbnLBEYY4zP/X/6m14JiGhpHQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluate the linear regression model against the test set:\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.3516 - root_mean_squared_error: 0.5899\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.35161352157592773, 0.589897871017456]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZjkJYDeGmuv",
        "colab_type": "text"
      },
      "source": [
        "##Build a neural net model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzIkZNjddP_p",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "source": [
        "#@title Define functions to create and train a neural net model\n",
        "def create_model(my_learning_rate, my_feature_layer):\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
        "  # Most simple tf.keras models are sequential.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # Add the layer containing the feature columns to the model.\n",
        "  model.add(my_feature_layer)\n",
        "\n",
        "  # Describe the topography of the model by calling the tf.keras.layers.Dense\n",
        "  # method once for each layer. We've specified the following arguments:\n",
        "  #   * units specifies the number of nodes in this layer.\n",
        "  #   * activation specifies the activation function (Rectified Linear Unit).\n",
        "  #   * name is just a string that can be useful when debugging.\n",
        "\n",
        "  # Define the first hidden layer with 20 nodes.   \n",
        "  model.add(tf.keras.layers.Dense(units=20, \n",
        "                                  activation='relu',\n",
        "                                  name='Hidden1'))\n",
        "  \n",
        "  # Define the second hidden layer with 12 nodes. \n",
        "  model.add(tf.keras.layers.Dense(units=12, \n",
        "                                  activation='relu', \n",
        "                                  name='Hidden2'))\n",
        "  \n",
        "  # Define the output layer.\n",
        "  model.add(tf.keras.layers.Dense(units=1,  \n",
        "                                  name='Output'))                              \n",
        "  \n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  return model\n",
        "\n",
        "def train_model(model, dataset, epochs, label_name,\n",
        "                batch_size, validation_split):\n",
        "  \"\"\"Train the model by feeding it data.\"\"\"\n",
        "\n",
        "  # Split the dataset into features and label.\n",
        "  features = {name:np.array(value) for name, value in dataset.items()}\n",
        "  label = np.array(features.pop(label_name))\n",
        "  history = model.fit(x=features, y=label, batch_size=batch_size,\n",
        "                      epochs=epochs, validation_split=validation_split, shuffle=True) \n",
        "\n",
        "  # The list of epochs is stored separately from the rest of history.\n",
        "  epochs = history.epoch\n",
        "  \n",
        "  # To track the progression of training, gather a snapshot\n",
        "  # of the model's mean squared error at each epoch. \n",
        "  hist = pd.DataFrame(history.history)\n",
        "  rmse = hist[\"root_mean_squared_error\"]\n",
        "\n",
        "  return epochs, rmse, history.history "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV3YvV0kiKTp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf0020da-098c-41db-d340-fa1f87429152"
      },
      "source": [
        "#@title Train the model\n",
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.01\n",
        "epochs = 50\n",
        "batch_size = 2000\n",
        "validation_split = 0.2\n",
        "label_name = \"Radiation\"\n",
        " \n",
        "\n",
        "# Establish the model's topography.\n",
        "my_model = create_model(learning_rate, my_feature_layer)\n",
        "\n",
        "# Train the model on the normalized training set.\n",
        "epochs, mse, history = train_model(my_model, data_train_norm, epochs, label_name, batch_size, \n",
        "                          validation_split)\n",
        "plot_the_loss_curve(epochs, history[\"root_mean_squared_error\"], \n",
        "                    history[\"val_root_mean_squared_error\"])\n",
        "\n",
        "test_features = {name:np.array(value) for name, value in data_test_norm.items()}\n",
        "test_label = np.array(test_features.pop(label_name)) # isolate the label\n",
        "print(\"\\n Evaluate the linear regression model against the test set:\")\n",
        "my_model.evaluate(x = test_features, y = test_label, batch_size=batch_size)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "11/11 [==============================] - 0s 18ms/step - loss: 0.6687 - root_mean_squared_error: 0.8270 - val_loss: 0.4183 - val_root_mean_squared_error: 0.6464\n",
            "Epoch 2/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.3748 - root_mean_squared_error: 0.6142 - val_loss: 0.2990 - val_root_mean_squared_error: 0.5472\n",
            "Epoch 3/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2889 - root_mean_squared_error: 0.5391 - val_loss: 0.2533 - val_root_mean_squared_error: 0.5045\n",
            "Epoch 4/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2418 - root_mean_squared_error: 0.4924 - val_loss: 0.2160 - val_root_mean_squared_error: 0.4662\n",
            "Epoch 5/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2104 - root_mean_squared_error: 0.4597 - val_loss: 0.1955 - val_root_mean_squared_error: 0.4437\n",
            "Epoch 6/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1912 - root_mean_squared_error: 0.4380 - val_loss: 0.1813 - val_root_mean_squared_error: 0.4274\n",
            "Epoch 7/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1797 - root_mean_squared_error: 0.4233 - val_loss: 0.1690 - val_root_mean_squared_error: 0.4128\n",
            "Epoch 8/50\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1672 - root_mean_squared_error: 0.4092 - val_loss: 0.1572 - val_root_mean_squared_error: 0.3980\n",
            "Epoch 9/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1590 - root_mean_squared_error: 0.3980 - val_loss: 0.1488 - val_root_mean_squared_error: 0.3875\n",
            "Epoch 10/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1495 - root_mean_squared_error: 0.3874 - val_loss: 0.1427 - val_root_mean_squared_error: 0.3794\n",
            "Epoch 11/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1436 - root_mean_squared_error: 0.3795 - val_loss: 0.1388 - val_root_mean_squared_error: 0.3746\n",
            "Epoch 12/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1397 - root_mean_squared_error: 0.3737 - val_loss: 0.1323 - val_root_mean_squared_error: 0.3657\n",
            "Epoch 13/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1377 - root_mean_squared_error: 0.3710 - val_loss: 0.1297 - val_root_mean_squared_error: 0.3622\n",
            "Epoch 14/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1343 - root_mean_squared_error: 0.3663 - val_loss: 0.1298 - val_root_mean_squared_error: 0.3624\n",
            "Epoch 15/50\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1313 - root_mean_squared_error: 0.3634 - val_loss: 0.1259 - val_root_mean_squared_error: 0.3569\n",
            "Epoch 16/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1299 - root_mean_squared_error: 0.3609 - val_loss: 0.1249 - val_root_mean_squared_error: 0.3555\n",
            "Epoch 17/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1293 - root_mean_squared_error: 0.3594 - val_loss: 0.1262 - val_root_mean_squared_error: 0.3574\n",
            "Epoch 18/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1302 - root_mean_squared_error: 0.3603 - val_loss: 0.1232 - val_root_mean_squared_error: 0.3532\n",
            "Epoch 19/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1293 - root_mean_squared_error: 0.3601 - val_loss: 0.1246 - val_root_mean_squared_error: 0.3553\n",
            "Epoch 20/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1266 - root_mean_squared_error: 0.3568 - val_loss: 0.1216 - val_root_mean_squared_error: 0.3509\n",
            "Epoch 21/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1253 - root_mean_squared_error: 0.3549 - val_loss: 0.1208 - val_root_mean_squared_error: 0.3501\n",
            "Epoch 22/50\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1260 - root_mean_squared_error: 0.3551 - val_loss: 0.1221 - val_root_mean_squared_error: 0.3519\n",
            "Epoch 23/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1261 - root_mean_squared_error: 0.3562 - val_loss: 0.1204 - val_root_mean_squared_error: 0.3495\n",
            "Epoch 24/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1256 - root_mean_squared_error: 0.3557 - val_loss: 0.1247 - val_root_mean_squared_error: 0.3552\n",
            "Epoch 25/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1248 - root_mean_squared_error: 0.3537 - val_loss: 0.1190 - val_root_mean_squared_error: 0.3472\n",
            "Epoch 26/50\n",
            "11/11 [==============================] - 0s 10ms/step - loss: 0.1232 - root_mean_squared_error: 0.3504 - val_loss: 0.1181 - val_root_mean_squared_error: 0.3462\n",
            "Epoch 27/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1229 - root_mean_squared_error: 0.3503 - val_loss: 0.1190 - val_root_mean_squared_error: 0.3474\n",
            "Epoch 28/50\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1221 - root_mean_squared_error: 0.3496 - val_loss: 0.1179 - val_root_mean_squared_error: 0.3458\n",
            "Epoch 29/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1233 - root_mean_squared_error: 0.3501 - val_loss: 0.1176 - val_root_mean_squared_error: 0.3456\n",
            "Epoch 30/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1213 - root_mean_squared_error: 0.3483 - val_loss: 0.1201 - val_root_mean_squared_error: 0.3490\n",
            "Epoch 31/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1244 - root_mean_squared_error: 0.3526 - val_loss: 0.1194 - val_root_mean_squared_error: 0.3482\n",
            "Epoch 32/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1216 - root_mean_squared_error: 0.3494 - val_loss: 0.1187 - val_root_mean_squared_error: 0.3469\n",
            "Epoch 33/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1195 - root_mean_squared_error: 0.3475 - val_loss: 0.1163 - val_root_mean_squared_error: 0.3433\n",
            "Epoch 34/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1198 - root_mean_squared_error: 0.3458 - val_loss: 0.1169 - val_root_mean_squared_error: 0.3441\n",
            "Epoch 35/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1193 - root_mean_squared_error: 0.3461 - val_loss: 0.1172 - val_root_mean_squared_error: 0.3446\n",
            "Epoch 36/50\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1198 - root_mean_squared_error: 0.3461 - val_loss: 0.1186 - val_root_mean_squared_error: 0.3467\n",
            "Epoch 37/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1203 - root_mean_squared_error: 0.3464 - val_loss: 0.1162 - val_root_mean_squared_error: 0.3433\n",
            "Epoch 38/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1185 - root_mean_squared_error: 0.3442 - val_loss: 0.1173 - val_root_mean_squared_error: 0.3446\n",
            "Epoch 39/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1199 - root_mean_squared_error: 0.3468 - val_loss: 0.1197 - val_root_mean_squared_error: 0.3485\n",
            "Epoch 40/50\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1202 - root_mean_squared_error: 0.3481 - val_loss: 0.1164 - val_root_mean_squared_error: 0.3435\n",
            "Epoch 41/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1201 - root_mean_squared_error: 0.3457 - val_loss: 0.1142 - val_root_mean_squared_error: 0.3404\n",
            "Epoch 42/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1181 - root_mean_squared_error: 0.3443 - val_loss: 0.1178 - val_root_mean_squared_error: 0.3457\n",
            "Epoch 43/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1221 - root_mean_squared_error: 0.3481 - val_loss: 0.1204 - val_root_mean_squared_error: 0.3491\n",
            "Epoch 44/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1206 - root_mean_squared_error: 0.3471 - val_loss: 0.1172 - val_root_mean_squared_error: 0.3446\n",
            "Epoch 45/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1205 - root_mean_squared_error: 0.3466 - val_loss: 0.1153 - val_root_mean_squared_error: 0.3420\n",
            "Epoch 46/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1176 - root_mean_squared_error: 0.3428 - val_loss: 0.1180 - val_root_mean_squared_error: 0.3460\n",
            "Epoch 47/50\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.1191 - root_mean_squared_error: 0.3437 - val_loss: 0.1143 - val_root_mean_squared_error: 0.3406\n",
            "Epoch 48/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1153 - root_mean_squared_error: 0.3420 - val_loss: 0.1143 - val_root_mean_squared_error: 0.3407\n",
            "Epoch 49/50\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1174 - root_mean_squared_error: 0.3430 - val_loss: 0.1132 - val_root_mean_squared_error: 0.3391\n",
            "Epoch 50/50\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1178 - root_mean_squared_error: 0.3427 - val_loss: 0.1166 - val_root_mean_squared_error: 0.3440\n",
            "0.2750650942325592\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXxU9dX48c/JHrKHBMhCJEhYAoGQ\nRECFFtyKG1Rxo25oW6ut2moXtT9bldanto+11qe1VluXVivuFBWlat1xYV/CIghBkrAlQBbIPuf3\nx70JIYYwxEwmyZz363VfM/OduTPnYpwz311UFWOMMaatIH8HYIwxpmeyBGGMMaZdliCMMca0yxKE\nMcaYdlmCMMYY064QfwfQVZKSknTIkCH+DsMYY3qVZcuWlalqcnvP9ZkEMWTIEJYuXervMIwxplcR\nkW1Hes6amIwxxrTLEoQxxph2WYIwxhjTrj7TB2GM6T4NDQ0UFxdTW1vr71CMlyIiIkhPTyc0NNTr\ncyxBGGOOWXFxMTExMQwZMgQR8Xc45ihUlfLycoqLi8nMzPT6PGtiMsYcs9raWvr372/JoZcQEfr3\n73/MNT5LEMaYTrHk0Lt05r9XwCeIipoG7n/zM1Zt3+/vUIwxpkcJ+AQhAve/uYlPt+71dyjGGC+V\nl5eTm5tLbm4ugwYNIi0treVxfX19h+cuXbqUG2+88aifcdJJJ3VJrO+88w7nnHNOl7xXdwv4TurY\niFBiwkMo2V/j71CMMV7q378/K1euBODOO+8kOjqan/zkJy3PNzY2EhLS/tdbQUEBBQUFR/2MxYsX\nd02wvVjA1yAAUuMjLUEY08vNmTOHa6+9lokTJ/Kzn/2MTz/9lBNPPJHx48dz0kknsXHjRuDwX/R3\n3nknV199NVOnTmXo0KE88MADLe8XHR3d8vqpU6dywQUXMHLkSC699FKad+JcuHAhI0eOJD8/nxtv\nvPGYagpPP/00OTk5jBkzhltuuQWApqYm5syZw5gxY8jJyeEPf/gDAA888ADZ2dmMHTuWSy655Kv/\nY3kp4GsQAKnxEZRagjCmU+56uZB1pZVd+p7ZqbHcce7oYz6vuLiYxYsXExwcTGVlJe+//z4hISG8\n+eab/PznP+eFF1740jkbNmzg7bffpqqqihEjRnDdddd9aa7AihUrKCwsJDU1lZNPPpkPP/yQgoIC\nvve97/Hee++RmZnJ7NmzvY6ztLSUW265hWXLlpGQkMAZZ5zB/PnzGTx4MCUlJaxduxaA/fudvtF7\n7rmHrVu3Eh4e3lLWHawGgVODsARhTO934YUXEhwcDEBFRQUXXnghY8aM4aabbqKwsLDdc84++2zC\nw8NJSkpiwIAB7Nq160uvmTBhAunp6QQFBZGbm0tRUREbNmxg6NChLfMKjiVBLFmyhKlTp5KcnExI\nSAiXXnop7733HkOHDmXLli3ccMMNvP7668TGxgIwduxYLr30Up588skjNp35gtUgcBLEvoMNHKxv\npF+Y/ZMYcyw680vfV6Kiolru/+IXv2DatGm89NJLFBUVMXXq1HbPCQ8Pb7kfHBxMY2Njp17TFRIS\nEli1ahWLFi3ioYce4tlnn+XRRx/l1Vdf5b333uPll1/m7rvvZs2aNd2SKKwGAaQnRAJQut+WDTCm\nr6ioqCAtLQ2Axx9/vMvff8SIEWzZsoWioiIAnnnmGa/PnTBhAu+++y5lZWU0NTXx9NNP8/Wvf52y\nsjI8Hg+zZs3i17/+NcuXL8fj8bB9+3amTZvGb3/7WyoqKqiuru7y62mPTxOEiEwXkY0isllEbj3C\nay4SkXUiUigi/2pVfqWIbHKPK30ZZ2p8c4KwZiZj+oqf/exn3HbbbYwfP94nv/gjIyN58MEHmT59\nOvn5+cTExBAXF9fua9966y3S09NbjqKiIu655x6mTZvGuHHjyM/PZ+bMmZSUlDB16lRyc3O57LLL\n+M1vfkNTUxOXXXYZOTk5jB8/nhtvvJH4+Pguv572SHNvfJe/sUgw8BlwOlAMLAFmq+q6Vq/JAp4F\nTlHVfSIyQFV3i0gisBQoABRYBuSr6r4jfV5BQYF2dsOgkv01nHzPf7nn/BwumZDRqfcwJpCsX7+e\nUaNG+TsMv6uuriY6OhpV5Qc/+AFZWVncdNNN/g7riNr77yYiy1S13XG/vqxBTAA2q+oWVa0H5gEz\n27zmu8Cfm7/4VXW3W/4N4A1V3es+9wYw3VeBDowJJ0isBmGMOTaPPPIIubm5jB49moqKCr73ve/5\nO6Qu5ctejjRge6vHxcDENq8ZDiAiHwLBwJ2q+voRzk1r+wEicg1wDUBGRud/+YcEBzEoNoIS64Mw\nxhyDm266qUfXGL4qf3dShwBZwFRgNvCIiHjduKaqD6tqgaoWJCe3u+e212yoqzHGHM6XCaIEGNzq\ncbpb1loxsEBVG1R1K06fRZaX53Ypm01tjDGH82WCWAJkiUimiIQBlwAL2rxmPk7tARFJwmly2gIs\nAs4QkQQRSQDOcMt8JjU+kh0VNXg8vum0N8aY3sZnfRCq2igi1+N8sQcDj6pqoYjMBZaq6gIOJYJ1\nQBPwU1UtBxCRX+EkGYC5qurT5VbT4iNoaFLKqusYEBvhy48yxphewad9EKq6UFWHq+rxqnq3W/ZL\nNzmgjptVNVtVc1R1XqtzH1XVYe7xmC/jhENzIayZyZieb9q0aSxadHijwv3338911113xHOmTp1K\n81D4s846q901je68807uvffeDj97/vz5rFvXMlqfX/7yl7z55pvHEn67euKy4P7upO4xDk2Ws5FM\nxvR0s2fPZt68eYeVzZs3z+v1kBYuXNjpyWZtE8TcuXM57bTTOvVePZ0lCFdags2mNqa3uOCCC3j1\n1VdbNgcqKiqitLSUKVOmcN1111FQUMDo0aO544472j1/yJAhlJWVAXD33XczfPhwJk+e3LIkODhz\nHE444QTGjRvHrFmzOHjwIIsXL2bBggX89Kc/JTc3l88//5w5c+bw/PPPA86M6fHjx5OTk8PVV19N\nXV1dy+fdcccd5OXlkZOTw4YNG7y+Vn8uC24r07ls4yBjOum1W2Hnmq59z0E5cOY9R3w6MTGRCRMm\n8NprrzFz5kzmzZvHRRddhIhw9913k5iYSFNTE6eeeiqrV69m7Nix7b7PsmXLmDdvHitXrqSxsZG8\nvDzy8/MBOP/88/nud78LwO23387f//53brjhBmbMmME555zDBRdccNh71dbWMmfOHN566y2GDx/O\nFVdcwV/+8hd+9KMfAZCUlMTy5ct58MEHuffee/nb3/521H8Gfy8LbjWIVmwuhDG9R+tmptbNS88+\n+yx5eXmMHz+ewsLCw5qD2nr//fc577zz6NevH7GxscyYMaPlubVr1zJlyhRycnJ46qmnjrhceLON\nGzeSmZnJ8OHDAbjyyit57733Wp4///zzAcjPz29Z4O9o/L0suNUgWkmNj6C0whKEMcekg1/6vjRz\n5kxuuukmli9fzsGDB8nPz2fr1q3ce++9LFmyhISEBObMmUNtbef6FefMmcP8+fMZN24cjz/+OO+8\n885Xird5yfCuWC68u5YFtxpEK04NwjqpjekNoqOjmTZtGldffXVL7aGyspKoqCji4uLYtWsXr732\nWofv8bWvfY358+dTU1NDVVUVL7/8cstzVVVVpKSk0NDQwFNPPdVSHhMTQ1VV1Zfea8SIERQVFbF5\n82YA/vnPf/L1r3/9K12jv5cFtxpEK6nxkew9UG8bBxnTS8yePZvzzjuvpalp3LhxjB8/npEjRzJ4\n8GBOPvnkDs/Py8vj4osvZty4cQwYMIATTjih5blf/epXTJw4keTkZCZOnNiSFC655BK++93v8sAD\nD7R0TgNERETw2GOPceGFF9LY2MgJJ5zAtddee0zX07wseLPnnnuuZVlwVeXss89m5syZrFq1iquu\nugqPxwNw2LLgFRUVqGqXLAvus+W+u9tXWe672fwVJfzomZW8efPXGTYguosiM6bvseW+e6eetNx3\nr2MbBxljzCGWIFpJjXeW2LAEYYwxliAOMzA2wjYOMsZLfaV5OlB05r+XJYhWQoODGGgbBxlzVBER\nEZSXl1uS6CVUlfLyciIijm0hUhuq00aaTZYz5qjS09MpLi5mz549/g7FeCkiIuKwEVLesATRRmp8\nJKuKv/oUdWP6stDQUDIzM/0dhvExa2JqIzU+kh37a23jIGNMwLME0UZafAT1TR7Kquv8HYoxxviV\nJYg2bOMgY4xxWIJowzYOMsYYhyWINmw2tTHGOCxBtBEbEUK0bRxkjDGWINoSEWdfCEsQxpgAZwmi\nHanxkbZxkDEm4HWYIEQkWETu7a5gegrbOMgYY46SIFS1CZjcTbH0GGnuxkE19U3+DsUYY/zGm6U2\nVojIAuA54EBzoaq+6LOo/CyteSRTRQ3HJ9vGQcaYwORNgogAyoFTWpUp0GcTRMtkuX2WIIwxgeuo\nCUJVr+qOQHoS2zjIGGO8GMUkIuki8pKI7HaPF0TEqzVjRWS6iGwUkc0icms7z88RkT0istI9vtPq\nuaZW5QuO7bK+Gts4yBhjvGtiegz4F3Ch+/gyt+z0jk4SkWDgz+7rioElIrJAVde1eekzqnp9O29R\no6q5XsTX5WzjIGOM8W4eRLKqPqaqje7xOJDsxXkTgM2qukVV64F5wMyvEGu3SrWNg4wxAc6bBFEu\nIpe5cyKCReQynE7ro0kDtrd6XOyWtTVLRFaLyPMiMrhVeYSILBWRj0Xkm+19gIhc475maVfvbGWT\n5Ywxgc6bBHE1cBGwE9gBXAB0Vcf1y8AQVR0LvAE80eq541S1APgWcL+IHN/2ZFV9WFULVLUgOdmb\nSk076qphzfNQ/vlhxanxEbZxkDEmoB11JjXwP6o6Q1WTVXWAqn5TVb/w4r1LgNY1gnS3rIWqlqtq\n8848fwPyWz1X4t5uAd4BxnvxmceusQ5e+DZseOWw4rT4SGfjoAO2cZAxJjB5M5P6OBEJ68R7LwGy\nRCTTPf8S4LDRSCKS0urhDGC9W54gIuHu/STgZKBt53bXiOoP8RlQsvyw4tQ42xfCGBPYvBnFtAX4\n0B1q2nom9X0dnaSqjSJyPbAICAYeVdVCEZkLLFXVBcCNIjIDaAT2AnPc00cBfxURD04Su6ed0U9d\nJ3U8lB6eINISDu0LkTs43mcfbYwxPZU3CeJz9wgCYo7lzVV1IbCwTdkvW92/DbitnfMWAznH8llf\nSWoerPs3HCh3ahQcPpvaGGMCUYcJwu2DGK6ql3ZTPP6Rlufclq6ArNMA2zjIGGN82QfRe6TkAnJY\nM5NtHGSMCXQ+64PoVSJiISnrSx3VGYn92FJ24AgnGWNM3+bNPIjPgVc41AfRfPQtqXlODUIPzXvI\nTolly55qahtsXwhjTODxZjXXu9qWiYg3NY/eJS0PVs+DylKIcyZ8Z6fG4lHYsLPKRjIZYwLOEWsQ\nIvJBq/v/bPP0pz6LyF9SmzuqDzUzjU6NA2BdaaU/IjLGGL/qqIkpqtX9MW2eEx/E4l+DciAo5LB+\niPSESGLCQ1i3o8KPgRljjH90lCD0CPfbe9z7hUbAgOwvjWQalRpLodUgjDEBqKO+hHgROQ8nicSL\nyPluuQBxPo/MH9LyoPAlp6NanErS6NRY5n26nSaPEhzU9ypOxhhzJB3VIN7FWR/pHPf+ue5xDvCe\n70Pzg9Q8qK2AvVtairJTYqlpaGKrDXc1xgSYI9YgAnEv6pYZ1SXLob+zunh2aiwA63ZUMmxAtL8i\nM8aYbufNPIjAkTwKQiIP64fIGhBDaLDYSCZjTMCxBNFacAikjHXWZHKFhQSRNSCGwlIbyWSMCSyW\nINpKHQ87VkFTY0vR6NRY1pVWotr3Bm8ZY8yRHLEPotWopXap6otdH04PkJoHnzwEZRth4GjA6Yd4\nblkxe6rqGBAb4ecAjTGme3Q0zPVc93YAcBLwX/fxNGAx0DcTROuO6uYEkeJ0VBeWVlqCMMYEjCM2\nManqVe5IplAgW1VnqeosYLRb1jclHg/hsYd1VI9qNZLJGGMChTd9EINVdUerx7uADB/F439BQZCa\ne9iSG7ERoWQk9rORTMaYgOJNgnhLRBaJyBwRmQO8Crzp27D8LDUPdhVCY11LUXZKrI1kMsYElKMm\nCFW9HngIGOceD6vqDb4OzK/S8sDTADvXthSNTo2lqPwg1XWNHZxojDF9h7fDXJcDr6rqTcAiEel7\nGwa11s7S380zqjdYP4QxJkAcNUGIyHeB54G/ukVpwHxfBuV3cekQlXxYP0RzgrCVXY0xgcKbGsQP\ngJOBSgBV3YQz9LXvEjm0BalrUGwEiVFh1lFtjAkY3iSIOlWtb37gbjfa96cUp+XBno1QVwU4e0Nk\np8TaUFdjTMDwJkG8KyI/ByJF5HTgOeBl34bVA6TmAeosu+HKTo1l484qGpo8/ovLGGO6iTcJ4hZg\nD7AG+B6wELjdl0H1CK1nVLtGp8ZS3+Th8z3VfgrKGGO6T0dLbSAiwUChqo4EHumekHqIqCSIyzh8\nJFPzkhsllYwcFOuvyIwxplt0WINQ1SZgo4h0aua0iEwXkY0isllEbm3n+TkiskdEVrrHd1o9d6WI\nbHKPKzvz+V9Zej4UL215mJkURXhIkPVDGGMCQoc1CFcCUCginwIt+26q6oyOTnJrH38GTgeKgSUi\nskBV17V56TPuZLzW5yYCdwAFOB3iy9xz93kRb9cZPNHZo7qiBOLSCAkOYmRKrI1kMsYEBG8SxC86\n+d4TgM2qugVAROYBM4G2CaI93wDeUNW97rlvANOBpzsZS+cMnujcbv8Y4mYBTjPTq6tLUVVEpFvD\nMcaY7uTNUhvvtnd48d5pwPZWj4vdsrZmichqEXleRAYfy7kico2ILBWRpXv27PEipGM0KAdC+8EX\nn7QUZafGUlnbSMn+mq7/PGOM6UG8mUk9SUSWiEi1iNSLSJOIdFUby8vAEFUdC7wBPHEsJ6vqw6pa\noKoFycnJXRRSK8GhkJbv1CBco5uX/rZmJmNMH+fNMNc/AbOBTUAk8B2cvoWjKQEGt3qc7pa1UNVy\nVW1eMvVvQL6353abjEnOon11ztDWkYNiELElN4wxfZ9Xi/Wp6mYgWFWbVPUxnP6Ao1kCZIlIpoiE\nAZcAC1q/QERSWj2cAax37y8CzhCRBBFJAM5wy7rf4EmgTVDijGbqFxZCZlKUjWQyxvR53nRSH3S/\n4FeKyO+AHXjXd9EoItfjfLEHA4+qaqGIzAWWquoC4EYRmQE0AnuBOe65e0XkVzhJBmBuc4d1t0sv\nAMTphxg6FYDRqXEs39a9A6qMMaa7eZMgLsf5gr8euAmn6WeWN2+uqgtxZl63Lvtlq/u3Abcd4dxH\ngUe9+RyfioyHAaMO64fITonl5VWl7D1QT2JUmB+DM8YY3/GmJrBNVWtUtVJV71LVm90mp8AxeKIz\nYc7TBMAJQxIA+HhLuT+jMsYYn/JmFNNWEdnS9uiO4HqMjElQVwm7nS6ScYPjiQ4P4f1NZX4OzBhj\nfMebJqaCVvcjgAuBRN+E00O1njA3aAyhwUFMGtqfDzb7YO6FMcb0EN40MZW3OkpU9X7g7G6IredI\nGALRAw+bMDclK4nte2vYVn7gyOcZY0wvdtQahIjktXoYhFOj8Kbm0XeIOLWIVh3Vk7OSAHh/UxnH\n9Y/yV2TGGOMz3nzR/77V/UagCLjIJ9H0ZBmTYP0CqNwBsSkMTYoiNS6CDzaVcdmk4/wdnTHGdLmj\nJghVndYdgfR4gyc5t9s/htHnISJMzkri9bU7afIowUG2cJ8xpm/xponp5o6eV9X7ui6cHixlLIRE\nOv0Qo88DYHJWMs8uLWZ18X7GZyT4OUBjjOla3iy1UQBch7OaahpwLZAHxLhHYAgOdbYhbdUPcfLx\n/QH4wIa7GmP6IG8SRDqQp6o/VtUf4yyol+FOmrvLt+H1MIMnwo7VUO+MXOofHc7o1Fje32wJwhjT\n93iTIAYC9a0e17tlgSejeeG+ZS1Fk7OSWPHFPg7UNfoxMGOM6XreJIh/AJ+KyJ0ichfwCfC4T6Pq\nqdJPcG5bz4cYlkxDk/LJVlt2wxjTt3gzUe5u4CpgH1AOXKWqv/F1YD1Sv0RIHnlYP0TBkATCQ4Js\n2Q1jTJ9zxAQhIv1EJBRAVZcDr+Os6prZTbH1TIMnwvYl4PEAEBEazITMROuoNsb0OR3VIF4HhgCI\nyDDgI2Ao8AMRucf3ofVQGZOgrgL2rG8pmjwsiU27q9lZUevHwIwxpmt1lCASVHWTe/9K4GlVvQE4\nk0Bbi6m15oX7vvjyshsf2GgmY0wf0lGC0Fb3TwHeAFDVesDjy6B6tMShEJUM2w91VI8aFEv/qDA+\n2GSruxpj+o6OZlKvFpF7gRJgGPAfABGJ747AeqyWhfsOJYigIOHkYUl8sLkcVUXElt0wxvR+HdUg\nvguU4fRDnKGqB93ybOBeH8fVs2VMgn1FzuGanJVEWXUdG3ZW+S0sY4zpSkdMEO42o/eo6g9VdVWr\n8sWq+s/uCa+Hyp4JCKz8V0vR5GFuP4SNZjLG9BHeTJQzbcVnwLBTYcWTLftUp8ZHMjQ5ypbdMMb0\nGZYgOivvCqgsgc1vthRNGZbEp1vLqW1o8mNgxhjTNSxBdNbwM53RTMv/0VI0OSuZ2gYPy7ft82Ng\nxhjTNY6aIERkuIg8IiL/EZH/Nh/dEVyPFhIG42bDxtegaicAJx7fn/CQIF5ds8PPwRljzFfnTQ3i\nOWA5cDvw01aHybvSWd115VMARIeHcM7YVOavKKHaVnc1xvRy3iSIRlX9i6p+qqrLmg+fR9YbJA2D\n4ybD8n+2rM106aQMDtQ3sWBlqZ+DM8aYr8abBPGyiHxfRFJEJLH58HlkvUXeFbBvKxS9D8D4wfGM\nSonlqU+2oapHOdkYY3oubxLElThNSouBZe6x1Js3F5HpIrJRRDaLyK0dvG6WiKiIFLiPh4hIjYis\ndI+HvPk8v8ieARFxLZ3VIsKlEzMoLK1kVXGFn4MzxpjO82Y/iMx2jqFHO09EgoE/4yzulw3MFpHs\ndl4XA/wQZyOi1j5X1Vz3uNarq/GH0EgYewmsXwAH9wLwzfFpRIUF8+TH2/wcnDHGdJ5Xw1xFZIyI\nXCQiVzQfXpw2AdisqlvcBf7mATPbed2vgN8CvXet7LwroKkeVs0DnM7qmePTeHlVKRUHG/wcnDHG\ndI43w1zvAP7PPaYBvwNmePHeacD2Vo+L3bLW750HDFbVV9s5P1NEVojIuyIy5QixXSMiS0Vk6Z49\nflxJddAYSMt3mpncfodvTcigrtHDC8uL/ReXMcZ8Bd7UIC4ATgV2qupVwDgg7qt+sIgEAfcBP27n\n6R1AhqqOB24G/iUisW1fpKoPq2qBqhYkJyd/1ZC+mrwrnE2EipcAMCYtjtzB8dZZbYzptbxJEDWq\n6gEa3S/p3cBgL84rafO6dLesWQwwBnhHRIqAScACESlQ1TpVLQdwh9R+Dgz34jP9Z8wsCI2C5U+0\nFF06MYPP9xzgk617/RiYMcZ0jjcJYqm7B8QjOCOYluNsP3o0S4AsEckUkTDgEmBB85OqWqGqSao6\nRFWHAB8DM1R1qYgku53ciMhQIAvYciwX1u3CYyBnFqx9EWorATh3XCqxESE89ckXfg7OGGOOnTej\nmL6vqvtV9SHgdOBKt6npaOc1AtcDi4D1wLOqWigic0XkaH0YX8PZsGgl8Dxwrar2/J/heVdCw8GW\nZcAjQoO5IH8wr6/dQVl1nZ+DM8aYYyNHax8XZ3u0S4GhqjpXRDKAQar6aXcE6K2CggJdutSr6Rm+\nowqPnw1ln8GNKyE8ms27qzntvne5ZfpIrpt6vH/jM8aYNkRkmaoWtPecN01MDwInArPdx1U48xtM\nWyJw+lw4sAc++hMAwwZEM2loIv/6dBsej3VWG2N6D28SxERV/QHuPAVV3QeE+TSq3iy9AEbNgA8f\ngOrdAFw68Ti2762xzYSMMb2KNwmiwe0wVgARSQY8Po2qtzv1DmishXd/B8A3Rg+if1QYj3+41c+B\nGWOM97xJEA8ALwEDRORu4APgf3waVW+XNAzyr4Rlj0H554SFBPGdKUN5e+Me3t6429/RGWOMV7wZ\nxfQU8DPgNzgT2L6pqs/5OrBe7+u3QnA4vDUXgG9PzmRochR3Lii0LUmNMb3CERNEm6W9dwNPA/8C\ndtly316IGQgnXQ/r5kPxMsJCgrhrxmi2lR/kkfd69pQOY4yBjmsQZcBKnKW9l3JoqW+vl/sOeCfd\nAP2S4M07QJUpWcmcnZPCn97ezPa9B/0dnTHGdKijBPEAsA94HWdPiKHHsty3wZld/fVbnM2ENr0B\nwO3njCI4SJj7yjo/B2eMMR07YoJQ1R8BuTh7Ul8OrBCR34lIZncF1yfkz4GETKcW4WkiJS6SG0/N\n4o11u/jvhl3+js4YY46ow05qdbyN00n9EHAVcFp3BNZnhITBqb+A3etg9TMAXH1yJscnR3HngnXW\nYW2M6bE66qSOEpFvici/gYVANJCvqo90W3R9RfZ5kDreGdFUV0VYSBBzZ47hi70H+eu71mFtjOmZ\nOqpB7MapOXwE/B5nNdUCETlfRM7vjuD6jKAgOPN3ULWjZfLcycOSOGdsCg++s5kvyq3D2hjT83SU\nIJ4DVgAjgHOAc1sd5/g+tD5m8AQYfxl8/CDs3gDA7WdnExIkzH2l0M/BGWPMl4Uc6QlVndONcQSG\n0+6C9a/Awp/AlS8zKC6CH502nLsXrmdR4U6+MXqQvyM0xpgW3iy1YbpKVBKc+ktn2OvaFwCYc/IQ\nRg6K4c4FhVTXNfo5QGOMOcQSRHfLnwMpubDo/0FdFaHBQfzP+TnsrKzlvv985u/ojDGmxVEThIiE\ne1NmvBQUDGffB9W74J17AMjLSOCyicfx+OKtrCmu8HOAxhjj8KYG0d7+097sSW2OJD0f8q6Aj/8C\nu5wZ1T+dPoL+0eHc9tJqGptsNXVjjP91NA9ikIjkA5EiMl5E8txjKtCv2yLsq069AyJiYeFPQZXY\niFDuPHc0a0sq+cdH2/wdnTHGdFiD+AZwL5AO3IczF+L3wM3Az30fWh8X1d9JEts+gDXPA3BWziCm\njUjm9//ZSOn+Gj8HaIwJdHW1ti4AABvWSURBVB2txfSEqk4D5qjqtFbHDFV9sRtj7LvyroDUPPjP\n/4PaSkSEuTPH0KTKnQtsboQxxr+86YN4S0TuE5Gl7vF7EYnzeWSBICgYzv69s3e122E9OLEfN502\nnP+s28Wiwp1+DtAYE8i8SRB/B6qAi9yjEnjMl0EFlLQ8Z3vSTx5q6bC+enKmzY0wxvidNwnieFW9\nQ1W3uMddgO0H0ZVO+aXTYf3az0D1sLkRd/y7EFX1d4TGmADkTYKoEZHJzQ9E5GTAelC7UlR/OOUX\nh82wzstI4IenZvHC8mKe/OQLPwdojAlE3iSI64A/i0iRiGwD/gR8z7dhBaD8OZAyDv5zO9RVAXDj\nKVmcOnIAc18uZNm2vf6NzxgTcI6aIFR1paqOA8YCOao6XlVX+z60ABMUDGfde9iS4EFBwn0X55Ia\nH8l1Ty5nd2Wtn4M0xgQSb5baiBOR+4D/Av89llFMIjJdRDaKyGYRubWD180SERWRglZlt7nnbRSR\nb3jzeb3e4AmQ6y4JvsdZlykuMpS/Xp5PVW0j339qOfWNNsvaGNM9vGliepROjGISkWDgz8CZQDYw\nW0Sy23ldDPBD4JNWZdnAJcBoYDrwoPt+fd9pd0JoFLzmzLAGGDkolt9eMJal2/bxPwvX+zU8Y0zg\n8OUopgnAZvecemAeMLOd1/0K+C3Quv1kJjBPVetUdSuw2X2/vi86GU75f7DlHVj375biGeNS+c7k\nTB5fXMSLy4v9F58xJmD4chRTGrC91eNit6yFiOQBg1X11WM91z3/muYJfHv27PEipF6i4NswcIyz\nJHj9gZbiW88cyaShidz24hrWltiqr8YY3/LbKCYRCcJZ4+nHnX0PVX1YVQtUtSA5OfmrhtRzBIc4\nHdaVxfD6rS1NTSHBQfzpW3kk9Avje/9cRnl1nZ8DNcb0Zcc8igkocG+PpgQY3OpxulvWLAYYA7wj\nIkXAJGCB21F9tHP7vuNOhMk3w/J/OJ3WrqTocB6+Ip+y6jqufXKZdVobY3ymo+W+Y92RRH8SkdNx\nOqqvwOkPuMiL914CZIlIpoiE4XQ6L2h+UlUrVDVJVYeo6hDgY2CGqi51X3eJiISLSCaQBXzayWvs\nvU75BYw612lq2vhaS/HY9Hj+98JxLCnax+3z19hMa2OMT3RUg/gnMAJYA3wXeBu4EDhPVdvrbD6M\nqjYC1wOLgPXAs6paKCJzRWTGUc4tBJ4F1gGvAz9Q1SYvrqdvCQqC8/7qTKB7/tuwc03LUzPGpXLD\nKcN4dmkxj35Y5L8YjTF9lhzp16eIrFHVHPd+MLADyFDVHjlbq6CgQJcuXervMHyjshQeOQUkGL77\nX4gZCIDHo1z31DLeWLeLv885gWkjBvg5UGNMbyMiy1S1oL3nOqpBNDTfcX+9F/fU5NDnxabC7HlQ\nsxfmzYYGZxBZUJBw30W5jBgUy43/WsHm3VV+DtQY05d0lCDGiUile1QBY5vvi0hldwVoXKm5cP7D\nULIM5n+/ZWRTVHgIj1yRT3hoEN9+Yin7DtT7OVBjTF/R0Y5ywaoa6x4xqhrS6n5sdwZpXKPOdWZa\nF74Ib81tSRLpCf346+X57Nhfy/efWk5tQ+B11xhjup438yBMT3Lyj2D85fDBffD6beBxhrnmH5fI\nb87P4aMt5Vzx6KdUHGw4yhsZY0zHLEH0NiJw7gMw8Tr45C/w0jXQ6DQrzcpP54+X5LLii33Memgx\nJftt2w5jTOdZguiNgoJg+m/g1F/Cmuecjmt3SY6ZuWk8cfUEdlXWct6fP6Sw1JbkMMZ0jiWI3koE\npvzYqU18/l94YgYcdDYVOun4JJ6/9iSCg4SL//ox72/qQ+tUGWO6jSWI3i7/Srjon84kukenQ4Wz\n0uuIQTG8+P2TSE+I5KrHltgKsMaYY2YJoi8YdQ5c/qKzG93fz4D1L4MqKXGRPHvtiZwwJJGbn13F\nr19ZZyOcjDFeswTRVwyZDHNehbBoeOYypzZRvJTYiFCeuHoCl03K4G8fbOXMP77Pp1ttf2tjzNFZ\nguhLUsbCdYvhnPth7xb426nw3BzCKrfx62/m8K/vTKTR4+Hihz/izgWFHKxv9HfExpge7IhrMfU2\nfXotps6oq4bFD8Di/4OmBphwDUy9hQMSxf8u2sjji4sYnBjJb88fy0nDkvwdrTHGTzpai8kSRF9X\nuQPevhtWPgWDxsIV8yEygU+37uWWF1aztewAZ49N4ZycFKYMTyY6PMTfERtjupElCAOfLXL6JgaO\nhsvnQ2Q8NfVN3P/WZzyzZDv7DzYQFhzEicf357TsgZw+aiCD4iL8HbUxxscsQRjHxtedJDFoTEuS\nAGhs8rBs2z7eWLeLN9bvYlv5QQDGDY7n+mnDOG3UAETEn5EbY3zEEoQ5pCVJ5DjNTRFxhz2tqny+\np5o31u3muaXb2VJ2gBOGJHDrmSPJPy7RT0EbY3zFEoQ53MbX4JnLnVFPl7/0pSTRrKHJw7NLt3P/\nm5vYU1XHGdkD+dn0EQwbENPNARtjfMUShPmyDQvh2Suc7Uwvf/GISQLgYH0jj36wlYfe3cLB+kYu\nKhjMd6YMZdiA6G4M2BjjC5YgTPs2vArPXgnxg6Hg2zDuEog68pDX8uo6/vT2Zp78eBsNTcrwgdGc\nlZPCWTkpDB9otQpjeiNLEObIPv8vvP0bKP4UgkJh5NmQdwUMneasGtuOXZW1vLZmBwvX7mRJ0V5U\nYdiAaM4aM4hvjBnEqEGxBAVZp7YxvYElCHN0u9bBin/CqqehZh/EZcCY852lOzyNzqFN7q3CyHPg\nuBPZXVnLosKdLFyzk0+2luNRSIoOZ0pWElOykpiclcSAGBsua0xPZQnCeK+xDja8Asv/AVveOVQu\nQRAUAhLsJIqmemdnu9PnQj9ndFNZdR3vbtzDe5v28MGmMsrd/bFHpcQyeVh/RqfGMWJQDMcnRxMW\n0vEqLwfrG6muayQsOIiwkCDCgoMICbaVYYzpapYgTOc01jv7Tkjw4c1N9Qfg3d/C4j85cynOuNvp\nv2g1V8LjUdbtqOS9TXt4/7Mylm7bS0OT87cWEiRkJkUxYlAMwwfG0OhRdlXUsqOylp0VNeysqKWy\n9svrRAUJhAYHERMRyunZA5iVl07+cQk2R8OYr8AShPGNnWvhlR9B8RLI/Bqc/QdIGtbuS+sbPWwt\nO8CGnZV8tquKjTur2LCziuJ9NYhAcnQ4KXERDIyNcG7jIoiJCKWh0UN9k4f6RudoaPKwo6KWN9bt\noqahicykKM4fn8b5+emkxUd28z+AMb2fJQjjOx4PLH8c3rgTGmtgvDsJL2kEJA13RkW1/oVfsw9K\nlkPJMihZhmfHakgZR9CUm2HwBK8/trqukdfW7OCF5cV8vGUvInDi0P6cOmog4zPiGZ0aS3hIcCcv\nSSk/UI+iRIeHEBkabLUU02dZgjC+V7UL3viFs1lRw8FD5ZEJTqKIHuB0hO/93H1CnPKB2U5fR80+\nOO5kmHwzDDv18KTSrKHGSS57tzijrdy+j+17D/Li8hLmryxha5mzN3dYcBCj02IZPziBvOPiGdI/\niobmmkirGsnB+iZ2VNRQvK+Gkv2HbusbPS0fGyQQFRZCdEQIWaG7GR5RSb/hUykYksj4jHhiIkJ9\n9I9qjO9ZgjDdx+OByhIo2whlm2CPe1tVCgOyIS3fOVJzD03Oqz8Ay56Aj/7knDswByb/CIZMcZqv\ntn8MX3wMpSvB0+CcExYNJ3wbTrwBopNbPn5XZS0rvtjHii/2s/yLfawurqCu1Zf9kSRFh5EWH0l6\nQj/SEyJJjY8kOEiormvkQF0jB2pqKSh5ktP3PEaoNvDbxkv4S+O5BIkwclAsJwxJ4ITMRKaNGECU\nrYhrehG/JQgRmQ78EQgG/qaq97R5/lrgB0ATUA1co6rrRGQIsB7Y6L70Y1W9tqPPsgTRBzTWw5rn\n4MP7oeyzQ+XBYZCaBxmTnCNqAHz8IKx9AUIioOBqOPlGiBn0pbdsaPKwfkclpftrCA8JdkZEuaOi\nwkKCiAiGQfFRRIZ10By1YxX8+3rYuRqyZzqd9oUvUjJyDs8mXsfSL/azfNt+ahqa6BcWzPQxg7gg\nL51JQ/v7fT7IjooaXl+7k7Hp8eRlxFtTmfkSvyQIEQkGPgNOB4qBJcBsVV3X6jWxqlrp3p8BfF9V\np7sJ4hVVHePt51mC6EM8Hti4EPZthfQTICUXQtuZS1G2Cd7/Pax+1hmCm3cFDJ/uNGdFD3T6P4Ja\nffHXVjpf9qUrDh37tznLjRx/Chx/qtMPEuw2GTXUOqO1Pvyj815n3QvZM5z4Fv0cPvkLjLkAvvkX\nGiSE5dv28dKKEl5dvYOqukbS4iM5b3was/LTyUyK6p5/O9cX5Qf5y7uf8/yy7S2jxzIS+zEzN5WZ\nuWm2TIpp4a8EcSJwp6p+w318G4Cq/uYIr58NXKGqZ1qCMMdk7xZ4/z5nkp+n9fBYcb7Yowc68zvK\nNwPu33tchtPMlTDEbcb61JnfERbtjMjKOBGWP+GcM/4yOOPXTn9KM1X44A/w1l3OrPOL/wnhznIj\ntQ1NLCrcyQvLS/hg0x48ClFhwQQHCaHBQYfdRoQGER8ZRly/UBL6hRLfL4z4fqHERIRS19BEVa0z\nH6SqtsG9bSQ5Jpxx6fHkpMeRnRJLROihJLh5dzUPvrOZf68sJViEi05I5/JJQ1hdvJ8Fq0r5cHMZ\nHoXRqbF8MzeNU0YNYGhSlNUsApi/EsQFwHRV/Y77+HJgoqpe3+Z1PwBuBsKAU1R1k5sgCnFqIJXA\n7ar6fjufcQ1wDUBGRkb+tm3bfHItppeo3uN0glfvhupdzu2B3c4t4iSE1PHO0XbNqdoK2Pqes/TI\n5recmkV8Bpz7ABw/7cifueJJWHCjszLut547rD8EYGdFLa+sLmVHRS1NHqWhyUOTR2n0KI1NHmoa\nmqioaWD/Qfeoqae24fA+k+jwEOeICCEqLJiS/bWUVdcB0C+ogTkJa5jFW6TUfMauxhjKJIF+iWkM\nyRxKVGIaxKQ4iTBxKLubonl5zU4WrCxhVXEFAHGRoeQOjmd8Rjy5g50jvl/YV/2v0bU8Tc6mV+Wb\nnAma7gCFxiYPxftqKN1fw7CB0Z2fta8KX3yEZ9kTeDYspCrlJOqn3EL/zNw+P0GzRyeIVq//FvAN\nVb1SRMKBaFUtF5F8YD4wurk5qj1WgzBdRhUqiiEquf2mrbY2vg7PzYGYgc4SJHHpEDfYuY3PcGoe\nnkbY/4XTbLbXPfZtdUZmJY+EAaOc3f6SR1IbFEllbQORocFEhYV8qR9DVdmzZSUHP3qUgUXziWys\npJgBfKjjGJekHB9ZTejB3c7IsoYDh8caFgOJmZA4lP2Rg1kZPIZFB0eyfHsln+2uovnrYGhSFGPS\n4shJi2NMWhxj0mKPfbSWqlMDq9kHaQUtky1VlbpGD40ePfoWt3VVsOIp9JOHkH1bAagJjuGF2Ct4\nvP4UivbV0+g59B02YmAMk7OSmDwsiQmZiUcfMFC9G1Y9TdOyJwje+znV9OOdphy+HrSaKGp52XMi\nT0V8i6bE40mJiyApOpyYiEMJuzl5D4yNYHRqbK+sifWWJqYgYJ+qfmndaRF5B/iJqh4xA1iCMH71\nxSfw6o+dL8TGmsOfC+3nNHFp06GykEjnV31IuNMh33pocPxxTtKIiHWeD4k4dASFwOdvOc1iwWFO\nQsq/Eh0yhSaVL//araty9iXfV+Q0xbU+9m9zEldCJhRcRfWoi1m9N4QV2/ezavt+1pZUUFpR2/JW\nmUlRjEqJQRAO1jdysL6JmoYm57a+CZoaGMlWcnU9Yz3rGedZTzzOb7pSBvAC03i28WtsbzzUVJcW\nH8nEoYlMzExkYmZ/juvfz/mS3VdEw0d/hRX/ILShmjUygofqvkGRDuT2sKc5UdayMzSD94fehGad\nTkpcBGtLKvlg8x6WFO2jvtFDSJCQl5FA3nEJDB8YzfCBMQwbEO00yZWuhPfvRTe+hngaWaYj+VfD\nVMoypnPxySOJ1UoSV/6VrKKnCPI08H7kqfyFWayrSaC6rpH2vjZHp8Zy9cmZnDMuhXBR2PCyM5Bi\n6DTIn3N4f1gP4q8EEYLTRHQqUILTSf0tVS1s9ZosVd3k3j8XuENVC0QkGdirqk0iMhR4H8hR1b1H\n+jxLEKZHUIWD5VCxHfZvd2oiFcUQGgmJQ51f7wmZzoir5l+bHg/sL3LmiexeD7sLoWwz1Fc7iaWx\n1r2tAfU4kxDzroBxsyGqf+djbayDdQtg6aPwxWIn4WR/0xkVljEJ1EP5nlI+37qV0uJt7N21nbqK\nXcRwgNigWuKoIVpqiOYA/fQgA+u2EaZO01dZaBpb+uWwJXIMDRLOpMrXyTqwDA9BFCWcxMbUb/JF\n/ymsKqlk+9bPSKz9gqFSypjwXYwN38XxNWtoUmGhZyLzgs4mbtiJnDJyACdnJZEaG4589jr853an\nSXHYac5yLwNGAk4f0NKifXywuYwPN5exfkdlSy0jXqq5K+pFzm1cxIGgGJ6un8JLegrZ407g6slD\nGJ3a5vdp9W744H5Y8jfn3z57Jpp1BgczpnIgOI6qukaqaxtZW1rB4x8WUbp7D1f3+4DvhC4irq4U\nwuOgrsJp1jz7PkjLo8mjlFfXER4STFy/LphDU7rCqS2OmN6p0/05zPUs4H6cYa6PqurdIjIXWKqq\nC0Tkj8BpQAOwD7heVQtFZBYw1y334CSOlzv6LEsQps9TdX7xB/tgYt7u9U6iWDUP6iqdOSp1Vc6X\nYlsS5HTIh8c5txGxzm3iUKdzP2NSu0OO2bvV6bNZ+RRU7XA+o6EWmupaXnIwKJotmsLq0HHsGXk5\nJ4wdQ8GQxPYXd2yshyWPwDu/dZLpsNMg50IYcSaEHxql1dDkoWhPFTWfPEHWmnsJb6xiftjZ/FUu\nZnrBCC6dlHH0vovKUmcgROFLcLAMEGc+T9bpzhGVjH7yME1LHyOkoZpPPSN4wnM2EWPO4aTa9zht\n+x+JadrPS0Fn8OvaC9jncUa1pcVHkp0aS3ZKLKNTY8lOjSU1LpJ9B+vZUVFL6f4adlbWUrq/lt2V\nTm0uPDSY8JAgkj1lTCt5iOw9C6mMzSL2piXtTzA9CpsoZ4zxTv0BWPM8lC53+mCiBhwaNhw9wCkL\nj+nUF1GLpkbY/IYz6z4yAZKynFn1/bO+vDSLNw6Uw+IHnDk0lSVOk96Is5xkcfwpTo3s1Z9AyVIn\ngZ31v85yMJ3h8cCOFbDpDecoWUbLyDgJcubJnHgDn4eP4PEPi3hheTHBIgyNbeL7+gynVy+gJiSO\nlSNvZk3SWRTuqGJdaQVbyg60NFsFCXjafC2HBgsDYiIQgaD6A1zW9AJX6CsI8PemM1k86HKevP6M\nTl2SJQhjTN/n8cAXH8Ha551f+jX7nFpKbaWT2M74FYy9+Kslt7YOlDkj3/Zvg5yLIOG4w55W1cM7\nrnesdvqqij+F0CgnFvWg6kE9HlAPjRJCRfRQahOzCRo0hn4Z44g7bjxBETGw4h/w9v/AgT2QcyFN\n035BfXQ6jR5Pp5d8sQRhjAksjfWw5W0onO8MPZ7y4w73Xe9WHo9T29mx0ql1iLi37lF/EHavg11r\nnf6sZmExUF/l1ILOuBvS87skHEsQxhjT26g683l2rXWW1i/fDFlnwKhzu7QW1FGCsFXFjDGmJxJx\nOvtjBjkd8H7Qt6cIGmOM6TRLEMYYY9plCcIYY0y7LEEYY4xplyUIY4wx7bIEYYwxpl2WIIwxxrTL\nEoQxxph29ZmZ1CKyBzjalnJJQFk3hNNTBfL1B/K1Q2Bfv117x45T1eT2nugzCcIbIrL0SFPKA0Eg\nX38gXzsE9vXbtXf+2q2JyRhjTLssQRhjjGlXoCWIh/0dgJ8F8vUH8rVDYF+/XXsnBVQfhDHGGO8F\nWg3CGGOMlyxBGGOMaVfAJAgRmS4iG0Vks4jc6u94fE1EHhWR3SKytlVZooi8ISKb3NsEf8boKyIy\nWETeFpF1IlIoIj90y/v89YtIhIh8KiKr3Gu/yy3PFJFP3L//Z0QkzN+x+oqIBIvIChF5xX0cSNde\nJCJrRGSliCx1yzr9dx8QCUJEgoE/A2cC2cBsEcn2b1Q+9zgwvU3ZrcBbqpoFvOU+7osagR+rajYw\nCfiB+987EK6/DjhFVccBucB0EZkE/Bb4g6oOA/YB3/ZjjL72Q2B9q8eBdO0A01Q1t9X8h07/3QdE\nggAmAJtVdYuq1gPzgJl+jsmnVPU9YG+b4pnAE+79J4BvdmtQ3URVd6jqcvd+Fc6XRRoBcP3qqHYf\nhrqHAqcAz7vlffLaAUQkHTgb+Jv7WAiQa+9Ap//uAyVBpAHbWz0udssCzUBV3eHe3wkM9Gcw3UFE\nhgDjgU8IkOt3m1hWAruBN4DPgf2q2ui+pC///d8P/AzwuI/7EzjXDs6Pgf+IyDIRucYt6/TffUhX\nR2d6B1VVEenTY5xFJBp4AfiRqlY6PyYdffn6VbUJyBWReOAlYKSfQ+oWInIOsFtVl4nIVH/H4yeT\nVbVERAYAb4jIhtZPHuvffaDUIEqAwa0ep7tlgWaXiKQAuLe7/RyPz4hIKE5yeEpVX3SLA+b6AVR1\nP/A2cCIQLyLNPwj76t//ycAMESnCaUY+BfgjgXHtAKhqiXu7G+fHwQS+wt99oCSIJUCWO5ohDLgE\nWODnmPxhAXCle/9K4N9+jMVn3HbnvwPrVfW+Vk/1+esXkWS35oCIRAKn4/TBvA1c4L6sT167qt6m\nqumqOgTn//H/quqlBMC1A4hIlIjENN8HzgDW8hX+7gNmJrWInIXTPhkMPKqqd/s5JJ8SkaeBqTjL\n/e4C7gDmA88CGThLo1+kqm07sns9EZkMvA+s4VBb9M9x+iH69PWLyFicjshgnB+Az6rqXBEZivOr\nOhFYAVymqnX+i9S33Camn6jqOYFy7e51vuQ+DAH+pap3i0h/Ovl3HzAJwhhjzLEJlCYmY4wxx8gS\nhDHGmHZZgjDGGNMuSxDGGGPaZQnCGGNMuyxBGHMMRKTJXSmz+eiyBf9EZEjr1XeN8TdbasOYY1Oj\nqrn+DsKY7mA1CGO6gLsO/+/ctfg/FZFhbvkQEfmviKwWkbdEJMMtHygiL7n7NqwSkZPctwoWkUfc\nvRz+486GNsYvLEEYc2wi2zQxXdzquQpVzQH+hDNrH+D/gCdUdSzwFPCAW/4A8K67b0MeUOiWZwF/\nVtXRwH5glo+vx5gjspnUxhwDEalW1eh2yotwNurZ4i4UuFNV+4tIGZCiqg1u+Q5VTRKRPUB66yUf\n3KXJ33A3dkFEbgFCVfXXvr8yY77MahDGdB09wv1j0XqNoCasn9D4kSUIY7rOxa1uP3LvL8ZZWRTg\nUpxFBMHZ+vE6aNngJ667gjTGW/brxJhjE+nu1tbsdVVtHuqaICKrcWoBs92yG4DHROSnwB7gKrf8\nh8DDIvJtnJrCdcAOjOlBrA/CmC7g9kEUqGqZv2MxpqtYE5Mxxph2WQ3CGGNMu6wGYYwxpl2WIIwx\nxrTLEoQxxph2WYIwxhjTLksQxhhj2vX/AfCwgl8+be0BAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluate the linear regression model against the test set:\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 0.1233 - root_mean_squared_error: 0.3533\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.12334352731704712, 0.3532779812812805]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    }
  ]
}