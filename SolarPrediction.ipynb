{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SolarPrediction.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrch-hub/bangkit1/blob/test_feature_2/SolarPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5bF6G8ff6Zq",
        "colab_type": "text"
      },
      "source": [
        "##Solar radiation intensity prediction using TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6pwJrUZ9rYW",
        "colab_type": "code",
        "outputId": "6a289da9-924b-4a89-fdb3-eb987e32fa59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\"\"\"A python code for predicting solar radiation\n",
        "intensity using TensorFlow. Created for \n",
        "5th Bangk!t assignment.\n",
        "Collaborators: Marcellinus Chrisnada, Muhammad\n",
        "Harits Hafidza, Mochammad Randy Caesario H.\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A python code for predicting solar radiation\\nintensity using TensorFlow. Created for \\n5th Bangk!t assignment.\\nCollaborators: Marcellinus Chrisnada, Muhammad\\nHarits Hafidza, Mochammad Randy Caesario H.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yb2tFywNgWIn",
        "colab_type": "text"
      },
      "source": [
        "##Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8ekWJYDbTzp",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Run on TensorFlow 2.x\n",
        "%tensorflow_version 2.x\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPY5vbLWXmKN",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "6bd6dce3-40f3-4f78-d664-0db8a2f75a1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#@title Import relevant modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Adjust the granularity of reporting. \n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "\n",
        "print(\"Imported modules.\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imported modules.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRlH8pQwbSpE",
        "colab_type": "code",
        "outputId": "76f4eb17-bade-4434-8932-f8f7c372cdf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "#@title Load dataset\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/mrch-hub/bangkit1/master/SolarPrediction.csv')\n",
        "data = data.reindex(np.random.permutation(data.index)) # shuffle dataset\n",
        "data.head(40)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UNIXTime</th>\n",
              "      <th>Data</th>\n",
              "      <th>Time</th>\n",
              "      <th>Radiation</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Pressure</th>\n",
              "      <th>Humidity</th>\n",
              "      <th>WindDirection(Degrees)</th>\n",
              "      <th>Speed</th>\n",
              "      <th>TimeSunRise</th>\n",
              "      <th>TimeSunSet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27247</th>\n",
              "      <td>1482445849</td>\n",
              "      <td>12/22/2016 12:00:00 AM</td>\n",
              "      <td>12:30:49</td>\n",
              "      <td>856.5</td>\n",
              "      <td>57</td>\n",
              "      <td>30.4</td>\n",
              "      <td>80</td>\n",
              "      <td>41.7</td>\n",
              "      <td>9.0</td>\n",
              "      <td>06:53:00</td>\n",
              "      <td>17:49:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28993</th>\n",
              "      <td>1481920518</td>\n",
              "      <td>12/16/2016 12:00:00 AM</td>\n",
              "      <td>10:35:18</td>\n",
              "      <td>752.2</td>\n",
              "      <td>52</td>\n",
              "      <td>30.3</td>\n",
              "      <td>61</td>\n",
              "      <td>9.1</td>\n",
              "      <td>3.4</td>\n",
              "      <td>06:50:00</td>\n",
              "      <td>17:46:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1127</th>\n",
              "      <td>1474878919</td>\n",
              "      <td>9/25/2016 12:00:00 AM</td>\n",
              "      <td>22:35:19</td>\n",
              "      <td>1.3</td>\n",
              "      <td>48</td>\n",
              "      <td>30.5</td>\n",
              "      <td>52</td>\n",
              "      <td>137.7</td>\n",
              "      <td>6.8</td>\n",
              "      <td>06:12:00</td>\n",
              "      <td>18:16:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13145</th>\n",
              "      <td>1476262522</td>\n",
              "      <td>10/11/2016 12:00:00 AM</td>\n",
              "      <td>22:55:22</td>\n",
              "      <td>1.2</td>\n",
              "      <td>51</td>\n",
              "      <td>30.5</td>\n",
              "      <td>83</td>\n",
              "      <td>168.9</td>\n",
              "      <td>5.6</td>\n",
              "      <td>06:16:00</td>\n",
              "      <td>18:03:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31349</th>\n",
              "      <td>1480987540</td>\n",
              "      <td>12/5/2016 12:00:00 AM</td>\n",
              "      <td>15:25:40</td>\n",
              "      <td>29.1</td>\n",
              "      <td>45</td>\n",
              "      <td>30.3</td>\n",
              "      <td>93</td>\n",
              "      <td>358.0</td>\n",
              "      <td>6.8</td>\n",
              "      <td>06:44:00</td>\n",
              "      <td>17:43:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14105</th>\n",
              "      <td>1475968224</td>\n",
              "      <td>10/8/2016 12:00:00 AM</td>\n",
              "      <td>13:10:24</td>\n",
              "      <td>840.2</td>\n",
              "      <td>63</td>\n",
              "      <td>30.4</td>\n",
              "      <td>69</td>\n",
              "      <td>359.9</td>\n",
              "      <td>5.6</td>\n",
              "      <td>06:15:00</td>\n",
              "      <td>18:05:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1361</th>\n",
              "      <td>1474808718</td>\n",
              "      <td>9/25/2016 12:00:00 AM</td>\n",
              "      <td>03:05:18</td>\n",
              "      <td>1.2</td>\n",
              "      <td>47</td>\n",
              "      <td>30.4</td>\n",
              "      <td>68</td>\n",
              "      <td>182.7</td>\n",
              "      <td>7.9</td>\n",
              "      <td>06:12:00</td>\n",
              "      <td>18:16:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15618</th>\n",
              "      <td>1475505322</td>\n",
              "      <td>10/3/2016 12:00:00 AM</td>\n",
              "      <td>04:35:22</td>\n",
              "      <td>1.2</td>\n",
              "      <td>49</td>\n",
              "      <td>30.4</td>\n",
              "      <td>95</td>\n",
              "      <td>157.5</td>\n",
              "      <td>6.8</td>\n",
              "      <td>06:14:00</td>\n",
              "      <td>18:09:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4352</th>\n",
              "      <td>1473817204</td>\n",
              "      <td>9/13/2016 12:00:00 AM</td>\n",
              "      <td>15:40:04</td>\n",
              "      <td>294.3</td>\n",
              "      <td>61</td>\n",
              "      <td>30.4</td>\n",
              "      <td>81</td>\n",
              "      <td>320.0</td>\n",
              "      <td>6.8</td>\n",
              "      <td>06:10:00</td>\n",
              "      <td>18:27:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12373</th>\n",
              "      <td>1476498623</td>\n",
              "      <td>10/14/2016 12:00:00 AM</td>\n",
              "      <td>16:30:23</td>\n",
              "      <td>360.6</td>\n",
              "      <td>62</td>\n",
              "      <td>30.4</td>\n",
              "      <td>51</td>\n",
              "      <td>75.8</td>\n",
              "      <td>9.0</td>\n",
              "      <td>06:17:00</td>\n",
              "      <td>18:00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         UNIXTime                    Data  ... TimeSunRise  TimeSunSet\n",
              "27247  1482445849  12/22/2016 12:00:00 AM  ...    06:53:00    17:49:00\n",
              "28993  1481920518  12/16/2016 12:00:00 AM  ...    06:50:00    17:46:00\n",
              "1127   1474878919   9/25/2016 12:00:00 AM  ...    06:12:00    18:16:00\n",
              "13145  1476262522  10/11/2016 12:00:00 AM  ...    06:16:00    18:03:00\n",
              "31349  1480987540   12/5/2016 12:00:00 AM  ...    06:44:00    17:43:00\n",
              "...           ...                     ...  ...         ...         ...\n",
              "14105  1475968224   10/8/2016 12:00:00 AM  ...    06:15:00    18:05:00\n",
              "1361   1474808718   9/25/2016 12:00:00 AM  ...    06:12:00    18:16:00\n",
              "15618  1475505322   10/3/2016 12:00:00 AM  ...    06:14:00    18:09:00\n",
              "4352   1473817204   9/13/2016 12:00:00 AM  ...    06:10:00    18:27:00\n",
              "12373  1476498623  10/14/2016 12:00:00 AM  ...    06:17:00    18:00:00\n",
              "\n",
              "[40 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c28PYOGaauV0",
        "colab_type": "text"
      },
      "source": [
        "##Adding some features to the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymGkD9ZPaxro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Adding feature is_daylight that define measurement time is either daylight (1) or nighttime (0)\n",
        "is_daylight = [data['Time'].values[x] > data['TimeSunRise'].values[x] and data['Time'].values[x] < data['TimeSunSet'].values[x] for x in range(len(data))]\n",
        "data['is_daylight'] = is_daylight\n",
        "data['is_daylight'] = data['is_daylight'].astype('float')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCCuKjCwBH1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Convert UNIXTime into hour, day, month format\n",
        "data['Time_Convert'] = pd.to_datetime(data['Time'], format = '%H:%M:%S')\n",
        "\n",
        "data['Hour'] = pd.to_datetime(data['Time_Convert'], format = '%H:%M:%S').dt.hour # Get the hour of the day\n",
        "\n",
        "data['Day'] = pd.to_datetime(data['UNIXTime'].astype(int), unit = 's').dt.day # Get the day of the month\n",
        "\n",
        "data['Month'] = pd.to_datetime(data['UNIXTime'].astype(int), unit = 's').dt.month # Get the month of the year"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQeavaKNayAj",
        "colab_type": "text"
      },
      "source": [
        "##Data Preconditioning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbKi6_Xcbn6M",
        "colab_type": "code",
        "outputId": "d2389610-2bf3-4a94-eaa0-0f77720f2b8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#@title Splitting data to train set and test set\n",
        "test_split = 0.2 # percentage of train set to be considered as test set\n",
        "data_test = data[:][0:round((len(data)*test_split))]\n",
        "data_train = data[:][round((len(data)*test_split)):]\n",
        "print('train set length:', str(len(data_train)), '\\ntest set length:', \n",
        "      str(len(data_test)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train set length: 26149 \n",
            "test set length: 6537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v5LYeP_dECa",
        "colab_type": "code",
        "outputId": "480c0c8f-e680-4bd1-b03e-161262346597",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title Normalize values \n",
        "\n",
        "# Calculate the Z-scores of each column in the training set:\n",
        "data_train_mean = data_train.select_dtypes(include=['float64', 'int64']).mean()\n",
        "data_train_std = data_train.select_dtypes(include=['float64', 'int64']).std()\n",
        "data_train_norm = (data_train.select_dtypes(include=['float64', 'int64']) \n",
        "                   - data_train_mean)/data_train_std\n",
        "\n",
        "# Calculate the Z-scores of each column in the test set.\n",
        "data_test_mean = data_test.select_dtypes(include=['float64', 'int64']).mean()\n",
        "data_test_std = data_test.select_dtypes(include=['float64', 'int64']).std()\n",
        "data_test_norm = (data_test.select_dtypes(include=['float64', 'int64'])\n",
        "                  - data_test_mean)/data_test_std\n",
        "\n",
        "print(\"Normalized the values.\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normalized the values.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKdhPgg5eRFI",
        "colab_type": "text"
      },
      "source": [
        "## Represent data\n",
        "\n",
        "The following code cell creates a feature layer containing three features:\n",
        "\n",
        "* `Temperature`\n",
        "* `Pressure`\n",
        "* `is_daylight`\n",
        "* `Day`\n",
        "* `Hour`\n",
        "* `Month`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bDp6l3KeEgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create empty feature column list\n",
        "feature_columns = []\n",
        "\n",
        "# Represent Temperature as a floating-point value.\n",
        "temperature = tf.feature_column.numeric_column(\"Temperature\")\n",
        "feature_columns.append(temperature)\n",
        "\n",
        "# Represent Pressure as a floating-point value.\n",
        "pressure = tf.feature_column.numeric_column(\"Pressure\")\n",
        "feature_columns.append(pressure)\n",
        "\n",
        "# Represent Daylight as a floating-point value.\n",
        "daylight = tf.feature_column.numeric_column(\"is_daylight\")\n",
        "feature_columns.append(daylight)\n",
        "\n",
        "# Represent Hour as a floating-point value.\n",
        "day = tf.feature_column.numeric_column(\"Day\")\n",
        "feature_columns.append(day)\n",
        "\n",
        "# Represent Hour as a floating-point value.\n",
        "hour = tf.feature_column.numeric_column(\"Hour\")\n",
        "feature_columns.append(hour)\n",
        "\n",
        "# Represent Hour as a floating-point value.\n",
        "month = tf.feature_column.numeric_column(\"Month\")\n",
        "feature_columns.append(month)\n",
        "\n",
        "# Convert the list of feature columns into a layer that will later be fed into\n",
        "# the model. \n",
        "my_feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMAji1PSfPCt",
        "colab_type": "text"
      },
      "source": [
        "## Build a linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyOjMo-7ei25",
        "colab_type": "code",
        "outputId": "5c0dc4bd-c7b5-4a79-a55b-63276f186edd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title Define plotting function\n",
        "\n",
        "def plot_the_loss_curve(epochs, mse_training, mse_validation):\n",
        "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Root Mean Squared Error\")\n",
        "\n",
        "  plt.plot(epochs[1:], mse_training[1:], label=\"Training Loss\")\n",
        "  plt.plot(epochs[1:], mse_validation[1:], label=\"Validation Loss\")\n",
        "  plt.legend()\n",
        "\n",
        "  merged_mse_lists = mse_training[1:] + mse_validation[1:]\n",
        "  highest_loss = max(merged_mse_lists)\n",
        "  lowest_loss = min(merged_mse_lists)\n",
        "  delta = highest_loss - lowest_loss\n",
        "  print(delta)\n",
        "\n",
        "  top_of_y_axis = highest_loss + (delta * 0.05)\n",
        "  bottom_of_y_axis = lowest_loss - (delta * 0.05)\n",
        "  plt.ylim([bottom_of_y_axis, top_of_y_axis])\n",
        "  plt.show()  \n",
        "\n",
        "print(\"Defined the plot_the_loss_curve function.\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defined the plot_the_loss_curve function.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEsYOPPhetG3",
        "colab_type": "code",
        "outputId": "4d750c5e-43ee-4e16-80d2-266b4d739bf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title Define functions to create and train a linear regression model\n",
        "def create_model(my_learning_rate, feature_layer):\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
        "  # Most simple tf.keras models are sequential.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # Add the layer containing the feature columns to the model.\n",
        "  model.add(feature_layer)\n",
        "\n",
        "  # Add one linear layer to the model to yield a simple linear regressor.\n",
        "  model.add(tf.keras.layers.Dense(units=1, input_shape=(1,)))\n",
        "\n",
        "  # Construct the layers into a model that TensorFlow can execute.\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  return model           \n",
        "\n",
        "\n",
        "def train_model(model, dataset, epochs, batch_size, label_name,validation_split):\n",
        "  \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
        "\n",
        "  # Split the dataset into features and label.\n",
        "  features = {name:np.array(value) for name, value in dataset.items()}\n",
        "  label = np.array(features.pop(label_name))\n",
        "  history = model.fit(x=features, y=label, batch_size=batch_size,\n",
        "                      epochs=epochs, validation_split=validation_split, \n",
        "                      shuffle=True)\n",
        "\n",
        "  # Get details that will be useful for plotting the loss curve.\n",
        "  epochs = history.epoch\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  rmse = hist[\"root_mean_squared_error\"]\n",
        "\n",
        "  return epochs, rmse, history.history   \n",
        "\n",
        "print(\"Defined the create_model and train_model functions.\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defined the create_model and train_model functions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAJuzbBmexB4",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "fe0cace7-b472-4db4-e1c5-6a1050990e18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#@title Train the model as linear regression\n",
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.01\n",
        "epochs = 50\n",
        "batch_size = 1000\n",
        "validation_split = 0.2\n",
        "label_name = \"Radiation\"\n",
        " \n",
        "\n",
        "# Establish the model's topography.\n",
        "my_model = create_model(learning_rate, my_feature_layer)\n",
        "\n",
        "# Train the model on the normalized training set.\n",
        "epochs, mse, history = train_model(my_model, data_train_norm, epochs, batch_size, label_name, \n",
        "                          validation_split=validation_split)\n",
        "plot_the_loss_curve(epochs, history[\"root_mean_squared_error\"], \n",
        "                    history[\"val_root_mean_squared_error\"])\n",
        "\n",
        "test_features = {name:np.array(value) for name, value in data_test_norm.items()}\n",
        "test_label = np.array(test_features.pop(label_name)) # isolate the label\n",
        "print(\"\\n Evaluate the linear regression model against the test set:\")\n",
        "my_model.evaluate(x = test_features, y = test_label, batch_size=batch_size)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 3.9909 - root_mean_squared_error: 1.9985 - val_loss: 3.0284 - val_root_mean_squared_error: 1.7359\n",
            "Epoch 2/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 2.4311 - root_mean_squared_error: 1.5597 - val_loss: 1.8931 - val_root_mean_squared_error: 1.3711\n",
            "Epoch 3/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 1.4919 - root_mean_squared_error: 1.2219 - val_loss: 1.1372 - val_root_mean_squared_error: 1.0617\n",
            "Epoch 4/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.8889 - root_mean_squared_error: 0.9432 - val_loss: 0.6810 - val_root_mean_squared_error: 0.8212\n",
            "Epoch 5/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.5444 - root_mean_squared_error: 0.7381 - val_loss: 0.4498 - val_root_mean_squared_error: 0.6674\n",
            "Epoch 6/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3924 - root_mean_squared_error: 0.6265 - val_loss: 0.3729 - val_root_mean_squared_error: 0.6082\n",
            "Epoch 7/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3533 - root_mean_squared_error: 0.5944 - val_loss: 0.3591 - val_root_mean_squared_error: 0.5966\n",
            "Epoch 8/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3455 - root_mean_squared_error: 0.5877 - val_loss: 0.3535 - val_root_mean_squared_error: 0.5922\n",
            "Epoch 9/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3438 - root_mean_squared_error: 0.5864 - val_loss: 0.3530 - val_root_mean_squared_error: 0.5915\n",
            "Epoch 10/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3437 - root_mean_squared_error: 0.5863 - val_loss: 0.3547 - val_root_mean_squared_error: 0.5923\n",
            "Epoch 11/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3438 - root_mean_squared_error: 0.5862 - val_loss: 0.3544 - val_root_mean_squared_error: 0.5923\n",
            "Epoch 12/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3440 - root_mean_squared_error: 0.5866 - val_loss: 0.3522 - val_root_mean_squared_error: 0.5910\n",
            "Epoch 13/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3439 - root_mean_squared_error: 0.5865 - val_loss: 0.3533 - val_root_mean_squared_error: 0.5917\n",
            "Epoch 14/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3440 - root_mean_squared_error: 0.5865 - val_loss: 0.3530 - val_root_mean_squared_error: 0.5914\n",
            "Epoch 15/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3441 - root_mean_squared_error: 0.5866 - val_loss: 0.3527 - val_root_mean_squared_error: 0.5911\n",
            "Epoch 16/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3440 - root_mean_squared_error: 0.5865 - val_loss: 0.3530 - val_root_mean_squared_error: 0.5919\n",
            "Epoch 17/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3440 - root_mean_squared_error: 0.5865 - val_loss: 0.3528 - val_root_mean_squared_error: 0.5911\n",
            "Epoch 18/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3441 - root_mean_squared_error: 0.5865 - val_loss: 0.3527 - val_root_mean_squared_error: 0.5915\n",
            "Epoch 19/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3439 - root_mean_squared_error: 0.5865 - val_loss: 0.3538 - val_root_mean_squared_error: 0.5917\n",
            "Epoch 20/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3441 - root_mean_squared_error: 0.5866 - val_loss: 0.3531 - val_root_mean_squared_error: 0.5916\n",
            "Epoch 21/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3441 - root_mean_squared_error: 0.5865 - val_loss: 0.3537 - val_root_mean_squared_error: 0.5921\n",
            "Epoch 22/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3439 - root_mean_squared_error: 0.5862 - val_loss: 0.3541 - val_root_mean_squared_error: 0.5925\n",
            "Epoch 23/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3439 - root_mean_squared_error: 0.5864 - val_loss: 0.3534 - val_root_mean_squared_error: 0.5917\n",
            "Epoch 24/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3443 - root_mean_squared_error: 0.5868 - val_loss: 0.3527 - val_root_mean_squared_error: 0.5916\n",
            "Epoch 25/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3437 - root_mean_squared_error: 0.5863 - val_loss: 0.3543 - val_root_mean_squared_error: 0.5923\n",
            "Epoch 26/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3440 - root_mean_squared_error: 0.5864 - val_loss: 0.3545 - val_root_mean_squared_error: 0.5934\n",
            "Epoch 27/50\n",
            "21/21 [==============================] - 0s 5ms/step - loss: 0.3440 - root_mean_squared_error: 0.5866 - val_loss: 0.3529 - val_root_mean_squared_error: 0.5913\n",
            "Epoch 28/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3438 - root_mean_squared_error: 0.5864 - val_loss: 0.3530 - val_root_mean_squared_error: 0.5912\n",
            "Epoch 29/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3437 - root_mean_squared_error: 0.5863 - val_loss: 0.3535 - val_root_mean_squared_error: 0.5917\n",
            "Epoch 30/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3438 - root_mean_squared_error: 0.5864 - val_loss: 0.3547 - val_root_mean_squared_error: 0.5925\n",
            "Epoch 31/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3436 - root_mean_squared_error: 0.5861 - val_loss: 0.3533 - val_root_mean_squared_error: 0.5923\n",
            "Epoch 32/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3441 - root_mean_squared_error: 0.5866 - val_loss: 0.3531 - val_root_mean_squared_error: 0.5915\n",
            "Epoch 33/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3438 - root_mean_squared_error: 0.5864 - val_loss: 0.3530 - val_root_mean_squared_error: 0.5914\n",
            "Epoch 34/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3443 - root_mean_squared_error: 0.5867 - val_loss: 0.3544 - val_root_mean_squared_error: 0.5923\n",
            "Epoch 35/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3437 - root_mean_squared_error: 0.5863 - val_loss: 0.3531 - val_root_mean_squared_error: 0.5914\n",
            "Epoch 36/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3441 - root_mean_squared_error: 0.5864 - val_loss: 0.3562 - val_root_mean_squared_error: 0.5936\n",
            "Epoch 37/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3446 - root_mean_squared_error: 0.5869 - val_loss: 0.3531 - val_root_mean_squared_error: 0.5913\n",
            "Epoch 38/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3437 - root_mean_squared_error: 0.5861 - val_loss: 0.3533 - val_root_mean_squared_error: 0.5920\n",
            "Epoch 39/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3439 - root_mean_squared_error: 0.5865 - val_loss: 0.3537 - val_root_mean_squared_error: 0.5924\n",
            "Epoch 40/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3436 - root_mean_squared_error: 0.5862 - val_loss: 0.3538 - val_root_mean_squared_error: 0.5920\n",
            "Epoch 41/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3440 - root_mean_squared_error: 0.5866 - val_loss: 0.3530 - val_root_mean_squared_error: 0.5913\n",
            "Epoch 42/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3436 - root_mean_squared_error: 0.5862 - val_loss: 0.3536 - val_root_mean_squared_error: 0.5922\n",
            "Epoch 43/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3445 - root_mean_squared_error: 0.5866 - val_loss: 0.3537 - val_root_mean_squared_error: 0.5923\n",
            "Epoch 44/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3439 - root_mean_squared_error: 0.5864 - val_loss: 0.3527 - val_root_mean_squared_error: 0.5914\n",
            "Epoch 45/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3438 - root_mean_squared_error: 0.5864 - val_loss: 0.3523 - val_root_mean_squared_error: 0.5911\n",
            "Epoch 46/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3442 - root_mean_squared_error: 0.5865 - val_loss: 0.3539 - val_root_mean_squared_error: 0.5920\n",
            "Epoch 47/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3438 - root_mean_squared_error: 0.5863 - val_loss: 0.3542 - val_root_mean_squared_error: 0.5922\n",
            "Epoch 48/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3440 - root_mean_squared_error: 0.5865 - val_loss: 0.3540 - val_root_mean_squared_error: 0.5920\n",
            "Epoch 49/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3437 - root_mean_squared_error: 0.5864 - val_loss: 0.3537 - val_root_mean_squared_error: 0.5918\n",
            "Epoch 50/50\n",
            "21/21 [==============================] - 0s 4ms/step - loss: 0.3439 - root_mean_squared_error: 0.5864 - val_loss: 0.3535 - val_root_mean_squared_error: 0.5915\n",
            "0.9735934138298035\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEJCAYAAACZjSCSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluate the linear regression model against the test set:\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.3442 - root_mean_squared_error: 0.5844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.344160258769989, 0.5844473242759705]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzIkZNjddP_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}