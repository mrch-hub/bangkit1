{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SolarPrediction.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrch-hub/bangkit1/blob/test_feature_3/SolarPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5bF6G8ff6Zq",
        "colab_type": "text"
      },
      "source": [
        "##Solar radiation intensity prediction using TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6pwJrUZ9rYW",
        "colab_type": "code",
        "outputId": "6a289da9-924b-4a89-fdb3-eb987e32fa59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\"\"\"A python code for predicting solar radiation\n",
        "intensity using TensorFlow. Created for \n",
        "5th Bangk!t assignment.\n",
        "Collaborators: Marcellinus Chrisnada, Muhammad\n",
        "Harits Hafidza, Mochammad Randy Caesario H.\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A python code for predicting solar radiation\\nintensity using TensorFlow. Created for \\n5th Bangk!t assignment.\\nCollaborators: Marcellinus Chrisnada, Muhammad\\nHarits Hafidza, Mochammad Randy Caesario H.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yb2tFywNgWIn",
        "colab_type": "text"
      },
      "source": [
        "##Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8ekWJYDbTzp",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Run on TensorFlow 2.x\n",
        "%tensorflow_version 2.x\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPY5vbLWXmKN",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "c6e03b2e-c759-4bc5-a900-930dc69efc56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title Import relevant modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Adjust the granularity of reporting. \n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "\n",
        "print(\"Imported modules.\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imported modules.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRlH8pQwbSpE",
        "colab_type": "code",
        "outputId": "9892a3db-f2b2-4a19-a5f6-71e3bf84d946",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "#@title Load dataset\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/mrch-hub/bangkit1/master/SolarPrediction.csv')\n",
        "data = data.reindex(np.random.permutation(data.index)) # shuffle dataset\n",
        "data = data.rename(columns={'WindDirection(Degrees)':'WindDirection'})\n",
        "data.head(15)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UNIXTime</th>\n",
              "      <th>Data</th>\n",
              "      <th>Time</th>\n",
              "      <th>Radiation</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Pressure</th>\n",
              "      <th>Humidity</th>\n",
              "      <th>WindDirection</th>\n",
              "      <th>Speed</th>\n",
              "      <th>TimeSunRise</th>\n",
              "      <th>TimeSunSet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20379</th>\n",
              "      <td>1479238505</td>\n",
              "      <td>11/15/2016 12:00:00 AM</td>\n",
              "      <td>09:35:05</td>\n",
              "      <td>297.9</td>\n",
              "      <td>53</td>\n",
              "      <td>30.5</td>\n",
              "      <td>91</td>\n",
              "      <td>47.0</td>\n",
              "      <td>5.6</td>\n",
              "      <td>06:31:00</td>\n",
              "      <td>17:43:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10305</th>\n",
              "      <td>1477125020</td>\n",
              "      <td>10/21/2016 12:00:00 AM</td>\n",
              "      <td>22:30:20</td>\n",
              "      <td>1.2</td>\n",
              "      <td>48</td>\n",
              "      <td>30.4</td>\n",
              "      <td>101</td>\n",
              "      <td>136.6</td>\n",
              "      <td>6.8</td>\n",
              "      <td>06:19:00</td>\n",
              "      <td>17:55:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24171</th>\n",
              "      <td>1478100019</td>\n",
              "      <td>11/2/2016 12:00:00 AM</td>\n",
              "      <td>05:20:19</td>\n",
              "      <td>1.2</td>\n",
              "      <td>41</td>\n",
              "      <td>30.4</td>\n",
              "      <td>62</td>\n",
              "      <td>184.5</td>\n",
              "      <td>7.9</td>\n",
              "      <td>06:24:00</td>\n",
              "      <td>17:48:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25812</th>\n",
              "      <td>1482876352</td>\n",
              "      <td>12/27/2016 12:00:00 AM</td>\n",
              "      <td>12:05:52</td>\n",
              "      <td>865.2</td>\n",
              "      <td>59</td>\n",
              "      <td>30.4</td>\n",
              "      <td>20</td>\n",
              "      <td>10.8</td>\n",
              "      <td>3.4</td>\n",
              "      <td>06:56:00</td>\n",
              "      <td>17:52:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11082</th>\n",
              "      <td>1476891918</td>\n",
              "      <td>10/19/2016 12:00:00 AM</td>\n",
              "      <td>05:45:18</td>\n",
              "      <td>1.2</td>\n",
              "      <td>49</td>\n",
              "      <td>30.4</td>\n",
              "      <td>100</td>\n",
              "      <td>177.2</td>\n",
              "      <td>6.8</td>\n",
              "      <td>06:19:00</td>\n",
              "      <td>17:56:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18679</th>\n",
              "      <td>1479749102</td>\n",
              "      <td>11/21/2016 12:00:00 AM</td>\n",
              "      <td>07:25:02</td>\n",
              "      <td>89.3</td>\n",
              "      <td>44</td>\n",
              "      <td>30.4</td>\n",
              "      <td>87</td>\n",
              "      <td>154.4</td>\n",
              "      <td>7.9</td>\n",
              "      <td>06:35:00</td>\n",
              "      <td>17:42:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16298</th>\n",
              "      <td>1480464301</td>\n",
              "      <td>11/29/2016 12:00:00 AM</td>\n",
              "      <td>14:05:01</td>\n",
              "      <td>309.1</td>\n",
              "      <td>49</td>\n",
              "      <td>30.4</td>\n",
              "      <td>95</td>\n",
              "      <td>70.4</td>\n",
              "      <td>11.2</td>\n",
              "      <td>06:40:00</td>\n",
              "      <td>17:42:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7032</th>\n",
              "      <td>1472852708</td>\n",
              "      <td>9/2/2016 12:00:00 AM</td>\n",
              "      <td>11:45:08</td>\n",
              "      <td>1046.7</td>\n",
              "      <td>64</td>\n",
              "      <td>30.5</td>\n",
              "      <td>50</td>\n",
              "      <td>146.7</td>\n",
              "      <td>5.6</td>\n",
              "      <td>06:07:00</td>\n",
              "      <td>18:37:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16321</th>\n",
              "      <td>1480457402</td>\n",
              "      <td>11/29/2016 12:00:00 AM</td>\n",
              "      <td>12:10:02</td>\n",
              "      <td>692.1</td>\n",
              "      <td>48</td>\n",
              "      <td>30.4</td>\n",
              "      <td>99</td>\n",
              "      <td>76.9</td>\n",
              "      <td>4.5</td>\n",
              "      <td>06:40:00</td>\n",
              "      <td>17:42:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10061</th>\n",
              "      <td>1477198517</td>\n",
              "      <td>10/22/2016 12:00:00 AM</td>\n",
              "      <td>18:55:17</td>\n",
              "      <td>1.2</td>\n",
              "      <td>47</td>\n",
              "      <td>30.4</td>\n",
              "      <td>97</td>\n",
              "      <td>123.6</td>\n",
              "      <td>10.1</td>\n",
              "      <td>06:20:00</td>\n",
              "      <td>17:54:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15 rows Ã— 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         UNIXTime                    Data  ... TimeSunRise  TimeSunSet\n",
              "20379  1479238505  11/15/2016 12:00:00 AM  ...    06:31:00    17:43:00\n",
              "10305  1477125020  10/21/2016 12:00:00 AM  ...    06:19:00    17:55:00\n",
              "24171  1478100019   11/2/2016 12:00:00 AM  ...    06:24:00    17:48:00\n",
              "25812  1482876352  12/27/2016 12:00:00 AM  ...    06:56:00    17:52:00\n",
              "11082  1476891918  10/19/2016 12:00:00 AM  ...    06:19:00    17:56:00\n",
              "...           ...                     ...  ...         ...         ...\n",
              "18679  1479749102  11/21/2016 12:00:00 AM  ...    06:35:00    17:42:00\n",
              "16298  1480464301  11/29/2016 12:00:00 AM  ...    06:40:00    17:42:00\n",
              "7032   1472852708    9/2/2016 12:00:00 AM  ...    06:07:00    18:37:00\n",
              "16321  1480457402  11/29/2016 12:00:00 AM  ...    06:40:00    17:42:00\n",
              "10061  1477198517  10/22/2016 12:00:00 AM  ...    06:20:00    17:54:00\n",
              "\n",
              "[15 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c28PYOGaauV0",
        "colab_type": "text"
      },
      "source": [
        "##Adding some features to the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymGkD9ZPaxro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Adding feature is_daylight that define measurement time is either daylight (1) or nighttime (0)\n",
        "is_daylight = [data['Time'].values[x] > data['TimeSunRise'].values[x] and data['Time'].values[x] < data['TimeSunSet'].values[x] for x in range(len(data))]\n",
        "data['is_daylight'] = is_daylight\n",
        "data['is_daylight'] = data['is_daylight'].astype('float')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCCuKjCwBH1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Convert UNIXTime into hour, day, month format\n",
        "data['Time_Convert'] = pd.to_datetime(data['Time'], format = '%H:%M:%S')\n",
        "\n",
        "data['Hour'] = pd.to_datetime(data['Time_Convert'], format = '%H:%M:%S').dt.hour # Get the hour of the day\n",
        "\n",
        "data['Day'] = pd.to_datetime(data['UNIXTime'].astype(int), unit = 's').dt.day # Get the day of the month\n",
        "\n",
        "data['Month'] = pd.to_datetime(data['UNIXTime'].astype(int), unit = 's').dt.month # Get the month of the year"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQeavaKNayAj",
        "colab_type": "text"
      },
      "source": [
        "##Data Preconditioning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbKi6_Xcbn6M",
        "colab_type": "code",
        "outputId": "41cbd747-0fea-4f3f-e7e0-02a42b001573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#@title Splitting data to train set and test set\n",
        "test_split = 0.2 # percentage of train set to be considered as test set\n",
        "data_test = data[:][0:round((len(data)*test_split))]\n",
        "data_train = data[:][round((len(data)*test_split)):]\n",
        "print('train set length:', str(len(data_train)), '\\ntest set length:', \n",
        "      str(len(data_test)))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train set length: 26149 \n",
            "test set length: 6537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v5LYeP_dECa",
        "colab_type": "code",
        "outputId": "62bb9532-43b8-4fda-db4e-0a57da0bb662",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title Normalize values \n",
        "\n",
        "# Calculate the Z-scores of each column in the training set:\n",
        "data_train_mean = data_train.select_dtypes(include=['float64', 'int64']).mean()\n",
        "data_train_std = data_train.select_dtypes(include=['float64', 'int64']).std()\n",
        "data_train_norm = (data_train.select_dtypes(include=['float64', 'int64']) \n",
        "                   - data_train_mean)/data_train_std\n",
        "\n",
        "# Calculate the Z-scores of each column in the test set.\n",
        "data_test_mean = data_test.select_dtypes(include=['float64', 'int64']).mean()\n",
        "data_test_std = data_test.select_dtypes(include=['float64', 'int64']).std()\n",
        "data_test_norm = (data_test.select_dtypes(include=['float64', 'int64'])\n",
        "                  - data_test_mean)/data_test_std\n",
        "\n",
        "print(\"Normalized the values.\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normalized the values.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKdhPgg5eRFI",
        "colab_type": "text"
      },
      "source": [
        "## Represent data\n",
        "\n",
        "The following code cell creates a feature layer containing 6 features:\n",
        "\n",
        "* `Temperature`\n",
        "* `Pressure`\n",
        "* `is_daylight`\n",
        "* `Humidity x Wind Cross Feature`\n",
        "* `Hour x Month Cross Feature`\n",
        "* `Day`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bDp6l3KeEgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create empty feature column list\n",
        "feature_columns = []\n",
        "\n",
        "# Represent Temperature as a floating-point value.\n",
        "temperature_numeric_column = tf.feature_column.numeric_column(\"Temperature\")\n",
        "feature_columns.append(temperature_numeric_column)\n",
        "\n",
        "# Represent Pressure as a floating-point value.\n",
        "pressure_numeric_column = tf.feature_column.numeric_column(\"Pressure\")\n",
        "feature_columns.append(pressure_numeric_column)\n",
        "\n",
        "# Represent Humidity as a floating-point value.\n",
        "humidity_numeric_column = tf.feature_column.numeric_column(\"Humidity\")\n",
        "humidity_boundaries = list(np.arange(int(min(data_train['Humidity'])), int(max(data_train['Humidity']))))\n",
        "humidity = tf.feature_column.bucketized_column(humidity_numeric_column, humidity_boundaries)\n",
        "\n",
        "# Represent Wind as a floating-point value.\n",
        "wind_numeric_column = tf.feature_column.numeric_column(\"WindDirection\")\n",
        "wind_boundaries = list(np.arange(int(min(data_train['WindDirection'])), int(max(data_train['WindDirection']))))\n",
        "wind = tf.feature_column.bucketized_column(wind_numeric_column, wind_boundaries)\n",
        "\n",
        "# Represent Daylight as a floating-point value.\n",
        "daylight = tf.feature_column.numeric_column(\"is_daylight\")\n",
        "feature_columns.append(daylight)\n",
        "\n",
        "# Represent Hour as a floating-point value.\n",
        "day_numeric_column = tf.feature_column.numeric_column(\"Day\")\n",
        "feature_columns.append(day_numeric_column)\n",
        "\n",
        "# Represent Hour as a floating-point value.\n",
        "hour_numeric_column = tf.feature_column.numeric_column(\"Hour\")\n",
        "hour_boundaries = list(np.arange(int(min(data_train['Hour'])), int(max(data_train['Hour']))))\n",
        "hour = tf.feature_column.bucketized_column(hour_numeric_column, hour_boundaries)\n",
        "\n",
        "# Represent Hour as a floating-point value.\n",
        "month_numeric_column = tf.feature_column.numeric_column(\"Month\")\n",
        "month_boundaries = list(np.arange(int(min(data_train['Month'])), int(max(data_train['Month']))))\n",
        "month = tf.feature_column.bucketized_column(month_numeric_column, month_boundaries)\n",
        "\n",
        "# Create a feature cross between Humidity and Wind\n",
        "humidity_x_wind = tf.feature_column.crossed_column([humidity, wind], hash_bucket_size=100)\n",
        "crossed_feature_HW = tf.feature_column.indicator_column(humidity_x_wind)\n",
        "feature_columns.append(crossed_feature_HW)\n",
        "\n",
        "# Create a feature cross between Hour and Month\n",
        "hour_x_month = tf.feature_column.crossed_column([hour, month], hash_bucket_size=100)\n",
        "crossed_feature_HM = tf.feature_column.indicator_column(hour_x_month)\n",
        "feature_columns.append(crossed_feature_HM)\n",
        "\n",
        "# Convert the list of feature columns into a layer that will later be fed into\n",
        "# the model. \n",
        "my_feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMAji1PSfPCt",
        "colab_type": "text"
      },
      "source": [
        "## Build a linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyOjMo-7ei25",
        "colab_type": "code",
        "outputId": "829ab3e5-7e51-4bf4-d951-13b0852885a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title Define plotting function|\n",
        "\n",
        "def plot_the_loss_curve(epochs, mse_training, mse_validation):\n",
        "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Root Mean Squared Error\")\n",
        "\n",
        "  plt.plot(epochs[1:], mse_training[1:], label=\"Training Loss\")\n",
        "  plt.plot(epochs[1:], mse_validation[1:], label=\"Validation Loss\")\n",
        "  plt.legend()\n",
        "\n",
        "  merged_mse_lists = mse_training[1:] + mse_validation[1:]\n",
        "  highest_loss = max(merged_mse_lists)\n",
        "  lowest_loss = min(merged_mse_lists)\n",
        "  delta = highest_loss - lowest_loss\n",
        "  print(delta)\n",
        "\n",
        "  top_of_y_axis = highest_loss + (delta * 0.05)\n",
        "  bottom_of_y_axis = lowest_loss - (delta * 0.05)\n",
        "  plt.ylim([bottom_of_y_axis, top_of_y_axis])\n",
        "  plt.show()  \n",
        "\n",
        "print(\"Defined the plot_the_loss_curve function.\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defined the plot_the_loss_curve function.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEsYOPPhetG3",
        "colab_type": "code",
        "outputId": "5136d1b9-898b-40e2-e2ba-2a61a7d4528a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title Define functions to create and train a linear regression model\n",
        "def create_model(my_learning_rate, feature_layer):\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
        "  # Most simple tf.keras models are sequential.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # Add the layer containing the feature columns to the model.\n",
        "  model.add(feature_layer)\n",
        "\n",
        "  # Add one linear layer to the model to yield a simple linear regressor.\n",
        "  model.add(tf.keras.layers.Dense(units=1, input_shape=(1,)))\n",
        "\n",
        "  # Construct the layers into a model that TensorFlow can execute.\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  return model           \n",
        "\n",
        "\n",
        "def train_model(model, dataset, epochs, batch_size, label_name,validation_split):\n",
        "  \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
        "\n",
        "  # Split the dataset into features and label.\n",
        "  features = {name:np.array(value) for name, value in dataset.items()}\n",
        "  label = np.array(features.pop(label_name))\n",
        "  history = model.fit(x=features, y=label, batch_size=batch_size,\n",
        "                      epochs=epochs, validation_split=validation_split, \n",
        "                      shuffle=True)\n",
        "\n",
        "  # Get details that will be useful for plotting the loss curve.\n",
        "  epochs = history.epoch\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  rmse = hist[\"root_mean_squared_error\"]\n",
        "\n",
        "  return epochs, rmse, history.history   \n",
        "\n",
        "print(\"Defined the create_model and train_model functions.\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defined the create_model and train_model functions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAJuzbBmexB4",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "809c8fb1-e1f6-4114-e42e-d725fa0d2fdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#@title Train the model as linear regression\n",
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.01\n",
        "epochs = 50\n",
        "batch_size = 1000\n",
        "validation_split = 0.2\n",
        "label_name = \"Radiation\"\n",
        " \n",
        "\n",
        "# Establish the model's topography.\n",
        "my_model = create_model(learning_rate, my_feature_layer)\n",
        "\n",
        "# Train the model on the normalized training set.\n",
        "epochs, mse, history = train_model(my_model, data_train_norm, epochs, batch_size, label_name, \n",
        "                          validation_split=validation_split)\n",
        "plot_the_loss_curve(epochs, history[\"root_mean_squared_error\"], \n",
        "                    history[\"val_root_mean_squared_error\"])\n",
        "\n",
        "test_features = {name:np.array(value) for name, value in data_test_norm.items()}\n",
        "test_label = np.array(test_features.pop(label_name)) # isolate the label\n",
        "print(\"\\n Evaluate the linear regression model against the test set:\")\n",
        "my_model.evaluate(x = test_features, y = test_label, batch_size=batch_size)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "WARNING:tensorflow:Layer dense_features_7 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "21/21 [==============================] - 0s 18ms/step - loss: 0.6430 - root_mean_squared_error: 0.8022 - val_loss: 0.4302 - val_root_mean_squared_error: 0.6584\n",
            "Epoch 2/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3997 - root_mean_squared_error: 0.6322 - val_loss: 0.3463 - val_root_mean_squared_error: 0.5919\n",
            "Epoch 3/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3506 - root_mean_squared_error: 0.5921 - val_loss: 0.3229 - val_root_mean_squared_error: 0.5719\n",
            "Epoch 4/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3400 - root_mean_squared_error: 0.5831 - val_loss: 0.3236 - val_root_mean_squared_error: 0.5723\n",
            "Epoch 5/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3390 - root_mean_squared_error: 0.5822 - val_loss: 0.3200 - val_root_mean_squared_error: 0.5690\n",
            "Epoch 6/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3390 - root_mean_squared_error: 0.5822 - val_loss: 0.3243 - val_root_mean_squared_error: 0.5729\n",
            "Epoch 7/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3395 - root_mean_squared_error: 0.5826 - val_loss: 0.3201 - val_root_mean_squared_error: 0.5694\n",
            "Epoch 8/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3389 - root_mean_squared_error: 0.5821 - val_loss: 0.3200 - val_root_mean_squared_error: 0.5693\n",
            "Epoch 9/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3392 - root_mean_squared_error: 0.5824 - val_loss: 0.3206 - val_root_mean_squared_error: 0.5697\n",
            "Epoch 10/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3394 - root_mean_squared_error: 0.5825 - val_loss: 0.3203 - val_root_mean_squared_error: 0.5694\n",
            "Epoch 11/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3391 - root_mean_squared_error: 0.5824 - val_loss: 0.3201 - val_root_mean_squared_error: 0.5691\n",
            "Epoch 12/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3395 - root_mean_squared_error: 0.5827 - val_loss: 0.3203 - val_root_mean_squared_error: 0.5695\n",
            "Epoch 13/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3392 - root_mean_squared_error: 0.5825 - val_loss: 0.3203 - val_root_mean_squared_error: 0.5694\n",
            "Epoch 14/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3395 - root_mean_squared_error: 0.5825 - val_loss: 0.3220 - val_root_mean_squared_error: 0.5709\n",
            "Epoch 15/50\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.3391 - root_mean_squared_error: 0.5823 - val_loss: 0.3207 - val_root_mean_squared_error: 0.5697\n",
            "Epoch 16/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3393 - root_mean_squared_error: 0.5825 - val_loss: 0.3202 - val_root_mean_squared_error: 0.5694\n",
            "Epoch 17/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3390 - root_mean_squared_error: 0.5823 - val_loss: 0.3219 - val_root_mean_squared_error: 0.5709\n",
            "Epoch 18/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3391 - root_mean_squared_error: 0.5823 - val_loss: 0.3197 - val_root_mean_squared_error: 0.5691\n",
            "Epoch 19/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3392 - root_mean_squared_error: 0.5825 - val_loss: 0.3205 - val_root_mean_squared_error: 0.5696\n",
            "Epoch 20/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3392 - root_mean_squared_error: 0.5824 - val_loss: 0.3202 - val_root_mean_squared_error: 0.5695\n",
            "Epoch 21/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3391 - root_mean_squared_error: 0.5824 - val_loss: 0.3216 - val_root_mean_squared_error: 0.5705\n",
            "Epoch 22/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3391 - root_mean_squared_error: 0.5823 - val_loss: 0.3228 - val_root_mean_squared_error: 0.5714\n",
            "Epoch 23/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3389 - root_mean_squared_error: 0.5822 - val_loss: 0.3202 - val_root_mean_squared_error: 0.5695\n",
            "Epoch 24/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3393 - root_mean_squared_error: 0.5825 - val_loss: 0.3211 - val_root_mean_squared_error: 0.5701\n",
            "Epoch 25/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3395 - root_mean_squared_error: 0.5826 - val_loss: 0.3210 - val_root_mean_squared_error: 0.5700\n",
            "Epoch 26/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3394 - root_mean_squared_error: 0.5826 - val_loss: 0.3220 - val_root_mean_squared_error: 0.5707\n",
            "Epoch 27/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3391 - root_mean_squared_error: 0.5823 - val_loss: 0.3200 - val_root_mean_squared_error: 0.5692\n",
            "Epoch 28/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3392 - root_mean_squared_error: 0.5823 - val_loss: 0.3225 - val_root_mean_squared_error: 0.5710\n",
            "Epoch 29/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3389 - root_mean_squared_error: 0.5823 - val_loss: 0.3203 - val_root_mean_squared_error: 0.5695\n",
            "Epoch 30/50\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.3392 - root_mean_squared_error: 0.5823 - val_loss: 0.3211 - val_root_mean_squared_error: 0.5701\n",
            "Epoch 31/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3392 - root_mean_squared_error: 0.5824 - val_loss: 0.3232 - val_root_mean_squared_error: 0.5720\n",
            "Epoch 32/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3394 - root_mean_squared_error: 0.5826 - val_loss: 0.3215 - val_root_mean_squared_error: 0.5705\n",
            "Epoch 33/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3391 - root_mean_squared_error: 0.5822 - val_loss: 0.3208 - val_root_mean_squared_error: 0.5696\n",
            "Epoch 34/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3393 - root_mean_squared_error: 0.5824 - val_loss: 0.3218 - val_root_mean_squared_error: 0.5707\n",
            "Epoch 35/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3393 - root_mean_squared_error: 0.5824 - val_loss: 0.3231 - val_root_mean_squared_error: 0.5718\n",
            "Epoch 36/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3391 - root_mean_squared_error: 0.5823 - val_loss: 0.3213 - val_root_mean_squared_error: 0.5704\n",
            "Epoch 37/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3393 - root_mean_squared_error: 0.5825 - val_loss: 0.3227 - val_root_mean_squared_error: 0.5716\n",
            "Epoch 38/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3389 - root_mean_squared_error: 0.5822 - val_loss: 0.3205 - val_root_mean_squared_error: 0.5694\n",
            "Epoch 39/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3396 - root_mean_squared_error: 0.5827 - val_loss: 0.3208 - val_root_mean_squared_error: 0.5697\n",
            "Epoch 40/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3388 - root_mean_squared_error: 0.5820 - val_loss: 0.3203 - val_root_mean_squared_error: 0.5694\n",
            "Epoch 41/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3394 - root_mean_squared_error: 0.5826 - val_loss: 0.3205 - val_root_mean_squared_error: 0.5695\n",
            "Epoch 42/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3394 - root_mean_squared_error: 0.5824 - val_loss: 0.3207 - val_root_mean_squared_error: 0.5698\n",
            "Epoch 43/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3392 - root_mean_squared_error: 0.5824 - val_loss: 0.3237 - val_root_mean_squared_error: 0.5723\n",
            "Epoch 44/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3394 - root_mean_squared_error: 0.5825 - val_loss: 0.3203 - val_root_mean_squared_error: 0.5693\n",
            "Epoch 45/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3391 - root_mean_squared_error: 0.5824 - val_loss: 0.3201 - val_root_mean_squared_error: 0.5692\n",
            "Epoch 46/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3394 - root_mean_squared_error: 0.5826 - val_loss: 0.3197 - val_root_mean_squared_error: 0.5690\n",
            "Epoch 47/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3397 - root_mean_squared_error: 0.5828 - val_loss: 0.3207 - val_root_mean_squared_error: 0.5698\n",
            "Epoch 48/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3391 - root_mean_squared_error: 0.5824 - val_loss: 0.3212 - val_root_mean_squared_error: 0.5702\n",
            "Epoch 49/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3391 - root_mean_squared_error: 0.5821 - val_loss: 0.3229 - val_root_mean_squared_error: 0.5717\n",
            "Epoch 50/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3392 - root_mean_squared_error: 0.5824 - val_loss: 0.3210 - val_root_mean_squared_error: 0.5701\n",
            "0.06320399045944214\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY4yJygKEMcaYqP4/28TPRfitv4AAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluate the linear regression model against the test set:\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3366 - root_mean_squared_error: 0.5813\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.33663082122802734, 0.5813210010528564]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzIkZNjddP_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}