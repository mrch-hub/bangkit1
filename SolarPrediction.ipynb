{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SolarPrediction.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrch-hub/bangkit1/blob/master/SolarPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5bF6G8ff6Zq",
        "colab_type": "text"
      },
      "source": [
        "##Solar radiation intensity prediction using TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6pwJrUZ9rYW",
        "colab_type": "code",
        "outputId": "8eb7d43b-8719-4b88-81c0-7b3cb70b6847",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"A python code for predicting solar radiation\n",
        "intensity using TensorFlow. Created for \n",
        "5th Bangk!t assignment.\n",
        "Collaborators: Marcellinus Chrisnada, Muhammad\n",
        "Harits Hafidza, Mochammad Randy Caesario H.\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A python code for predicting solar radiation\\nintensity using machine learning. Created for \\n5th bangk!t assignment.\\nCollaborators: Marcellinus Chrisnada, Muhammad\\nHarits Hafidza, Mochammad Randy Caesario H.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yb2tFywNgWIn",
        "colab_type": "text"
      },
      "source": [
        "##Initialization and Data Preconditioning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8ekWJYDbTzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Run on TensorFlow 2.x\n",
        "%tensorflow_version 2.x\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPY5vbLWXmKN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "cellView": "both",
        "outputId": "b4ee9930-9df6-4601-d83d-9855834b0db3"
      },
      "source": [
        "#@title Import relevant modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Adjust the granularity of reporting. \n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "\n",
        "print(\"Imported modules.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 59\n",
            "Imported modules.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRlH8pQwbSpE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "66c2b387-08d9-4a95-ae17-44d92901c76b"
      },
      "source": [
        "#@title Load dataset\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/mrch-hub/bangkit1/master/SolarPrediction.csv')\n",
        "data = data.reindex(np.random.permutation(data.index)) # shuffle dataset\n",
        "data.head(40)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UNIXTime</th>\n",
              "      <th>Data</th>\n",
              "      <th>Time</th>\n",
              "      <th>Radiation</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Pressure</th>\n",
              "      <th>Humidity</th>\n",
              "      <th>WindDirection(Degrees)</th>\n",
              "      <th>Speed</th>\n",
              "      <th>TimeSunRise</th>\n",
              "      <th>TimeSunSet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22703</th>\n",
              "      <td>1478541303</td>\n",
              "      <td>11/7/2016 12:00:00 AM</td>\n",
              "      <td>07:55:03</td>\n",
              "      <td>330.8</td>\n",
              "      <td>55</td>\n",
              "      <td>30.5</td>\n",
              "      <td>16</td>\n",
              "      <td>275.4</td>\n",
              "      <td>4.5</td>\n",
              "      <td>06:27:00</td>\n",
              "      <td>17:46:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10661</th>\n",
              "      <td>1477018220</td>\n",
              "      <td>10/20/2016 12:00:00 AM</td>\n",
              "      <td>16:50:20</td>\n",
              "      <td>226.7</td>\n",
              "      <td>52</td>\n",
              "      <td>30.4</td>\n",
              "      <td>85</td>\n",
              "      <td>34.8</td>\n",
              "      <td>4.5</td>\n",
              "      <td>06:19:00</td>\n",
              "      <td>17:56:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31561</th>\n",
              "      <td>1480923633</td>\n",
              "      <td>12/4/2016 12:00:00 AM</td>\n",
              "      <td>21:40:33</td>\n",
              "      <td>1.2</td>\n",
              "      <td>45</td>\n",
              "      <td>30.4</td>\n",
              "      <td>93</td>\n",
              "      <td>51.3</td>\n",
              "      <td>3.4</td>\n",
              "      <td>06:43:00</td>\n",
              "      <td>17:43:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>1474226706</td>\n",
              "      <td>9/18/2016 12:00:00 AM</td>\n",
              "      <td>09:25:06</td>\n",
              "      <td>748.5</td>\n",
              "      <td>63</td>\n",
              "      <td>30.5</td>\n",
              "      <td>58</td>\n",
              "      <td>58.7</td>\n",
              "      <td>6.8</td>\n",
              "      <td>06:11:00</td>\n",
              "      <td>18:23:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13669</th>\n",
              "      <td>1476103524</td>\n",
              "      <td>10/10/2016 12:00:00 AM</td>\n",
              "      <td>02:45:24</td>\n",
              "      <td>1.3</td>\n",
              "      <td>49</td>\n",
              "      <td>30.4</td>\n",
              "      <td>81</td>\n",
              "      <td>199.6</td>\n",
              "      <td>9.0</td>\n",
              "      <td>06:16:00</td>\n",
              "      <td>18:03:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20568</th>\n",
              "      <td>1479181801</td>\n",
              "      <td>11/14/2016 12:00:00 AM</td>\n",
              "      <td>17:50:01</td>\n",
              "      <td>1.9</td>\n",
              "      <td>51</td>\n",
              "      <td>30.4</td>\n",
              "      <td>100</td>\n",
              "      <td>128.5</td>\n",
              "      <td>2.2</td>\n",
              "      <td>06:31:00</td>\n",
              "      <td>17:43:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7107</th>\n",
              "      <td>1472829906</td>\n",
              "      <td>9/2/2016 12:00:00 AM</td>\n",
              "      <td>05:25:06</td>\n",
              "      <td>2.5</td>\n",
              "      <td>47</td>\n",
              "      <td>30.4</td>\n",
              "      <td>72</td>\n",
              "      <td>148.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>06:07:00</td>\n",
              "      <td>18:37:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15227</th>\n",
              "      <td>1475625618</td>\n",
              "      <td>10/4/2016 12:00:00 AM</td>\n",
              "      <td>14:00:18</td>\n",
              "      <td>171.7</td>\n",
              "      <td>55</td>\n",
              "      <td>30.4</td>\n",
              "      <td>102</td>\n",
              "      <td>45.3</td>\n",
              "      <td>4.5</td>\n",
              "      <td>06:14:00</td>\n",
              "      <td>18:08:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9279</th>\n",
              "      <td>1477434318</td>\n",
              "      <td>10/25/2016 12:00:00 AM</td>\n",
              "      <td>12:25:18</td>\n",
              "      <td>956.1</td>\n",
              "      <td>64</td>\n",
              "      <td>30.5</td>\n",
              "      <td>63</td>\n",
              "      <td>3.1</td>\n",
              "      <td>2.2</td>\n",
              "      <td>06:21:00</td>\n",
              "      <td>17:52:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22567</th>\n",
              "      <td>1478582102</td>\n",
              "      <td>11/7/2016 12:00:00 AM</td>\n",
              "      <td>19:15:02</td>\n",
              "      <td>1.2</td>\n",
              "      <td>48</td>\n",
              "      <td>30.4</td>\n",
              "      <td>71</td>\n",
              "      <td>190.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>06:27:00</td>\n",
              "      <td>17:46:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         UNIXTime                    Data  ... TimeSunRise  TimeSunSet\n",
              "22703  1478541303   11/7/2016 12:00:00 AM  ...    06:27:00    17:46:00\n",
              "10661  1477018220  10/20/2016 12:00:00 AM  ...    06:19:00    17:56:00\n",
              "31561  1480923633   12/4/2016 12:00:00 AM  ...    06:43:00    17:43:00\n",
              "3258   1474226706   9/18/2016 12:00:00 AM  ...    06:11:00    18:23:00\n",
              "13669  1476103524  10/10/2016 12:00:00 AM  ...    06:16:00    18:03:00\n",
              "...           ...                     ...  ...         ...         ...\n",
              "20568  1479181801  11/14/2016 12:00:00 AM  ...    06:31:00    17:43:00\n",
              "7107   1472829906    9/2/2016 12:00:00 AM  ...    06:07:00    18:37:00\n",
              "15227  1475625618   10/4/2016 12:00:00 AM  ...    06:14:00    18:08:00\n",
              "9279   1477434318  10/25/2016 12:00:00 AM  ...    06:21:00    17:52:00\n",
              "22567  1478582102   11/7/2016 12:00:00 AM  ...    06:27:00    17:46:00\n",
              "\n",
              "[40 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbKi6_Xcbn6M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "7c66bbb4-ffd8-4ade-e579-2e0de7122de1"
      },
      "source": [
        "#@title Splitting data to train set and test set\n",
        "test_split = 0.2 # percentage of train set to be considered as test set\n",
        "data_test = data[:][0:round((len(data)*test_split))]\n",
        "data_train = data[:][round((len(data)*test_split)):]\n",
        "print('train set length:', str(len(data_train)), '\\ntest set length:', \n",
        "      str(len(data_test)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train set length: 26149 \n",
            "test set length: 6537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v5LYeP_dECa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "9a75c7f9-e238-44f1-a39b-4a25e014ad80"
      },
      "source": [
        "#@title Normalize values \n",
        "\n",
        "# Calculate the Z-scores of each column in the training set:\n",
        "data_train_mean = data_train[['UNIXTime', 'Radiation', 'Temperature', 'Pressure', \n",
        "                              'Humidity', 'WindDirection(Degrees)', 'Speed']].mean()\n",
        "data_train_std = data_train[['UNIXTime', 'Radiation', 'Temperature', 'Pressure', \n",
        "                             'Humidity', 'WindDirection(Degrees)', 'Speed']].std()\n",
        "data_train_norm = (data_train[['UNIXTime', 'Radiation', 'Temperature', 'Pressure', \n",
        "                               'Humidity', 'WindDirection(Degrees)', 'Speed']] \n",
        "                   - data_train_mean)/data_train_std\n",
        "\n",
        "# Calculate the Z-scores of each column in the test set.\n",
        "data_test_mean = data_test[['UNIXTime', 'Radiation', 'Temperature', 'Pressure', \n",
        "                            'Humidity', 'WindDirection(Degrees)', 'Speed']].mean()\n",
        "data_test_std = data_test[['UNIXTime', 'Radiation', 'Temperature', 'Pressure', \n",
        "                           'Humidity', 'WindDirection(Degrees)', 'Speed']].std()\n",
        "data_test_norm = (data_test[['UNIXTime', 'Radiation', 'Temperature', 'Pressure', \n",
        "                             'Humidity', 'WindDirection(Degrees)', 'Speed']] \n",
        "                  - data_test_mean)/data_test_std\n",
        "\n",
        "print(\"Normalized the values.\")\n",
        "data_train_norm.describe()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normalized the values.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UNIXTime</th>\n",
              "      <th>Radiation</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Pressure</th>\n",
              "      <th>Humidity</th>\n",
              "      <th>WindDirection(Degrees)</th>\n",
              "      <th>Speed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>26149.0</td>\n",
              "      <td>26149.0</td>\n",
              "      <td>26149.0</td>\n",
              "      <td>26149.0</td>\n",
              "      <td>26149.0</td>\n",
              "      <td>26149.0</td>\n",
              "      <td>26149.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.8</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-2.6</td>\n",
              "      <td>-4.3</td>\n",
              "      <td>-2.5</td>\n",
              "      <td>-1.7</td>\n",
              "      <td>-1.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.8</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.8</td>\n",
              "      <td>-0.4</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.7</td>\n",
              "      <td>-0.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-0.0</td>\n",
              "      <td>-0.6</td>\n",
              "      <td>-0.2</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.8</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.7</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.7</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.2</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1.1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>9.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       UNIXTime  Radiation  ...  WindDirection(Degrees)   Speed\n",
              "count   26149.0    26149.0  ...                 26149.0 26149.0\n",
              "mean       -0.0       -0.0  ...                     0.0     0.0\n",
              "std         1.0        1.0  ...                     1.0     1.0\n",
              "min        -1.8       -0.7  ...                    -1.7    -1.8\n",
              "25%        -0.8       -0.7  ...                    -0.7    -0.8\n",
              "50%        -0.0       -0.6  ...                     0.0    -0.2\n",
              "75%         0.8        0.5  ...                     0.4     0.5\n",
              "max         1.7        4.0  ...                     2.6     9.8\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKdhPgg5eRFI",
        "colab_type": "text"
      },
      "source": [
        "## Represent data\n",
        "\n",
        "The following code cell creates a feature layer containing two features:\n",
        "\n",
        "* `Temperature`\n",
        "* `Pressure`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bDp6l3KeEgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create empty feature column list\n",
        "feature_columns = []\n",
        "\n",
        "# Represent temperature as a floating-point value.\n",
        "temperature = tf.feature_column.numeric_column(\"Temperature\")\n",
        "feature_columns.append(temperature)\n",
        "\n",
        "# Represent pressure as a floating-point value.\n",
        "pressure = tf.feature_column.numeric_column(\"Pressure\")\n",
        "feature_columns.append(pressure)\n",
        "\n",
        "# Convert the list of feature columns into a layer that will later be fed into\n",
        "# the model. \n",
        "my_feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMAji1PSfPCt",
        "colab_type": "text"
      },
      "source": [
        "## Build a linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyOjMo-7ei25",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "89dd0525-e1a5-4b51-8a7d-b5a10d5d3e27"
      },
      "source": [
        "#@title Define plotting function\n",
        "\n",
        "def plot_the_loss_curve(epochs, mse):\n",
        "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Mean Squared Error\")\n",
        "\n",
        "  plt.plot(epochs, mse, label=\"Loss\")\n",
        "  plt.legend()\n",
        "  plt.ylim([mse.min()*0.95, mse.max() * 1.03])\n",
        "  plt.show()  \n",
        "\n",
        "print(\"Defined the plot_the_loss_curve function.\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defined the plot_the_loss_curve function.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEsYOPPhetG3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e6520a3b-aeb4-4332-d358-846d36cb4349"
      },
      "source": [
        "#@title Define functions to create and train a linear regression model\n",
        "def create_model(my_learning_rate, feature_layer):\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
        "  # Most simple tf.keras models are sequential.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # Add the layer containing the feature columns to the model.\n",
        "  model.add(feature_layer)\n",
        "\n",
        "  # Add one linear layer to the model to yield a simple linear regressor.\n",
        "  model.add(tf.keras.layers.Dense(units=1, input_shape=(1,)))\n",
        "\n",
        "  # Construct the layers into a model that TensorFlow can execute.\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[tf.keras.metrics.MeanSquaredError()])\n",
        "\n",
        "  return model           \n",
        "\n",
        "\n",
        "def train_model(model, dataset, epochs, batch_size, label_name):\n",
        "  \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
        "\n",
        "  # Split the dataset into features and label.\n",
        "  features = {name:np.array(value) for name, value in dataset.items()}\n",
        "  label = np.array(features.pop(label_name))\n",
        "  history = model.fit(x=features, y=label, batch_size=batch_size,\n",
        "                      epochs=epochs, shuffle=True)\n",
        "\n",
        "  # Get details that will be useful for plotting the loss curve.\n",
        "  epochs = history.epoch\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  rmse = hist[\"mean_squared_error\"]\n",
        "\n",
        "  return epochs, rmse   \n",
        "\n",
        "print(\"Defined the create_model and train_model functions.\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defined the create_model and train_model functions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAJuzbBmexB4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "cellView": "both",
        "outputId": "f2bd3450-fa4d-4f58-9578-309a94ea42cd"
      },
      "source": [
        "#@title Train the model as linear regression\n",
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.01\n",
        "epochs = 50\n",
        "batch_size = 1000\n",
        "label_name = \"Radiation\"\n",
        "\n",
        "# Establish the model's topography.\n",
        "my_model = create_model(learning_rate, my_feature_layer)\n",
        "\n",
        "# Train the model on the normalized training set.\n",
        "epochs, mse = train_model(my_model, data_train_norm, epochs, batch_size, label_name)\n",
        "plot_the_loss_curve(epochs, mse)\n",
        "\n",
        "test_features = {name:np.array(value) for name, value in data_test_norm.items()}\n",
        "test_label = np.array(test_features.pop(label_name)) # isolate the label\n",
        "print(\"\\n Evaluate the linear regression model against the test set:\")\n",
        "my_model.evaluate(x = test_features, y = test_label, batch_size=batch_size)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4977 - mean_squared_error: 0.5009\n",
            "Epoch 2/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4495 - mean_squared_error: 0.4499\n",
            "Epoch 3/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4480 - mean_squared_error: 0.4469\n",
            "Epoch 4/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4481 - mean_squared_error: 0.4472\n",
            "Epoch 5/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4447 - mean_squared_error: 0.4472\n",
            "Epoch 6/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4470 - mean_squared_error: 0.4473\n",
            "Epoch 7/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4501 - mean_squared_error: 0.4471\n",
            "Epoch 8/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4448 - mean_squared_error: 0.4473\n",
            "Epoch 9/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4513 - mean_squared_error: 0.4473\n",
            "Epoch 10/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4476 - mean_squared_error: 0.4471\n",
            "Epoch 11/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4477 - mean_squared_error: 0.4471\n",
            "Epoch 12/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4474 - mean_squared_error: 0.4472\n",
            "Epoch 13/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4473 - mean_squared_error: 0.4473\n",
            "Epoch 14/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4454 - mean_squared_error: 0.4472\n",
            "Epoch 15/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4488 - mean_squared_error: 0.4475\n",
            "Epoch 16/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4455 - mean_squared_error: 0.4471\n",
            "Epoch 17/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4464 - mean_squared_error: 0.4472\n",
            "Epoch 18/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4475 - mean_squared_error: 0.4472\n",
            "Epoch 19/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4471 - mean_squared_error: 0.4472\n",
            "Epoch 20/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4467 - mean_squared_error: 0.4471\n",
            "Epoch 21/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4465 - mean_squared_error: 0.4472\n",
            "Epoch 22/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4494 - mean_squared_error: 0.4473\n",
            "Epoch 23/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4433 - mean_squared_error: 0.4470\n",
            "Epoch 24/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4470 - mean_squared_error: 0.4472\n",
            "Epoch 25/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4457 - mean_squared_error: 0.4472\n",
            "Epoch 26/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4468 - mean_squared_error: 0.4472\n",
            "Epoch 27/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4486 - mean_squared_error: 0.4471\n",
            "Epoch 28/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4463 - mean_squared_error: 0.4473\n",
            "Epoch 29/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4472 - mean_squared_error: 0.4474\n",
            "Epoch 30/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4458 - mean_squared_error: 0.4472\n",
            "Epoch 31/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4487 - mean_squared_error: 0.4470\n",
            "Epoch 32/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4438 - mean_squared_error: 0.4474\n",
            "Epoch 33/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4485 - mean_squared_error: 0.4472\n",
            "Epoch 34/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4487 - mean_squared_error: 0.4475\n",
            "Epoch 35/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4453 - mean_squared_error: 0.4472\n",
            "Epoch 36/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4469 - mean_squared_error: 0.4471\n",
            "Epoch 37/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4476 - mean_squared_error: 0.4470\n",
            "Epoch 38/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4465 - mean_squared_error: 0.4473\n",
            "Epoch 39/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4483 - mean_squared_error: 0.4472\n",
            "Epoch 40/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4471 - mean_squared_error: 0.4472\n",
            "Epoch 41/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4477 - mean_squared_error: 0.4472\n",
            "Epoch 42/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4479 - mean_squared_error: 0.4471\n",
            "Epoch 43/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4481 - mean_squared_error: 0.4472\n",
            "Epoch 44/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4488 - mean_squared_error: 0.4471\n",
            "Epoch 45/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4469 - mean_squared_error: 0.4473\n",
            "Epoch 46/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4481 - mean_squared_error: 0.4472\n",
            "Epoch 47/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4443 - mean_squared_error: 0.4473\n",
            "Epoch 48/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4482 - mean_squared_error: 0.4471\n",
            "Epoch 49/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4503 - mean_squared_error: 0.4472\n",
            "Epoch 50/50\n",
            "27/27 [==============================] - 0s 1ms/step - loss: 0.4482 - mean_squared_error: 0.4471\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dfZRkdX3n8fenHru7uueBeQBkSGZU\nPCzoZDQjIcIu6okG1KCJJqKYkKw5JlmN5KgRzEYUiInkGHUhJGeJK0s060PcuDsGIrLIg66KDIoi\nT+vwoAwCM8xTT3dPd3VVffePe6u7prnd1Mx0dfV0fV7n1Kl7f/X0vd237rd+v9+9v58iAjMzs5ly\n3Q7AzMwWJycIMzPL5ARhZmaZnCDMzCyTE4SZmWUqdDuA+bJ69epYv359t8MwMzuq3HXXXU9HxJqs\nx5ZMgli/fj1bt27tdhhmZkcVST+Z7TE3MZmZWSYnCDMzy+QEYWZmmZZMH4SZ2eGanJxk+/btjI+P\ndzuUjunr62PdunUUi8W2X+MEYWY9b/v27QwNDbF+/XokdTuceRcR7Nq1i+3bt7Nhw4a2X+cmJjPr\neePj46xatWpJJgcASaxateqQa0hOEGZmsGSTQ9PhbJ8ThJmZZXKCMDNbBAYHB7sdwjM4QZiZWSYn\nCDOzReruu+/m9NNPZ+PGjfz6r/86e/bsAeDKK6/klFNOYePGjZx33nkA3HbbbWzatIlNmzbx4he/\nmP379x/x5/s0VzOzFpd+5V7u+9nwvL7nKc9Zxod+7dRDft3v/M7vcNVVV3HWWWdxySWXcOmll/LJ\nT36Sj370ozzyyCOUy2X27t0LwMc+9jGuvvpqzjjjDEZGRujr6zviuF2DMDNbhPbt28fevXs566yz\nALjgggu4/fbbAdi4cSPnn38+n/3sZykUkt/5Z5xxBu95z3u48sor2bt371T5kXANwsysxeH80l9o\n119/Pbfffjtf+cpX+MhHPsI999zDxRdfzGtf+1puuOEGzjjjDG688UZOPvnkI/oc1yDMzBah5cuX\ns3LlSr7xjW8A8JnPfIazzjqLRqPBY489xite8QquuOIK9u3bx8jICA899BAvetGLuOiii3jpS1/K\nAw88cMQxuAZhZrYIjI2NsW7duqn197znPVx33XX84R/+IWNjYzz3uc/l2muvpV6v87a3vY19+/YR\nEbz73e9mxYoVfPCDH+SWW24hl8tx6qmncs455xxxTE4QZmaLQKPRyCz/zne+84yyb37zm88ou+qq\nq+Y9JjcxmZlZJicIMzPL5ARhZkYyJPZSdjjb5wRhZj2vr6+PXbt2Ldkk0ZwP4lAvnnMntZn1vHXr\n1rF9+3Z27tzZ7VA6pjmj3KFwgjCznlcsFg9pprVe4SYmMzPL5ARhZmaZnCDMzCyTE4SZmWVygjAz\ns0xOEGZmlskJwszMMjlBmJlZJicIMzPL5ARhZmaZOpogJJ0t6UFJ2yRdnPH470raKenu9Pb7LY9d\nIOnH6e2CTsX4011jfOBffsiDT+7v1EeYmR2VOpYgJOWBq4FzgFOAt0g6JeOpX4iITentU+lrjwE+\nBPwScBrwIUkrOxHn8Pgkn/vuYzy6a7QTb29mdtTqZA3iNGBbRDwcEVXg88Dr23ztrwI3RcTuiNgD\n3ASc3YkgK+VkvMLRiVon3t7M7KjVyQRxAvBYy/r2tGymN0r6oaQvSTrxUF4r6R2StkraerjD9FbK\necAJwsxspm53Un8FWB8RG0lqCdcdyosj4pqI2BwRm9esWXNYAQymNYiRifphvd7MbKnqZIJ4HDix\nZX1dWjYlInZFxES6+ingF9t97XzpL+bJyTUIM7OZOpkg7gROkrRBUgk4D9jS+gRJx7esngvcny7f\nCLxa0sq0c/rVadm8k0SlVGDECcLM7CAdm1EuImqS3kVyYM8Dn46IeyVdBmyNiC3AuyWdC9SA3cDv\npq/dLelykiQDcFlE7O5UrJVywTUIM7MZOjrlaETcANwwo+ySluUPAB+Y5bWfBj7dyfiaBvsKjFad\nIMzMWnW7k3pRqJQL7B93gjAza+UEAQyW825iMjObwQkCqJQKjPo0VzOzgzhBkFwL4bOYzMwO5gRB\nehaTO6nNzA7iBIFPczUzy+IEQdJJPVkPJmruhzAza3KCoHVEVycIM7MmJwg85LeZWRYnCGBoakRX\nJwgzsyYnCFyDMDPL4gTBdILY7wRhZjbFCYLpSYNcgzAzm+YEgacdNTPL4gSBpx01M8viBIE7qc3M\nsjhBAMV8jlIh5wRhZtZizgQhKSfpZQsVTDd5RFczs4PNmSAiogFcvUCxdFXFkwaZmR2knSammyW9\nUZI6Hk0XVUoFd1KbmbVoJ0H8AfDPQFXSsKT9koY7HNeCG+rzkN9mZq0Kz/aEiBhaiEC6rVIusHu0\n2u0wzMwWjWdNEACSzgX+Q7p6a0T8a+dC6o5KucBPd411Owwzs0XjWZuYJH0UuBC4L71dKOmvOh3Y\nQhss+SwmM7NW7dQgXgNsSs9oQtJ1wPeBD3QysIXmaUfNzA7W7oVyK1qWl3cikG4bLOcZrdZpNKLb\noZiZLQrt1CD+Evi+pFsAkfRFXNzRqLqgOdzG2GR9amwmM7NeNueRUFIOaACnAy9Niy+KiCc7HdhC\nax2PyQnCzOxZEkRENCS9PyK+CGxZoJi6YrBl2tFjuxyLmdli0E4fxP+R9D5JJ0o6pnnreGQLzCO6\nmpkdrJ22lDen9+9sKQvgufMfTve01iDMzKy9PoiLI+ILCxRP10xPO+rxmMzMoL3RXP90gWLpKk87\namZ2MPdBpJo1iP1OEGZmgPsgpriT2szsYO2M5rphIQLptoFSHskJwsysadYmJknvb1n+zRmP/WUn\ng+oGSemkQU4QZmYwdx/EeS3LMwfmO7sDsXSdpx01M5s2V4LQLMtZ60tCMqKrT3M1M4O5E0TMspy1\nnknS2ZIelLRN0qwD/KVzXoekzel6UdJ1ku6RdL+kBRlafLDsJiYzs6a5Oql/IZ17WkB/yzzUAvqe\n7Y0l5YGrgVcB24E7JW2JiPtmPG+IZEKiO1qKfxMoR8SLJA0A90n6XEQ82uZ2HZZKyXNCmJk1zVqD\niIh8RCyLiKGIKKTLzfViG+99GrAtIh6OiCrweeD1Gc+7HLgCGG/9eKAiqQD0A1VgOOO182qwzzUI\nM7OmdicMOhwnAI+1rG9Py6ZIeglwYkRcP+O1XwJGgSeAnwIfi4jdMz9A0jskbZW0defOnUcc8GC5\nwGjVCcLMDDqbIOaUjvP0ceC9GQ+fBtSB5wAbgPdKesaFeRFxTURsjojNa9asOeKYkrOY3EltZgbt\nXUl9uB4HTmxZX5eWNQ0BLwRulQRwHLBF0rnAW4GvRsQksEPS/wU2Aw93MF4q5QIj465BmJlBZ2sQ\ndwInSdogqURyXcXUpEMRsS8iVkfE+ohYD3wHODcitpI0K70SQFKFZEa7BzoYKwCDpQLVeoNqrdHp\njzIzW/RmrUFI2s8cp7NGxLK53jgiapLeBdwI5IFPR8S9ki4DtkbEXDPUXQ1cK+lekrOmro2IH871\nefOhdTymUqHU6Y8zM1vUZk0QETEEIOlyks7iz5AcrM8Hjm/nzSPiBuCGGWWXzPLcl7csj5Cc6rqg\nWicNWllxgjCz3tZOE9O5EfF3EbE/IoYj4u/JPl31qDdVg/CZTGZmbSWIUUnnS8pLykk6n+QU1CXH\nkwaZmU1rJ0G8Ffgt4Kn09ptp2ZIz3cTkU13NzNqZD+JRlmiT0kyeNMjMbNqz1iAkvUDSzZJ+lK5v\nlPTnnQ9t4bV2UpuZ9bp2mpj+gWQ+iEmA9HTT8+Z8xVFq0DUIM7Mp7SSIgYj47oyyJXkEdROTmdm0\ndhLE05KeR3rRnKQ3kVwXseSUCjlK+Rz7nSDMzNoai+mdwDXAyZIeBx4huVhuSfK0o2ZmiTkTRDrp\nz3+KiF9Jx0TKRcT+hQmtOzztqJlZYs4EERF1SWemy0vy4riZPO2omVminSam70vaAvwzLVdQR8S/\ndCyqLkpqEE4QZmbtJIg+YBfp8NupAJZsgtg3Vu12GGZmXdfOldS/txCBLBaD5TyP73ENwszsWROE\npD7g7cCpJLUJACLiP3Ywrq4ZdCe1mRnQ3nUQnyGZDvRXgdtIpg5dsmcyuQ/CzCzRToJ4fkR8EBiN\niOuA1wK/1NmwumewXGC0WiNi1sn0zMx6QjsJYjK93yvphcByYG3nQuquSrlAI+DApJuZzKy3tXMW\n0zWSVgIfBLYAg0DmtKFLQaVlRNeBUjt/HjOzpamds5g+lS7eBjy3s+F032A6q9zIeI21Q10Oxsys\ni9o5iymzthARl81/ON1XKTVHdHUTk5n1tnbaUFqH2OgDXgfc35lwus+TBpmZJdppYvqb1nVJHwNu\n7FhEXeY5IczMEu2cxTTTAMm1EEvSVIKoOkGYWW9rpw/iHtLJgoA8sAZYkv0P4CYmM7OmdvogXtey\nXAOeiogle/Qc7HMTk5kZtJcgZg6rsUzS1EpE7J7XiLpsoJie5uqzmMysx7WTIL4HnAjsAQSsAH6a\nPhYssWsjcjlRKXnaUTOzdjqpbwJ+LSJWR8Qqkianr0XEhohYUsmhyQP2mZm1lyBOj4gbmisR8W/A\nyzoXUvd52lEzs/aamH4m6c+Bz6br5wM/61xI3VdxgjAza6sG8RaSU1u/nN7WpmVLVqXsPggzs3au\npN4NXAiQjuq6N5b4ZAmD5QKP7x3vdhhmZl01aw1C0iWSTk6Xy5K+DmwDnpL0KwsVYDe4k9rMbO4m\npjcDD6bLF6TPXQucBfxlh+PqKicIM7O5E0S1pSnpV4HPRUQ9Iu6nvc7to9aQO6nNzOZMEBOSXihp\nDfAK4Gstjw10NqzuqpQLTNQa1OqNbodiZtY1cyWIC4EvAQ8An4iIRwAkvQb4/gLE1jXTQ357uA0z\n612zJoiIuCMiTo6IVRFxeUv5DRHR1mmuks6W9KCkbZIunuN5b5QUkja3lG2U9G1J90q6R1Jfuxt1\npKamHfWQ32bWwzrWlyApD1wNvArYDtwpaUtE3DfjeUMktZU7WsoKJBfm/XZE/EDSKmCyU7HO5EmD\nzMwOb8Kgdp0GbIuIhyOiCnweeH3G8y4HrgBaLzx4NfDDiPgBQETsiogFa++peE4IM7OOJogTgMda\n1renZVMkvQQ4MSKun/HaFwAh6UZJ35P0/qwPkPQOSVslbd25c+e8BT41adC4E4SZ9a62mpgkvQxY\n3/r8iPjHI/lgSTng48DvzhLXmcBLgTHgZkl3RcTNrU+KiGuAawA2b948b1d3V0puYjIza2fK0c8A\nzwPuBprNPAE8W4J4nGQeiaZ1aVnTEPBC4NZ0AqLjgC2SziWpbdweEU+nMdwAvAQ4KEF0iqcdNTNr\nrwaxGTjlMMZfuhM4SdIGksRwHvDW5oMRsQ9Y3VyXdCvwvojYKukh4P2SBoAqydXbnzjEzz9slfQs\nJtcgzKyXtdMH8SOSX/eHJJ23+l3AjcD9wBcj4l5Jl6W1hLleu4ek+elOkprL9zL6KTpm6iymqq+D\nMLPe1U4NYjVwn6TvAhPNwoiY8yCfPucG4IYZZZfM8tyXz1j/LNNzUCyociFHMS83MZlZT2snQXy4\n00EsNpI8YJ+Z9bx25oO4bSECWWwqJQ/YZ2a97Vn7ICSdLulOSSOSqpLqkoYXIrhuGnQNwsx6XDud\n1H9LMsXoj4F+4PdJhtBY0pJpR91JbWa9q60rqSNiG5BP54O4Fji7s2F1X8VzQphZj2unk3pMUgm4\nW9JfA0/Q2SE6FoXBcoEn9nleajPrXe0c6H87fd67gFGSq6Pf2MmgFgOfxWRmva6ds5h+IqkfOD4i\nLl2AmBaFQTcxmVmPa+cspl8juZr5q+n6JklbOh1YtyWd1DUOfYQRM7OloZ0mpg+TzO2wFyAi7gY2\ndDCmRWGwXKQRMD7peanNrDe1kyAm04H1Wi35n9VT0466mcnMelQ7CeJeSW8F8pJOknQV8K0Ox9V1\nnnbUzHpdOwnij4FTSQbq+xwwDPxJJ4NaDDztqJn1unbOYhoD/nN66xmDrkGYWY+bNUE825lK7Qz3\nfTSbnhPCCcLMetNcNYhfBh4jaVa6A9CCRLRITHdSezwmM+tNcyWI44BXkQzU91bgeuBzEXHvQgTW\nbVN9EOOuQZhZb5q1kzodmO+rEXEBcDqwDbhV0rsWLLou8llMZtbr5jyLSVJZ0m+QTP35TuBK4MsL\nEVi3VUoFSvkc3354F/XGkr/sw8zsGWZNEJL+Efg28BLg0oh4aURcHhGPL1h0XZTPiYvOOZmvP7CD\ny//1Pg+5YWY9Z64+iLeRjN56IfBuaaqPWkBExLIOx9Z1bz9zA0/sPcCnvvkIxy/v4w/Oel63QzIz\nWzCzJoiIWPJzPrTjz17z73hyeJy/+rcHOHZZH2948QndDsnMbEG0M2FQT8vlxN/81i/w9MgEf/ql\nH7B6sMyZJ63udlhmZh2npdK2vnnz5ti6dWvH3n/fgUne/F+/zfY9B/jCH5zOqc9ZftjvVas3GJus\nc6BaZ3yyzoqBEsv6CrQ042WKCIbHa0zU6pTyOYr5HKVCjkJOz/raIxURUyPb9hVzs37egWqdn+4e\n49Fdo/xk1yhPDU9w/PI+nrd2kOetHuSElf3kc4vvkppGI6jWGxTzuUUZX/PvP1qtMTZRZ2yyxvhk\ng0opz7L+IkN9BfqL+UPeD/aMVtm2c4T945Ms7y+yvL/EioEiy/uLFPNJI0KjEew9MMnu0QmeHqmy\ne7TKvgOTrOgvsnZZmTWDfawZKtNfyndi0xe9yXqDPWNVCCgX8pSLOcqF2b8ji42kuyJic+ZjThDt\ne2LfAX7j775FvRFc8aaNjIzX2LF/gh37x9kxnNzvOzBJvZF8qeoRU/e1ejBWrTFWrTNRe+YQ4v3F\nPMct7+PYZWWOW9bHscv6mKg1Wt47ef/Zhh8v5ZOdcqCcp1IuMFguUCkVqJQLDKRf3CA50ES6EgST\n9aBWbzBZTw6Qk+ltfLLBgWqdA2kiOzA5fcFgPicGywWG+gpT90L8dPcYTw4fPE1rXzF3UMylQo4N\nqypsWF2hVMhRrTWo1hvJfa3BRL1BvdGg0YBGBBHJfaMZN0knmKSpKzfzOVEu5CgX8/QV8/QVcvQV\n85QKOSZqDcYmkr97kpSn/wfVWrKt1VqDWnqmWj4n1gyWOXZ5H8ctK3P88n6OXdbHYDnP8HiNvWPJ\nwXHv2CT7Dkyyf7xGI4J6I9I4p+PNSxTySQIv5nMU8qKQE6VCmtzTBF8qJMuNCPaP1xiZqE3dj6T3\no9Uaz/ZVLeTEUF+BZf1FVg6UWD1YYlWlzKrBEqsGy6yqlNg7VuXHO0bYtmOEh3aO8PRIddb3q5Ty\nlIt59o5VaedEvsFygTVDZZb1FRgoFaiU8wfd9xfz6f8plxxI0+XJerBjeJwnh8d5aniCp4bHeXLf\nOHvGquSU/M1yueQ+n8tN/Q2bf7dSIdn3S4Xp5N7cN5oH6UJO9JfyDJSSfaQ/veXzYrxaZ2zGvj5R\na5ATyefnRU4in0vuhw9Msnusyp7RJFkOZ1wrJUE53Q8LuRwRB+8fEZATrKyUOKZSYlV6f0ylzPL+\nItVaI42nNhXb+GSdiOS9JU3FJ8Ev/vwxvP3Mw5uFwQliHv2/p/bzpr//1kE7RSmfY81QmbXLyqzo\nL5LP5cjnmNqh8rnkVikVGCjnGShOf2lKhRx7Rqs82fyC7EvudwxPUC7kWLOszNqhMmuH+pL7ZWX6\nSwUma9MH82o90oN6ndGJGqPV9H6ixshEspNBy0FV0wfZ1gNWMZ8eyNIvU18x+UL1F/P0p1/wIBht\nHsDGa+yfqLF/fJJGA048ZoD1qwb4+dWV5P6YCssHiuwerfLwzuSA9NDOUR7aMcIjT4/SiDjoi14u\n5NNYBEx/AXK56dhbkxtABNQbwUQt2f7xWoOJ9MtUrTUopweCSjnZhoFiPt22gw/SzdrYWLXGk/vS\ng1T6/9jfci1MfzGf/tIusnygyLK+wtT/Odf8f6df4HojqDUaU0m41oj0fxYHJaeJNEnmBEN9xamk\n20zAzYR/0EG3lPytRqt19o9PMnwg+T8Mp8t7xqo8PVJl18gEu0erUwkQYFlfgeevHeT5awc5ae0Q\nz187yIqBIvsOTE7dmglwfLLOyoESqwaTA9jqwTLHVEos6y+yb2ySnSMT7BgeZ+fIBDv3J7eRiaSW\nM5oe3Jr74oHJ+pyJZuVAkWPTH0fHLitzTKVMENTrQa2RJOHkx1bjoB8WE82/Ya0x/QMo3TeS3SX5\ngdaaAMYn60zWI/1eMJUwmvt8qZCb2rfq6Q+A5o+AZX3F9GCe3FYOlDimUkTS1H44ke6Lzc/J59J9\nOT2g5yRq9Qa7x5Ka2a60ZrZnrDoVVymfm0pqzdhyOWg0pn/sNZPOy1+whj9/3SmHdUxzgphnP9t7\ngId3jrI2PXgv7y8eNdVJO3Sj6S/45f1FyoWjrxml0QiGxyfZNVplKP2V3639tVafPqBP1OpMTDbI\nSaxdVqavuLB/28l6g3ojFlVzUESSyEr5HIX8wpwnNFeCcCf1YXjOin6es6K/22HYAqmkv+KPVrmc\nWDFQYsVAqduhJE1u+RyVcrcjIa01dzuKg0lioLR49jWfympmZpmcIMzMLJMThJmZZXKCMDOzTE4Q\nZmaWyQnCzMwyOUGYmVkmJwgzM8vkBGFmZpmcIMzMLJMThJmZZepogpB0tqQHJW2TdPEcz3ujpJC0\neUb5z0kakfS+TsZpZmbP1LEEISkPXA2cA5wCvEXSM8ajlTREMu/1HRlv83Hg3zoVo5mZza6TNYjT\ngG0R8XBEVIHPA6/PeN7lwBXAQTPNSHoD8AhwbwdjNDOzWXQyQZwAPNayvj0tmyLpJcCJEXH9jPJB\n4CLg0rk+QNI7JG2VtHXnzp3zE7WZmQFd7KSWlCNpQnpvxsMfBj4RESNzvUdEXBMRmyNi85o1azoQ\npZlZ7+rkzBSPAye2rK9Ly5qGgBcCt6azOR0HbJF0LvBLwJsk/TWwAmhIGo+Iv+1gvGZm1qKTCeJO\n4CRJG0gSw3nAW5sPRsQ+YHVzXdKtwPsiYivw71vKPwyMODmYmS2sjjUxRUQNeBdwI3A/8MWIuFfS\nZWktwczMFjFFRLdjmBebN2+OrVu3djsMM7OjiqS7ImJz1mO+ktrMzDI5QZiZWSYnCDMzy+QEYWZm\nmZwgzMwskxOEmZllcoIwM7NMThBmZpbJCcLMzDI5QZiZWSYnCDMzy+QEYWZmmZwgzMwskxOEmZll\ncoIwM7NMThBmZpbJCcLMzDI5QZiZWSYnCDMzy+QEYWZmmZwgzMwskxOEmZllcoIwM7NMThBmZpbJ\nCcLMzDI5QZiZWSYnCDMzy+QEYWZmmZwgzMwskxOEmZllcoIwM7NMiohuxzAvJO0EfnIEb7EaeHqe\nwjmaeLt7i7e7t7Sz3T8fEWuyHlgyCeJISdoaEZu7HcdC83b3Fm93bznS7XYTk5mZZXKCMDOzTE4Q\n067pdgBd4u3uLd7u3nJE2+0+CDMzy+QahJmZZXKCMDOzTD2fICSdLelBSdskXdzteDpF0qcl7ZD0\no5ayYyTdJOnH6f3KbsbYCZJOlHSLpPsk3SvpwrR8SW+7pD5J35X0g3S7L03LN0i6I93fvyCp1O1Y\nO0FSXtL3Jf1rut4r2/2opHsk3S1pa1p22Pt6TycISXngauAc4BTgLZJO6W5UHfPfgbNnlF0M3BwR\nJwE3p+tLTQ14b0ScApwOvDP9Hy/1bZ8AXhkRvwBsAs6WdDpwBfCJiHg+sAd4exdj7KQLgftb1ntl\nuwFeERGbWq5/OOx9vacTBHAasC0iHo6IKvB54PVdjqkjIuJ2YPeM4tcD16XL1wFvWNCgFkBEPBER\n30uX95McNE5giW97JEbS1WJ6C+CVwJfS8iW33QCS1gGvBT6Vrose2O45HPa+3usJ4gTgsZb17WlZ\nrzg2Ip5Il58Eju1mMJ0maT3wYuAOemDb02aWu4EdwE3AQ8DeiKilT1mq+/sngfcDjXR9Fb2x3ZD8\nCPiapLskvSMtO+x9vTDf0dnRKSJC0pI951nSIPA/gT+JiOHkR2ViqW57RNSBTZJWAF8GTu5ySB0n\n6XXAjoi4S9LLux1PF5wZEY9LWgvcJOmB1gcPdV/v9RrE48CJLevr0rJe8ZSk4wHS+x1djqcjJBVJ\nksM/RcS/pMU9se0AEbEXuAX4ZWCFpOYPw6W4v58BnCvpUZIm41cC/4Wlv90ARMTj6f0Okh8Fp3EE\n+3qvJ4g7gZPSMxxKwHnAli7HtJC2ABekyxcA/7uLsXRE2v7834D7I+LjLQ8t6W2XtCatOSCpH3gV\nSf/LLcCb0qctue2OiA9ExLqIWE/yff56RJzPEt9uAEkVSUPNZeDVwI84gn2956+klvQakjbLPPDp\niPhIl0PqCEmfA15OMvzvU8CHgP8FfBH4OZKh0n8rImZ2ZB/VJJ0JfAO4h+k26T8j6YdYstsuaSNJ\nh2Se5IfgFyPiMknPJfllfQzwfeBtETHRvUg7J21iel9EvK4Xtjvdxi+nqwXgf0TERySt4jD39Z5P\nEGZmlq3Xm5jMzGwWThBmZpbJCcLMzDI5QZiZWSYnCDMzy+QEYXYIJNXTkTKbt3kb5E/S+tbRds26\nzUNtmB2aAxGxqdtBmC0E1yDM5kE6Dv9fp2Pxf1fS89Py9ZK+LumHkm6W9HNp+bGSvpzO1/ADSS9L\n3yov6R/SORy+ll4FbdYVThBmh6Z/RhPTm1se2xcRLwL+luTqfICrgOsiYiPwT8CVafmVwG3pfA0v\nAe5Ny08Cro6IU4G9wBs7vD1ms/KV1GaHQNJIRAxmlD9KMkHPw+nggE9GxCpJTwPHR8RkWv5ERKyW\ntBNY1zrcQzoc+U3pxC5IuggoRsRfdH7LzJ7JNQiz+ROzLB+K1vGB6rif0LrICcJs/ry55f7b6fK3\nSEYVBTifZOBASKZ+/COYmthn+UIFadYu/zoxOzT96SxtTV+NiOaprisl/ZCkFvCWtOyPgWsl/Smw\nE/i9tPxC4BpJbyepKfwR8ARmi4j7IMzmQdoHsTkinu52LGbzxU1MZmaWyTUIMzPL5BqEmZllcoIw\nM7NMThBmZpbJCcLMzDI5QVV68QMAAAAKSURBVJiZWab/D/5d+kl/g/3aAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluate the linear regression model against the test set:\n",
            "7/7 [==============================] - 0s 1ms/step - loss: 0.4502 - mean_squared_error: 0.4463\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.45016786456108093, 0.44629010558128357]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}