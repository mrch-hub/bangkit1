{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SolarPrediction.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrch-hub/bangkit1/blob/test_feature_1/SolarPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5bF6G8ff6Zq",
        "colab_type": "text"
      },
      "source": [
        "##Solar radiation intensity prediction using TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6pwJrUZ9rYW",
        "colab_type": "code",
        "outputId": "6a289da9-924b-4a89-fdb3-eb987e32fa59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\"\"\"A python code for predicting solar radiation\n",
        "intensity using TensorFlow. Created for \n",
        "5th Bangk!t assignment.\n",
        "Collaborators: Marcellinus Chrisnada, Muhammad\n",
        "Harits Hafidza, Mochammad Randy Caesario H.\"\"\""
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A python code for predicting solar radiation\\nintensity using TensorFlow. Created for \\n5th Bangk!t assignment.\\nCollaborators: Marcellinus Chrisnada, Muhammad\\nHarits Hafidza, Mochammad Randy Caesario H.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yb2tFywNgWIn",
        "colab_type": "text"
      },
      "source": [
        "##Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8ekWJYDbTzp",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Run on TensorFlow 2.x\n",
        "%tensorflow_version 2.x\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPY5vbLWXmKN",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "e665dbe3-d091-4f31-fa88-a8ec3e7a494a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#@title Import relevant modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Adjust the granularity of reporting. \n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "\n",
        "print(\"Imported modules.\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imported modules.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRlH8pQwbSpE",
        "colab_type": "code",
        "outputId": "51c1cab7-6788-4973-967a-2df8392b10b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "#@title Load dataset\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/mrch-hub/bangkit1/master/SolarPrediction.csv')\n",
        "data = data.reindex(np.random.permutation(data.index)) # shuffle dataset\n",
        "data.head(40)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UNIXTime</th>\n",
              "      <th>Data</th>\n",
              "      <th>Time</th>\n",
              "      <th>Radiation</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Pressure</th>\n",
              "      <th>Humidity</th>\n",
              "      <th>WindDirection(Degrees)</th>\n",
              "      <th>Speed</th>\n",
              "      <th>TimeSunRise</th>\n",
              "      <th>TimeSunSet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3082</th>\n",
              "      <td>1474283402</td>\n",
              "      <td>9/19/2016 12:00:00 AM</td>\n",
              "      <td>01:10:02</td>\n",
              "      <td>1.2</td>\n",
              "      <td>48</td>\n",
              "      <td>30.4</td>\n",
              "      <td>47</td>\n",
              "      <td>191.1</td>\n",
              "      <td>7.9</td>\n",
              "      <td>06:11:00</td>\n",
              "      <td>18:22:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23742</th>\n",
              "      <td>1478229024</td>\n",
              "      <td>11/3/2016 12:00:00 AM</td>\n",
              "      <td>17:10:24</td>\n",
              "      <td>80.0</td>\n",
              "      <td>61</td>\n",
              "      <td>30.4</td>\n",
              "      <td>50</td>\n",
              "      <td>27.2</td>\n",
              "      <td>6.8</td>\n",
              "      <td>06:25:00</td>\n",
              "      <td>17:47:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22986</th>\n",
              "      <td>1478456402</td>\n",
              "      <td>11/6/2016 12:00:00 AM</td>\n",
              "      <td>08:20:02</td>\n",
              "      <td>455.5</td>\n",
              "      <td>60</td>\n",
              "      <td>30.5</td>\n",
              "      <td>18</td>\n",
              "      <td>35.8</td>\n",
              "      <td>9.0</td>\n",
              "      <td>06:26:00</td>\n",
              "      <td>17:46:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3302</th>\n",
              "      <td>1474213203</td>\n",
              "      <td>9/18/2016 12:00:00 AM</td>\n",
              "      <td>05:40:03</td>\n",
              "      <td>1.2</td>\n",
              "      <td>50</td>\n",
              "      <td>30.4</td>\n",
              "      <td>100</td>\n",
              "      <td>179.1</td>\n",
              "      <td>3.4</td>\n",
              "      <td>06:11:00</td>\n",
              "      <td>18:23:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17075</th>\n",
              "      <td>1480231217</td>\n",
              "      <td>11/26/2016 12:00:00 AM</td>\n",
              "      <td>21:20:17</td>\n",
              "      <td>1.2</td>\n",
              "      <td>45</td>\n",
              "      <td>30.5</td>\n",
              "      <td>81</td>\n",
              "      <td>95.7</td>\n",
              "      <td>3.4</td>\n",
              "      <td>06:38:00</td>\n",
              "      <td>17:42:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13696</th>\n",
              "      <td>1476093625</td>\n",
              "      <td>10/10/2016 12:00:00 AM</td>\n",
              "      <td>00:00:25</td>\n",
              "      <td>1.3</td>\n",
              "      <td>49</td>\n",
              "      <td>30.4</td>\n",
              "      <td>87</td>\n",
              "      <td>178.3</td>\n",
              "      <td>6.8</td>\n",
              "      <td>06:16:00</td>\n",
              "      <td>18:03:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23895</th>\n",
              "      <td>1478183118</td>\n",
              "      <td>11/3/2016 12:00:00 AM</td>\n",
              "      <td>04:25:18</td>\n",
              "      <td>1.2</td>\n",
              "      <td>45</td>\n",
              "      <td>30.4</td>\n",
              "      <td>38</td>\n",
              "      <td>185.8</td>\n",
              "      <td>6.8</td>\n",
              "      <td>06:25:00</td>\n",
              "      <td>17:47:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5692</th>\n",
              "      <td>1473264623</td>\n",
              "      <td>9/7/2016 12:00:00 AM</td>\n",
              "      <td>06:10:23</td>\n",
              "      <td>8.1</td>\n",
              "      <td>45</td>\n",
              "      <td>30.4</td>\n",
              "      <td>78</td>\n",
              "      <td>164.1</td>\n",
              "      <td>3.4</td>\n",
              "      <td>06:08:00</td>\n",
              "      <td>18:33:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30584</th>\n",
              "      <td>1481441761</td>\n",
              "      <td>12/10/2016 12:00:00 AM</td>\n",
              "      <td>21:36:01</td>\n",
              "      <td>1.3</td>\n",
              "      <td>48</td>\n",
              "      <td>30.4</td>\n",
              "      <td>102</td>\n",
              "      <td>85.4</td>\n",
              "      <td>2.2</td>\n",
              "      <td>06:47:00</td>\n",
              "      <td>17:44:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30674</th>\n",
              "      <td>1481414740</td>\n",
              "      <td>12/10/2016 12:00:00 AM</td>\n",
              "      <td>14:05:40</td>\n",
              "      <td>84.4</td>\n",
              "      <td>52</td>\n",
              "      <td>30.4</td>\n",
              "      <td>100</td>\n",
              "      <td>356.4</td>\n",
              "      <td>7.9</td>\n",
              "      <td>06:47:00</td>\n",
              "      <td>17:44:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         UNIXTime                    Data  ... TimeSunRise  TimeSunSet\n",
              "3082   1474283402   9/19/2016 12:00:00 AM  ...    06:11:00    18:22:00\n",
              "23742  1478229024   11/3/2016 12:00:00 AM  ...    06:25:00    17:47:00\n",
              "22986  1478456402   11/6/2016 12:00:00 AM  ...    06:26:00    17:46:00\n",
              "3302   1474213203   9/18/2016 12:00:00 AM  ...    06:11:00    18:23:00\n",
              "17075  1480231217  11/26/2016 12:00:00 AM  ...    06:38:00    17:42:00\n",
              "...           ...                     ...  ...         ...         ...\n",
              "13696  1476093625  10/10/2016 12:00:00 AM  ...    06:16:00    18:03:00\n",
              "23895  1478183118   11/3/2016 12:00:00 AM  ...    06:25:00    17:47:00\n",
              "5692   1473264623    9/7/2016 12:00:00 AM  ...    06:08:00    18:33:00\n",
              "30584  1481441761  12/10/2016 12:00:00 AM  ...    06:47:00    17:44:00\n",
              "30674  1481414740  12/10/2016 12:00:00 AM  ...    06:47:00    17:44:00\n",
              "\n",
              "[40 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c28PYOGaauV0",
        "colab_type": "text"
      },
      "source": [
        "##Adding some features to the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymGkD9ZPaxro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Adding feature is_daylight that define measurement time is either daylight (1) or nighttime (0)\n",
        "is_daylight = [data['Time'].values[x] > data['TimeSunRise'].values[x] and data['Time'].values[x] < data['TimeSunSet'].values[x] for x in range(len(data))]\n",
        "data['is_daylight'] = is_daylight\n",
        "data['is_daylight'] = data['is_daylight'].astype('float')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQeavaKNayAj",
        "colab_type": "text"
      },
      "source": [
        "##Data Preconditioning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbKi6_Xcbn6M",
        "colab_type": "code",
        "outputId": "966deccb-2381-4c3b-e8be-0596cb87467c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "#@title Splitting data to train set and test set\n",
        "test_split = 0.2 # percentage of train set to be considered as test set\n",
        "data_test = data[:][0:round((len(data)*test_split))]\n",
        "data_train = data[:][round((len(data)*test_split)):]\n",
        "print('train set length:', str(len(data_train)), '\\ntest set length:', \n",
        "      str(len(data_test)))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train set length: 26149 \n",
            "test set length: 6537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v5LYeP_dECa",
        "colab_type": "code",
        "outputId": "5ea87423-96f8-4bf0-e701-b0521ab8d74c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#@title Normalize values \n",
        "\n",
        "# Calculate the Z-scores of each column in the training set:\n",
        "data_train_mean = data_train.select_dtypes(include=['float64', 'int64']).mean()\n",
        "data_train_std = data_train.select_dtypes(include=['float64', 'int64']).std()\n",
        "data_train_norm = (data_train.select_dtypes(include=['float64', 'int64']) \n",
        "                   - data_train_mean)/data_train_std\n",
        "\n",
        "# Calculate the Z-scores of each column in the test set.\n",
        "data_test_mean = data_test.select_dtypes(include=['float64', 'int64']).mean()\n",
        "data_test_std = data_test.select_dtypes(include=['float64', 'int64']).std()\n",
        "data_test_norm = (data_test.select_dtypes(include=['float64', 'int64'])\n",
        "                  - data_test_mean)/data_test_std\n",
        "\n",
        "print(\"Normalized the values.\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normalized the values.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKdhPgg5eRFI",
        "colab_type": "text"
      },
      "source": [
        "## Represent data\n",
        "\n",
        "The following code cell creates a feature layer containing three features:\n",
        "\n",
        "* `Temperature`\n",
        "* `Pressure`\n",
        "* `is_daylight`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bDp6l3KeEgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create empty feature column list\n",
        "feature_columns = []\n",
        "\n",
        "# Represent Temperature as a floating-point value.\n",
        "temperature = tf.feature_column.numeric_column(\"Temperature\")\n",
        "feature_columns.append(temperature)\n",
        "\n",
        "# Represent Pressure as a floating-point value.\n",
        "pressure = tf.feature_column.numeric_column(\"Pressure\")\n",
        "feature_columns.append(pressure)\n",
        "\n",
        "# Represent is_daylight as a floating-point value.\n",
        "daylight = tf.feature_column.numeric_column(\"is_daylight\")\n",
        "feature_columns.append(daylight)\n",
        "\n",
        "# Convert the list of feature columns into a layer that will later be fed into\n",
        "# the model. \n",
        "my_feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMAji1PSfPCt",
        "colab_type": "text"
      },
      "source": [
        "## Build a linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyOjMo-7ei25",
        "colab_type": "code",
        "outputId": "fef4da55-c24b-42d6-eaa4-64821ba234b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#@title Define plotting function\n",
        "\n",
        "def plot_the_loss_curve(epochs, mse):\n",
        "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Mean Squared Error\")\n",
        "\n",
        "  plt.plot(epochs, mse, label=\"Loss\")\n",
        "  plt.legend()\n",
        "  plt.ylim([mse.min()*0.95, mse.max() * 1.03])\n",
        "  plt.show()  \n",
        "\n",
        "print(\"Defined the plot_the_loss_curve function.\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defined the plot_the_loss_curve function.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEsYOPPhetG3",
        "colab_type": "code",
        "outputId": "b3066a0b-a955-4bf7-9d19-83fdf2c81873",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#@title Define functions to create and train a linear regression model\n",
        "def create_model(my_learning_rate, feature_layer):\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
        "  # Most simple tf.keras models are sequential.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # Add the layer containing the feature columns to the model.\n",
        "  model.add(feature_layer)\n",
        "\n",
        "  # Add one linear layer to the model to yield a simple linear regressor.\n",
        "  model.add(tf.keras.layers.Dense(units=1, input_shape=(1,)))\n",
        "\n",
        "  # Construct the layers into a model that TensorFlow can execute.\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[tf.keras.metrics.MeanSquaredError()])\n",
        "\n",
        "  return model           \n",
        "\n",
        "\n",
        "def train_model(model, dataset, epochs, batch_size, label_name):\n",
        "  \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
        "\n",
        "  # Split the dataset into features and label.\n",
        "  features = {name:np.array(value) for name, value in dataset.items()}\n",
        "  label = np.array(features.pop(label_name))\n",
        "  history = model.fit(x=features, y=label, batch_size=batch_size,\n",
        "                      epochs=epochs, shuffle=True)\n",
        "\n",
        "  # Get details that will be useful for plotting the loss curve.\n",
        "  epochs = history.epoch\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  rmse = hist[\"mean_squared_error\"]\n",
        "\n",
        "  return epochs, rmse   \n",
        "\n",
        "print(\"Defined the create_model and train_model functions.\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defined the create_model and train_model functions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAJuzbBmexB4",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "1a180168-a41d-4230-ceed-d804607a6687",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#@title Train the model as linear regression\n",
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.01\n",
        "epochs = 50\n",
        "batch_size = 1000\n",
        "label_name = \"Radiation\"\n",
        "\n",
        "# Establish the model's topography.\n",
        "my_model = create_model(learning_rate, my_feature_layer)\n",
        "\n",
        "# Train the model on the normalized training set.\n",
        "epochs, mse = train_model(my_model, data_train_norm, epochs, batch_size, label_name)\n",
        "plot_the_loss_curve(epochs, mse)\n",
        "\n",
        "test_features = {name:np.array(value) for name, value in data_test_norm.items()}\n",
        "test_label = np.array(test_features.pop(label_name)) # isolate the label\n",
        "print(\"\\n Evaluate the linear regression model against the test set:\")\n",
        "my_model.evaluate(x = test_features, y = test_label, batch_size=batch_size)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.5094 - mean_squared_error: 0.5142\n",
            "Epoch 2/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.4113 - mean_squared_error: 0.4130\n",
            "Epoch 3/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3792 - mean_squared_error: 0.3790\n",
            "Epoch 4/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3760 - mean_squared_error: 0.3739\n",
            "Epoch 5/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3760 - mean_squared_error: 0.3739\n",
            "Epoch 6/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3721 - mean_squared_error: 0.3738\n",
            "Epoch 7/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3736 - mean_squared_error: 0.3736\n",
            "Epoch 8/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3735 - mean_squared_error: 0.3739\n",
            "Epoch 9/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3732 - mean_squared_error: 0.3735\n",
            "Epoch 10/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3738 - mean_squared_error: 0.3738\n",
            "Epoch 11/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3721 - mean_squared_error: 0.3736\n",
            "Epoch 12/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3721 - mean_squared_error: 0.3738\n",
            "Epoch 13/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3735 - mean_squared_error: 0.3737\n",
            "Epoch 14/50\n",
            "27/27 [==============================] - 0s 3ms/step - loss: 0.3764 - mean_squared_error: 0.3738\n",
            "Epoch 15/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3717 - mean_squared_error: 0.3738\n",
            "Epoch 16/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3732 - mean_squared_error: 0.3737\n",
            "Epoch 17/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3751 - mean_squared_error: 0.3738\n",
            "Epoch 18/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3722 - mean_squared_error: 0.3738\n",
            "Epoch 19/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3702 - mean_squared_error: 0.3737\n",
            "Epoch 20/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3735 - mean_squared_error: 0.3740\n",
            "Epoch 21/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3740 - mean_squared_error: 0.3738\n",
            "Epoch 22/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3729 - mean_squared_error: 0.3739\n",
            "Epoch 23/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3746 - mean_squared_error: 0.3737\n",
            "Epoch 24/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3740 - mean_squared_error: 0.3738\n",
            "Epoch 25/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3735 - mean_squared_error: 0.3737\n",
            "Epoch 26/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3734 - mean_squared_error: 0.3735\n",
            "Epoch 27/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3716 - mean_squared_error: 0.3739\n",
            "Epoch 28/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3746 - mean_squared_error: 0.3737\n",
            "Epoch 29/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3749 - mean_squared_error: 0.3738\n",
            "Epoch 30/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3719 - mean_squared_error: 0.3736\n",
            "Epoch 31/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3762 - mean_squared_error: 0.3737\n",
            "Epoch 32/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3772 - mean_squared_error: 0.3737\n",
            "Epoch 33/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3719 - mean_squared_error: 0.3738\n",
            "Epoch 34/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3735 - mean_squared_error: 0.3740\n",
            "Epoch 35/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3738 - mean_squared_error: 0.3741\n",
            "Epoch 36/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3732 - mean_squared_error: 0.3737\n",
            "Epoch 37/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3767 - mean_squared_error: 0.3737\n",
            "Epoch 38/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3724 - mean_squared_error: 0.3737\n",
            "Epoch 39/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3750 - mean_squared_error: 0.3739\n",
            "Epoch 40/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3717 - mean_squared_error: 0.3736\n",
            "Epoch 41/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3747 - mean_squared_error: 0.3739\n",
            "Epoch 42/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3732 - mean_squared_error: 0.3740\n",
            "Epoch 43/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3744 - mean_squared_error: 0.3738\n",
            "Epoch 44/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3756 - mean_squared_error: 0.3737\n",
            "Epoch 45/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3762 - mean_squared_error: 0.3738\n",
            "Epoch 46/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3735 - mean_squared_error: 0.3739\n",
            "Epoch 47/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3747 - mean_squared_error: 0.3737\n",
            "Epoch 48/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3719 - mean_squared_error: 0.3737\n",
            "Epoch 49/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3762 - mean_squared_error: 0.3737\n",
            "Epoch 50/50\n",
            "27/27 [==============================] - 0s 2ms/step - loss: 0.3744 - mean_squared_error: 0.3738\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluate the linear regression model against the test set:\n",
            "7/7 [==============================] - 0s 2ms/step - loss: 0.3697 - mean_squared_error: 0.3698\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.36969563364982605, 0.36979421973228455]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    }
  ]
}