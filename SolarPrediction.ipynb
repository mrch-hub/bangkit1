{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SolarPrediction.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrch-hub/bangkit1/blob/test_feature_3_neuralnet/SolarPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5bF6G8ff6Zq",
        "colab_type": "text"
      },
      "source": [
        "##Solar radiation intensity prediction using TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6pwJrUZ9rYW",
        "colab_type": "code",
        "outputId": "85b4cfde-5564-4489-9794-e0635677e43e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\"\"\"A python code for predicting solar radiation\n",
        "intensity using TensorFlow. Created for \n",
        "5th Bangk!t assignment.\n",
        "Collaborators: Marcellinus Chrisnada, Muhammad\n",
        "Harits Hafidza, Mochammad Randy Caesario H.\"\"\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A python code for predicting solar radiation\\nintensity using TensorFlow. Created for \\n5th Bangk!t assignment.\\nCollaborators: Marcellinus Chrisnada, Muhammad\\nHarits Hafidza, Mochammad Randy Caesario H.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yb2tFywNgWIn",
        "colab_type": "text"
      },
      "source": [
        "##Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8ekWJYDbTzp",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Run on TensorFlow 2.x\n",
        "%tensorflow_version 2.x\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPY5vbLWXmKN",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "6eeeebbd-3fbf-4de3-935f-beecbd774240",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "#@title Import relevant modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Adjust the granularity of reporting. \n",
        "pd.options.display.max_rows = 10\n",
        "pd.options.display.float_format = \"{:.1f}\".format\n",
        "\n",
        "print(\"Imported modules.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Imported modules.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRlH8pQwbSpE",
        "colab_type": "code",
        "outputId": "88d99275-3b0a-4cdb-a9a2-808eed684d0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "#@title Load dataset\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/mrch-hub/bangkit1/master/SolarPrediction.csv')\n",
        "data = data.reindex(np.random.permutation(data.index)) # shuffle dataset\n",
        "data = data.rename(columns={'WindDirection(Degrees)':'WindDirection'})\n",
        "data.head(15)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UNIXTime</th>\n",
              "      <th>Data</th>\n",
              "      <th>Time</th>\n",
              "      <th>Radiation</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Pressure</th>\n",
              "      <th>Humidity</th>\n",
              "      <th>WindDirection</th>\n",
              "      <th>Speed</th>\n",
              "      <th>TimeSunRise</th>\n",
              "      <th>TimeSunSet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21292</th>\n",
              "      <td>1478964620</td>\n",
              "      <td>11/12/2016 12:00:00 AM</td>\n",
              "      <td>05:30:20</td>\n",
              "      <td>1.2</td>\n",
              "      <td>43</td>\n",
              "      <td>30.5</td>\n",
              "      <td>79</td>\n",
              "      <td>176.4</td>\n",
              "      <td>6.8</td>\n",
              "      <td>06:30:00</td>\n",
              "      <td>17:44:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22076</th>\n",
              "      <td>1478729402</td>\n",
              "      <td>11/9/2016 12:00:00 AM</td>\n",
              "      <td>12:10:02</td>\n",
              "      <td>885.1</td>\n",
              "      <td>63</td>\n",
              "      <td>30.4</td>\n",
              "      <td>41</td>\n",
              "      <td>300.8</td>\n",
              "      <td>9.0</td>\n",
              "      <td>06:28:00</td>\n",
              "      <td>17:45:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4311</th>\n",
              "      <td>1473829503</td>\n",
              "      <td>9/13/2016 12:00:00 AM</td>\n",
              "      <td>19:05:03</td>\n",
              "      <td>1.6</td>\n",
              "      <td>55</td>\n",
              "      <td>30.4</td>\n",
              "      <td>99</td>\n",
              "      <td>358.7</td>\n",
              "      <td>3.4</td>\n",
              "      <td>06:10:00</td>\n",
              "      <td>18:27:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14601</th>\n",
              "      <td>1475816723</td>\n",
              "      <td>10/6/2016 12:00:00 AM</td>\n",
              "      <td>19:05:23</td>\n",
              "      <td>1.3</td>\n",
              "      <td>52</td>\n",
              "      <td>30.4</td>\n",
              "      <td>101</td>\n",
              "      <td>315.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>06:15:00</td>\n",
              "      <td>18:07:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17026</th>\n",
              "      <td>1480245921</td>\n",
              "      <td>11/27/2016 12:00:00 AM</td>\n",
              "      <td>01:25:21</td>\n",
              "      <td>1.2</td>\n",
              "      <td>45</td>\n",
              "      <td>30.4</td>\n",
              "      <td>99</td>\n",
              "      <td>136.1</td>\n",
              "      <td>11.2</td>\n",
              "      <td>06:38:00</td>\n",
              "      <td>17:42:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2454</th>\n",
              "      <td>1474476004</td>\n",
              "      <td>9/21/2016 12:00:00 AM</td>\n",
              "      <td>06:40:04</td>\n",
              "      <td>16.2</td>\n",
              "      <td>47</td>\n",
              "      <td>30.4</td>\n",
              "      <td>100</td>\n",
              "      <td>178.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>06:11:00</td>\n",
              "      <td>18:20:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19611</th>\n",
              "      <td>1479469220</td>\n",
              "      <td>11/18/2016 12:00:00 AM</td>\n",
              "      <td>01:40:20</td>\n",
              "      <td>1.2</td>\n",
              "      <td>48</td>\n",
              "      <td>30.4</td>\n",
              "      <td>27</td>\n",
              "      <td>169.8</td>\n",
              "      <td>7.9</td>\n",
              "      <td>06:33:00</td>\n",
              "      <td>17:43:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26521</th>\n",
              "      <td>1482663686</td>\n",
              "      <td>12/25/2016 12:00:00 AM</td>\n",
              "      <td>01:01:26</td>\n",
              "      <td>1.2</td>\n",
              "      <td>46</td>\n",
              "      <td>30.5</td>\n",
              "      <td>31</td>\n",
              "      <td>155.2</td>\n",
              "      <td>10.1</td>\n",
              "      <td>06:55:00</td>\n",
              "      <td>17:51:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26779</th>\n",
              "      <td>1482586240</td>\n",
              "      <td>12/24/2016 12:00:00 AM</td>\n",
              "      <td>03:30:40</td>\n",
              "      <td>1.2</td>\n",
              "      <td>46</td>\n",
              "      <td>30.4</td>\n",
              "      <td>48</td>\n",
              "      <td>157.4</td>\n",
              "      <td>5.6</td>\n",
              "      <td>06:54:00</td>\n",
              "      <td>17:50:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31909</th>\n",
              "      <td>1480819235</td>\n",
              "      <td>12/3/2016 12:00:00 AM</td>\n",
              "      <td>16:40:35</td>\n",
              "      <td>27.0</td>\n",
              "      <td>45</td>\n",
              "      <td>30.3</td>\n",
              "      <td>93</td>\n",
              "      <td>284.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>06:42:00</td>\n",
              "      <td>17:43:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         UNIXTime                    Data  ... TimeSunRise  TimeSunSet\n",
              "21292  1478964620  11/12/2016 12:00:00 AM  ...    06:30:00    17:44:00\n",
              "22076  1478729402   11/9/2016 12:00:00 AM  ...    06:28:00    17:45:00\n",
              "4311   1473829503   9/13/2016 12:00:00 AM  ...    06:10:00    18:27:00\n",
              "14601  1475816723   10/6/2016 12:00:00 AM  ...    06:15:00    18:07:00\n",
              "17026  1480245921  11/27/2016 12:00:00 AM  ...    06:38:00    17:42:00\n",
              "...           ...                     ...  ...         ...         ...\n",
              "2454   1474476004   9/21/2016 12:00:00 AM  ...    06:11:00    18:20:00\n",
              "19611  1479469220  11/18/2016 12:00:00 AM  ...    06:33:00    17:43:00\n",
              "26521  1482663686  12/25/2016 12:00:00 AM  ...    06:55:00    17:51:00\n",
              "26779  1482586240  12/24/2016 12:00:00 AM  ...    06:54:00    17:50:00\n",
              "31909  1480819235   12/3/2016 12:00:00 AM  ...    06:42:00    17:43:00\n",
              "\n",
              "[15 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c28PYOGaauV0",
        "colab_type": "text"
      },
      "source": [
        "##Adding some features to the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymGkD9ZPaxro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Adding feature is_daylight that define measurement time is either daylight (1) or nighttime (0)\n",
        "is_daylight = [data['Time'].values[x] > data['TimeSunRise'].values[x] and data['Time'].values[x] < data['TimeSunSet'].values[x] for x in range(len(data))]\n",
        "data['is_daylight'] = is_daylight\n",
        "data['is_daylight'] = data['is_daylight'].astype('float')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCCuKjCwBH1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Convert UNIXTime into hour, day, month format\n",
        "data['Time_Convert'] = pd.to_datetime(data['Time'], format = '%H:%M:%S')\n",
        "\n",
        "data['Hour'] = pd.to_datetime(data['Time_Convert'], format = '%H:%M:%S').dt.hour # Get the hour of the day\n",
        "\n",
        "data['Day'] = pd.to_datetime(data['UNIXTime'].astype(int), unit = 's').dt.day # Get the day of the month\n",
        "\n",
        "data['Month'] = pd.to_datetime(data['UNIXTime'].astype(int), unit = 's').dt.month # Get the month of the year"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQeavaKNayAj",
        "colab_type": "text"
      },
      "source": [
        "##Data Preconditioning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbKi6_Xcbn6M",
        "colab_type": "code",
        "outputId": "2fd081d4-1873-444e-87e1-9f37969899e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "#@title Splitting data to train set and test set\n",
        "test_split = 0.2 # percentage of train set to be considered as test set\n",
        "data_test = data[:][0:round((len(data)*test_split))]\n",
        "data_train = data[:][round((len(data)*test_split)):]\n",
        "print('train set length:', str(len(data_train)), '\\ntest set length:', \n",
        "      str(len(data_test)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train set length: 26149 \n",
            "test set length: 6537\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v5LYeP_dECa",
        "colab_type": "code",
        "outputId": "87193280-1768-4e07-9d87-cec12f3217cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#@title Normalize values \n",
        "\n",
        "# Calculate the Z-scores of each column in the training set:\n",
        "data_train_mean = data_train.select_dtypes(include=['float64', 'int64']).mean()\n",
        "data_train_std = data_train.select_dtypes(include=['float64', 'int64']).std()\n",
        "data_train_norm = (data_train.select_dtypes(include=['float64', 'int64']) \n",
        "                   - data_train_mean)/data_train_std\n",
        "\n",
        "# Calculate the Z-scores of each column in the test set.\n",
        "data_test_mean = data_test.select_dtypes(include=['float64', 'int64']).mean()\n",
        "data_test_std = data_test.select_dtypes(include=['float64', 'int64']).std()\n",
        "data_test_norm = (data_test.select_dtypes(include=['float64', 'int64'])\n",
        "                  - data_test_mean)/data_test_std\n",
        "\n",
        "print(\"Normalized the values.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normalized the values.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKdhPgg5eRFI",
        "colab_type": "text"
      },
      "source": [
        "## Represent data\n",
        "\n",
        "The following code cell creates a feature layer containing 6 features:\n",
        "\n",
        "* `Temperature`\n",
        "* `Pressure`\n",
        "* `is_daylight`\n",
        "* `Humidity x Wind Cross Feature`\n",
        "* `Hour x Month Cross Feature`\n",
        "* `Day`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bDp6l3KeEgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create empty feature column list\n",
        "feature_columns = []\n",
        "\n",
        "# Represent Temperature as a floating-point value.\n",
        "temperature_numeric_column = tf.feature_column.numeric_column(\"Temperature\")\n",
        "feature_columns.append(temperature_numeric_column)\n",
        "\n",
        "# Represent Pressure as a floating-point value.\n",
        "pressure_numeric_column = tf.feature_column.numeric_column(\"Pressure\")\n",
        "feature_columns.append(pressure_numeric_column)\n",
        "\n",
        "# Represent Humidity as a floating-point value.\n",
        "humidity_numeric_column = tf.feature_column.numeric_column(\"Humidity\")\n",
        "humidity_boundaries = list(np.arange(int(min(data_train['Humidity'])), int(max(data_train['Humidity']))))\n",
        "humidity = tf.feature_column.bucketized_column(humidity_numeric_column, humidity_boundaries)\n",
        "\n",
        "# Represent Wind as a floating-point value.\n",
        "wind_numeric_column = tf.feature_column.numeric_column(\"WindDirection\")\n",
        "wind_boundaries = list(np.arange(int(min(data_train['WindDirection'])), int(max(data_train['WindDirection']))))\n",
        "wind = tf.feature_column.bucketized_column(wind_numeric_column, wind_boundaries)\n",
        "\n",
        "# Represent Daylight as a floating-point value.\n",
        "daylight = tf.feature_column.numeric_column(\"is_daylight\")\n",
        "feature_columns.append(daylight)\n",
        "\n",
        "# Represent Hour as a floating-point value.\n",
        "day_numeric_column = tf.feature_column.numeric_column(\"Day\")\n",
        "feature_columns.append(day_numeric_column)\n",
        "\n",
        "# Represent Hour as a floating-point value.\n",
        "hour_numeric_column = tf.feature_column.numeric_column(\"Hour\")\n",
        "hour_boundaries = list(np.arange(int(min(data_train['Hour'])), int(max(data_train['Hour']))))\n",
        "hour = tf.feature_column.bucketized_column(hour_numeric_column, hour_boundaries)\n",
        "\n",
        "# Represent Hour as a floating-point value.\n",
        "month_numeric_column = tf.feature_column.numeric_column(\"Month\")\n",
        "month_boundaries = list(np.arange(int(min(data_train['Month'])), int(max(data_train['Month']))))\n",
        "month = tf.feature_column.bucketized_column(month_numeric_column, month_boundaries)\n",
        "\n",
        "# Create a feature cross between Humidity and Wind\n",
        "humidity_x_wind = tf.feature_column.crossed_column([humidity, wind], hash_bucket_size=100)\n",
        "crossed_feature_HW = tf.feature_column.indicator_column(humidity_x_wind)\n",
        "feature_columns.append(crossed_feature_HW)\n",
        "\n",
        "# Create a feature cross between Hour and Month\n",
        "hour_x_month = tf.feature_column.crossed_column([hour, month], hash_bucket_size=100)\n",
        "crossed_feature_HM = tf.feature_column.indicator_column(hour_x_month)\n",
        "feature_columns.append(crossed_feature_HM)\n",
        "\n",
        "# Convert the list of feature columns into a layer that will later be fed into\n",
        "# the model. \n",
        "my_feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMAji1PSfPCt",
        "colab_type": "text"
      },
      "source": [
        "## Build a linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyOjMo-7ei25",
        "colab_type": "code",
        "outputId": "bbe6b71e-96fb-4927-be86-70c0942efb4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#@title Define plotting function|\n",
        "\n",
        "def plot_the_loss_curve(epochs, mse_training, mse_validation):\n",
        "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Root Mean Squared Error\")\n",
        "\n",
        "  plt.plot(epochs[1:], mse_training[1:], label=\"Training Loss\")\n",
        "  plt.plot(epochs[1:], mse_validation[1:], label=\"Validation Loss\")\n",
        "  plt.legend()\n",
        "\n",
        "  merged_mse_lists = mse_training[1:] + mse_validation[1:]\n",
        "  highest_loss = max(merged_mse_lists)\n",
        "  lowest_loss = min(merged_mse_lists)\n",
        "  delta = highest_loss - lowest_loss\n",
        "  print(delta)\n",
        "\n",
        "  top_of_y_axis = highest_loss + (delta * 0.05)\n",
        "  bottom_of_y_axis = lowest_loss - (delta * 0.05)\n",
        "  plt.ylim([bottom_of_y_axis, top_of_y_axis])\n",
        "  plt.show()  \n",
        "\n",
        "print(\"Defined the plot_the_loss_curve function.\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defined the plot_the_loss_curve function.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEsYOPPhetG3",
        "colab_type": "code",
        "outputId": "51a98f7c-fc8a-42f6-cd6f-b9929e3a6738",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#@title Define functions to create and train a linear regression model\n",
        "def create_model(my_learning_rate, feature_layer):\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
        "  # Most simple tf.keras models are sequential.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # Add the layer containing the feature columns to the model.\n",
        "  model.add(feature_layer)\n",
        "\n",
        "  # Add one linear layer to the model to yield a simple linear regressor.\n",
        "  model.add(tf.keras.layers.Dense(units=1, input_shape=(1,)))\n",
        "\n",
        "  # Construct the layers into a model that TensorFlow can execute.\n",
        "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  return model           \n",
        "\n",
        "\n",
        "def train_model(model, dataset, epochs, batch_size, label_name,validation_split):\n",
        "  \"\"\"Feed a dataset into the model in order to train it.\"\"\"\n",
        "\n",
        "  # Split the dataset into features and label.\n",
        "  features = {name:np.array(value) for name, value in dataset.items()}\n",
        "  label = np.array(features.pop(label_name))\n",
        "  history = model.fit(x=features, y=label, batch_size=batch_size,\n",
        "                      epochs=epochs, validation_split=validation_split, \n",
        "                      shuffle=True)\n",
        "\n",
        "  # Get details that will be useful for plotting the loss curve.\n",
        "  epochs = history.epoch\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  rmse = hist[\"root_mean_squared_error\"]\n",
        "\n",
        "  return epochs, rmse, history.history   \n",
        "\n",
        "print(\"Defined the create_model and train_model functions.\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Defined the create_model and train_model functions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAJuzbBmexB4",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "15e6ca74-6fc8-44b8-af71-d20ea0176a50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#@title Train the model as linear regression\n",
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.01\n",
        "epochs = 50\n",
        "batch_size = 1000\n",
        "validation_split = 0.2\n",
        "label_name = \"Radiation\"\n",
        " \n",
        "\n",
        "# Establish the model's topography.\n",
        "my_model = create_model(learning_rate, my_feature_layer)\n",
        "\n",
        "# Train the model on the normalized training set.\n",
        "epochs, mse, history = train_model(my_model, data_train_norm, epochs, batch_size, label_name, \n",
        "                          validation_split=validation_split)\n",
        "plot_the_loss_curve(epochs, history[\"root_mean_squared_error\"], \n",
        "                    history[\"val_root_mean_squared_error\"])\n",
        "\n",
        "test_features = {name:np.array(value) for name, value in data_test_norm.items()}\n",
        "test_label = np.array(test_features.pop(label_name)) # isolate the label\n",
        "print(\"\\n Evaluate the linear regression model against the test set:\")\n",
        "my_model.evaluate(x = test_features, y = test_label, batch_size=batch_size)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "WARNING:tensorflow:Layer dense_features is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "21/21 [==============================] - 0s 22ms/step - loss: 0.5993 - root_mean_squared_error: 0.7744 - val_loss: 0.4504 - val_root_mean_squared_error: 0.6694\n",
            "Epoch 2/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3954 - root_mean_squared_error: 0.6290 - val_loss: 0.3847 - val_root_mean_squared_error: 0.6183\n",
            "Epoch 3/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3544 - root_mean_squared_error: 0.5953 - val_loss: 0.3539 - val_root_mean_squared_error: 0.5928\n",
            "Epoch 4/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3377 - root_mean_squared_error: 0.5812 - val_loss: 0.3446 - val_root_mean_squared_error: 0.5853\n",
            "Epoch 5/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3345 - root_mean_squared_error: 0.5784 - val_loss: 0.3444 - val_root_mean_squared_error: 0.5847\n",
            "Epoch 6/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3343 - root_mean_squared_error: 0.5783 - val_loss: 0.3440 - val_root_mean_squared_error: 0.5852\n",
            "Epoch 7/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3342 - root_mean_squared_error: 0.5781 - val_loss: 0.3434 - val_root_mean_squared_error: 0.5842\n",
            "Epoch 8/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3341 - root_mean_squared_error: 0.5781 - val_loss: 0.3445 - val_root_mean_squared_error: 0.5848\n",
            "Epoch 9/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3343 - root_mean_squared_error: 0.5782 - val_loss: 0.3446 - val_root_mean_squared_error: 0.5856\n",
            "Epoch 10/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3342 - root_mean_squared_error: 0.5781 - val_loss: 0.3440 - val_root_mean_squared_error: 0.5843\n",
            "Epoch 11/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3340 - root_mean_squared_error: 0.5779 - val_loss: 0.3450 - val_root_mean_squared_error: 0.5863\n",
            "Epoch 12/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3343 - root_mean_squared_error: 0.5782 - val_loss: 0.3439 - val_root_mean_squared_error: 0.5850\n",
            "Epoch 13/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3342 - root_mean_squared_error: 0.5781 - val_loss: 0.3452 - val_root_mean_squared_error: 0.5866\n",
            "Epoch 14/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3341 - root_mean_squared_error: 0.5780 - val_loss: 0.3433 - val_root_mean_squared_error: 0.5842\n",
            "Epoch 15/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3344 - root_mean_squared_error: 0.5782 - val_loss: 0.3431 - val_root_mean_squared_error: 0.5840\n",
            "Epoch 16/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3341 - root_mean_squared_error: 0.5781 - val_loss: 0.3444 - val_root_mean_squared_error: 0.5857\n",
            "Epoch 17/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3341 - root_mean_squared_error: 0.5780 - val_loss: 0.3429 - val_root_mean_squared_error: 0.5838\n",
            "Epoch 18/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3344 - root_mean_squared_error: 0.5782 - val_loss: 0.3434 - val_root_mean_squared_error: 0.5844\n",
            "Epoch 19/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3345 - root_mean_squared_error: 0.5783 - val_loss: 0.3433 - val_root_mean_squared_error: 0.5841\n",
            "Epoch 20/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3344 - root_mean_squared_error: 0.5783 - val_loss: 0.3433 - val_root_mean_squared_error: 0.5842\n",
            "Epoch 21/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3346 - root_mean_squared_error: 0.5784 - val_loss: 0.3444 - val_root_mean_squared_error: 0.5857\n",
            "Epoch 22/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3343 - root_mean_squared_error: 0.5781 - val_loss: 0.3443 - val_root_mean_squared_error: 0.5851\n",
            "Epoch 23/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3342 - root_mean_squared_error: 0.5781 - val_loss: 0.3449 - val_root_mean_squared_error: 0.5857\n",
            "Epoch 24/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3344 - root_mean_squared_error: 0.5783 - val_loss: 0.3432 - val_root_mean_squared_error: 0.5842\n",
            "Epoch 25/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3340 - root_mean_squared_error: 0.5780 - val_loss: 0.3444 - val_root_mean_squared_error: 0.5857\n",
            "Epoch 26/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3345 - root_mean_squared_error: 0.5783 - val_loss: 0.3444 - val_root_mean_squared_error: 0.5858\n",
            "Epoch 27/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3343 - root_mean_squared_error: 0.5782 - val_loss: 0.3457 - val_root_mean_squared_error: 0.5868\n",
            "Epoch 28/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3345 - root_mean_squared_error: 0.5783 - val_loss: 0.3433 - val_root_mean_squared_error: 0.5842\n",
            "Epoch 29/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3343 - root_mean_squared_error: 0.5782 - val_loss: 0.3431 - val_root_mean_squared_error: 0.5842\n",
            "Epoch 30/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3344 - root_mean_squared_error: 0.5783 - val_loss: 0.3431 - val_root_mean_squared_error: 0.5844\n",
            "Epoch 31/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3342 - root_mean_squared_error: 0.5780 - val_loss: 0.3447 - val_root_mean_squared_error: 0.5861\n",
            "Epoch 32/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3344 - root_mean_squared_error: 0.5783 - val_loss: 0.3439 - val_root_mean_squared_error: 0.5843\n",
            "Epoch 33/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3346 - root_mean_squared_error: 0.5783 - val_loss: 0.3443 - val_root_mean_squared_error: 0.5844\n",
            "Epoch 34/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3345 - root_mean_squared_error: 0.5783 - val_loss: 0.3438 - val_root_mean_squared_error: 0.5845\n",
            "Epoch 35/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3344 - root_mean_squared_error: 0.5782 - val_loss: 0.3446 - val_root_mean_squared_error: 0.5855\n",
            "Epoch 36/50\n",
            "21/21 [==============================] - 0s 8ms/step - loss: 0.3341 - root_mean_squared_error: 0.5780 - val_loss: 0.3435 - val_root_mean_squared_error: 0.5841\n",
            "Epoch 37/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3343 - root_mean_squared_error: 0.5782 - val_loss: 0.3442 - val_root_mean_squared_error: 0.5845\n",
            "Epoch 38/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3346 - root_mean_squared_error: 0.5784 - val_loss: 0.3440 - val_root_mean_squared_error: 0.5844\n",
            "Epoch 39/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3342 - root_mean_squared_error: 0.5781 - val_loss: 0.3434 - val_root_mean_squared_error: 0.5841\n",
            "Epoch 40/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3340 - root_mean_squared_error: 0.5778 - val_loss: 0.3437 - val_root_mean_squared_error: 0.5844\n",
            "Epoch 41/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3340 - root_mean_squared_error: 0.5780 - val_loss: 0.3431 - val_root_mean_squared_error: 0.5840\n",
            "Epoch 42/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3346 - root_mean_squared_error: 0.5783 - val_loss: 0.3433 - val_root_mean_squared_error: 0.5840\n",
            "Epoch 43/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3345 - root_mean_squared_error: 0.5784 - val_loss: 0.3438 - val_root_mean_squared_error: 0.5844\n",
            "Epoch 44/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3341 - root_mean_squared_error: 0.5779 - val_loss: 0.3439 - val_root_mean_squared_error: 0.5843\n",
            "Epoch 45/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3342 - root_mean_squared_error: 0.5780 - val_loss: 0.3445 - val_root_mean_squared_error: 0.5857\n",
            "Epoch 46/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3345 - root_mean_squared_error: 0.5782 - val_loss: 0.3434 - val_root_mean_squared_error: 0.5841\n",
            "Epoch 47/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3343 - root_mean_squared_error: 0.5780 - val_loss: 0.3447 - val_root_mean_squared_error: 0.5853\n",
            "Epoch 48/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3344 - root_mean_squared_error: 0.5784 - val_loss: 0.3437 - val_root_mean_squared_error: 0.5845\n",
            "Epoch 49/50\n",
            "21/21 [==============================] - 0s 6ms/step - loss: 0.3343 - root_mean_squared_error: 0.5781 - val_loss: 0.3434 - val_root_mean_squared_error: 0.5839\n",
            "Epoch 50/50\n",
            "21/21 [==============================] - 0s 7ms/step - loss: 0.3340 - root_mean_squared_error: 0.5780 - val_loss: 0.3450 - val_root_mean_squared_error: 0.5864\n",
            "0.05115044116973877\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluate the linear regression model against the test set:\n",
            "7/7 [==============================] - 0s 3ms/step - loss: 0.3430 - root_mean_squared_error: 0.5838\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3429904282093048, 0.5838090777397156]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tENUoY3RLazP",
        "colab_type": "text"
      },
      "source": [
        "##Build a neural net model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzIkZNjddP_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Define functions to create and train a neural net model\n",
        "def create_model(my_learning_rate, my_feature_layer):\n",
        "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
        "  # Most simple tf.keras models are sequential.\n",
        "  model = tf.keras.models.Sequential()\n",
        "\n",
        "  # Add the layer containing the feature columns to the model.\n",
        "  model.add(my_feature_layer)\n",
        "\n",
        "  # Describe the topography of the model by calling the tf.keras.layers.Dense\n",
        "  # method once for each layer. We've specified the following arguments:\n",
        "  #   * units specifies the number of nodes in this layer.\n",
        "  #   * activation specifies the activation function (Rectified Linear Unit).\n",
        "  #   * name is just a string that can be useful when debugging.\n",
        "\n",
        "  # Define the first hidden layer with 20 nodes.   \n",
        "  model.add(tf.keras.layers.Dense(units=20, \n",
        "                                  activation='sigmoid',\n",
        "                                  name='Hidden1'))\n",
        "  \n",
        "  model.add(tf.keras.layers.Dropout(rate=0.25))\n",
        "  \n",
        "  # Define the second hidden layer with 12 nodes. \n",
        "  model.add(tf.keras.layers.Dense(units=12, \n",
        "                                  activation='sigmoid',\n",
        "                                  name='Hidden2'))\n",
        "\n",
        "  \n",
        "  # Define the output layer.\n",
        "  model.add(tf.keras.layers.Dense(units=1,  \n",
        "                                  name='Output'))                              \n",
        "  \n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
        "                loss=\"mean_squared_error\",\n",
        "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  return model\n",
        "\n",
        "def train_model(model, dataset, epochs, label_name,\n",
        "                batch_size, validation_split):\n",
        "  \"\"\"Train the model by feeding it data.\"\"\"\n",
        "\n",
        "  # Split the dataset into features and label.\n",
        "  features = {name:np.array(value) for name, value in dataset.items()}\n",
        "  label = np.array(features.pop(label_name))\n",
        "  history = model.fit(x=features, y=label, batch_size=batch_size,\n",
        "                      epochs=epochs, validation_split=validation_split, shuffle=True) \n",
        "\n",
        "  # The list of epochs is stored separately from the rest of history.\n",
        "  epochs = history.epoch\n",
        "  \n",
        "  # To track the progression of training, gather a snapshot\n",
        "  # of the model's mean squared error at each epoch. \n",
        "  hist = pd.DataFrame(history.history)\n",
        "  rmse = hist[\"root_mean_squared_error\"]\n",
        "\n",
        "  return epochs, rmse, history.history "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SgIHkGlLT_P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f53440b8-fb31-4eb2-e9b5-b91753c49229"
      },
      "source": [
        "#@title Train the model\n",
        "# The following variables are the hyperparameters.\n",
        "learning_rate = 0.1\n",
        "epochs = 200\n",
        "batch_size = 2000\n",
        "validation_split = 0.2\n",
        "label_name = \"Radiation\"\n",
        " \n",
        "\n",
        "# Establish the model's topography.\n",
        "my_model = create_model(learning_rate, my_feature_layer)\n",
        "\n",
        "# Train the model on the normalized training set.\n",
        "epochs, mse, history = train_model(my_model, data_train_norm, epochs, label_name, batch_size, \n",
        "                          validation_split)\n",
        "plot_the_loss_curve(epochs, history[\"root_mean_squared_error\"], \n",
        "                    history[\"val_root_mean_squared_error\"])\n",
        "\n",
        "test_features = {name:np.array(value) for name, value in data_test_norm.items()}\n",
        "test_label = np.array(test_features.pop(label_name)) # isolate the label\n",
        "print(\"\\n Evaluate the linear regression model against the test set:\")\n",
        "my_model.evaluate(x = test_features, y = test_label, batch_size=batch_size)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "11/11 [==============================] - 0s 38ms/step - loss: 0.8464 - root_mean_squared_error: 0.9304 - val_loss: 0.4397 - val_root_mean_squared_error: 0.6617\n",
            "Epoch 2/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.3750 - root_mean_squared_error: 0.6141 - val_loss: 0.3331 - val_root_mean_squared_error: 0.5769\n",
            "Epoch 3/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.3051 - root_mean_squared_error: 0.5540 - val_loss: 0.2937 - val_root_mean_squared_error: 0.5429\n",
            "Epoch 4/200\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.2829 - root_mean_squared_error: 0.5332 - val_loss: 0.2766 - val_root_mean_squared_error: 0.5264\n",
            "Epoch 5/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2758 - root_mean_squared_error: 0.5254 - val_loss: 0.2723 - val_root_mean_squared_error: 0.5218\n",
            "Epoch 6/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2727 - root_mean_squared_error: 0.5216 - val_loss: 0.2724 - val_root_mean_squared_error: 0.5224\n",
            "Epoch 7/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2688 - root_mean_squared_error: 0.5196 - val_loss: 0.2776 - val_root_mean_squared_error: 0.5278\n",
            "Epoch 8/200\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.2680 - root_mean_squared_error: 0.5197 - val_loss: 0.2655 - val_root_mean_squared_error: 0.5154\n",
            "Epoch 9/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2655 - root_mean_squared_error: 0.5142 - val_loss: 0.2638 - val_root_mean_squared_error: 0.5140\n",
            "Epoch 10/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2643 - root_mean_squared_error: 0.5157 - val_loss: 0.2635 - val_root_mean_squared_error: 0.5138\n",
            "Epoch 11/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2623 - root_mean_squared_error: 0.5135 - val_loss: 0.2622 - val_root_mean_squared_error: 0.5126\n",
            "Epoch 12/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2600 - root_mean_squared_error: 0.5107 - val_loss: 0.2608 - val_root_mean_squared_error: 0.5109\n",
            "Epoch 13/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2621 - root_mean_squared_error: 0.5114 - val_loss: 0.2609 - val_root_mean_squared_error: 0.5107\n",
            "Epoch 14/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2579 - root_mean_squared_error: 0.5076 - val_loss: 0.2586 - val_root_mean_squared_error: 0.5089\n",
            "Epoch 15/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2589 - root_mean_squared_error: 0.5092 - val_loss: 0.2593 - val_root_mean_squared_error: 0.5095\n",
            "Epoch 16/200\n",
            "11/11 [==============================] - 0s 17ms/step - loss: 0.2601 - root_mean_squared_error: 0.5094 - val_loss: 0.2588 - val_root_mean_squared_error: 0.5089\n",
            "Epoch 17/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2618 - root_mean_squared_error: 0.5105 - val_loss: 0.2611 - val_root_mean_squared_error: 0.5116\n",
            "Epoch 18/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2585 - root_mean_squared_error: 0.5089 - val_loss: 0.2588 - val_root_mean_squared_error: 0.5090\n",
            "Epoch 19/200\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.2563 - root_mean_squared_error: 0.5061 - val_loss: 0.2572 - val_root_mean_squared_error: 0.5073\n",
            "Epoch 20/200\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.2566 - root_mean_squared_error: 0.5064 - val_loss: 0.2583 - val_root_mean_squared_error: 0.5083\n",
            "Epoch 21/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2576 - root_mean_squared_error: 0.5070 - val_loss: 0.2576 - val_root_mean_squared_error: 0.5077\n",
            "Epoch 22/200\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.2561 - root_mean_squared_error: 0.5062 - val_loss: 0.2589 - val_root_mean_squared_error: 0.5094\n",
            "Epoch 23/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2573 - root_mean_squared_error: 0.5063 - val_loss: 0.2594 - val_root_mean_squared_error: 0.5097\n",
            "Epoch 24/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2535 - root_mean_squared_error: 0.5044 - val_loss: 0.2572 - val_root_mean_squared_error: 0.5071\n",
            "Epoch 25/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2581 - root_mean_squared_error: 0.5065 - val_loss: 0.2547 - val_root_mean_squared_error: 0.5050\n",
            "Epoch 26/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2540 - root_mean_squared_error: 0.5046 - val_loss: 0.2589 - val_root_mean_squared_error: 0.5093\n",
            "Epoch 27/200\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.2534 - root_mean_squared_error: 0.5043 - val_loss: 0.2545 - val_root_mean_squared_error: 0.5048\n",
            "Epoch 28/200\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.2528 - root_mean_squared_error: 0.5027 - val_loss: 0.2543 - val_root_mean_squared_error: 0.5045\n",
            "Epoch 29/200\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.2549 - root_mean_squared_error: 0.5040 - val_loss: 0.2544 - val_root_mean_squared_error: 0.5044\n",
            "Epoch 30/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2533 - root_mean_squared_error: 0.5043 - val_loss: 0.2539 - val_root_mean_squared_error: 0.5042\n",
            "Epoch 31/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2502 - root_mean_squared_error: 0.5013 - val_loss: 0.2545 - val_root_mean_squared_error: 0.5050\n",
            "Epoch 32/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2526 - root_mean_squared_error: 0.5026 - val_loss: 0.2526 - val_root_mean_squared_error: 0.5029\n",
            "Epoch 33/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2549 - root_mean_squared_error: 0.5038 - val_loss: 0.2549 - val_root_mean_squared_error: 0.5051\n",
            "Epoch 34/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2537 - root_mean_squared_error: 0.5034 - val_loss: 0.2557 - val_root_mean_squared_error: 0.5063\n",
            "Epoch 35/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2517 - root_mean_squared_error: 0.5025 - val_loss: 0.2531 - val_root_mean_squared_error: 0.5035\n",
            "Epoch 36/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2514 - root_mean_squared_error: 0.5009 - val_loss: 0.2528 - val_root_mean_squared_error: 0.5031\n",
            "Epoch 37/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2500 - root_mean_squared_error: 0.4997 - val_loss: 0.2553 - val_root_mean_squared_error: 0.5058\n",
            "Epoch 38/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2507 - root_mean_squared_error: 0.5005 - val_loss: 0.2536 - val_root_mean_squared_error: 0.5042\n",
            "Epoch 39/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.2487 - root_mean_squared_error: 0.5000 - val_loss: 0.2525 - val_root_mean_squared_error: 0.5030\n",
            "Epoch 40/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2522 - root_mean_squared_error: 0.5021 - val_loss: 0.2527 - val_root_mean_squared_error: 0.5031\n",
            "Epoch 41/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2526 - root_mean_squared_error: 0.5012 - val_loss: 0.2536 - val_root_mean_squared_error: 0.5043\n",
            "Epoch 42/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2507 - root_mean_squared_error: 0.5007 - val_loss: 0.2528 - val_root_mean_squared_error: 0.5028\n",
            "Epoch 43/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2507 - root_mean_squared_error: 0.5011 - val_loss: 0.2517 - val_root_mean_squared_error: 0.5021\n",
            "Epoch 44/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2516 - root_mean_squared_error: 0.5014 - val_loss: 0.2529 - val_root_mean_squared_error: 0.5035\n",
            "Epoch 45/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2496 - root_mean_squared_error: 0.4997 - val_loss: 0.2504 - val_root_mean_squared_error: 0.5008\n",
            "Epoch 46/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2498 - root_mean_squared_error: 0.5002 - val_loss: 0.2520 - val_root_mean_squared_error: 0.5024\n",
            "Epoch 47/200\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.2486 - root_mean_squared_error: 0.4991 - val_loss: 0.2511 - val_root_mean_squared_error: 0.5014\n",
            "Epoch 48/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2495 - root_mean_squared_error: 0.4987 - val_loss: 0.2499 - val_root_mean_squared_error: 0.5006\n",
            "Epoch 49/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2506 - root_mean_squared_error: 0.5005 - val_loss: 0.2524 - val_root_mean_squared_error: 0.5033\n",
            "Epoch 50/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2506 - root_mean_squared_error: 0.5000 - val_loss: 0.2502 - val_root_mean_squared_error: 0.5005\n",
            "Epoch 51/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2482 - root_mean_squared_error: 0.4995 - val_loss: 0.2550 - val_root_mean_squared_error: 0.5056\n",
            "Epoch 52/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2473 - root_mean_squared_error: 0.4993 - val_loss: 0.2500 - val_root_mean_squared_error: 0.5006\n",
            "Epoch 53/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2469 - root_mean_squared_error: 0.4972 - val_loss: 0.2518 - val_root_mean_squared_error: 0.5022\n",
            "Epoch 54/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2468 - root_mean_squared_error: 0.4977 - val_loss: 0.2495 - val_root_mean_squared_error: 0.4996\n",
            "Epoch 55/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2462 - root_mean_squared_error: 0.4977 - val_loss: 0.2501 - val_root_mean_squared_error: 0.5004\n",
            "Epoch 56/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2477 - root_mean_squared_error: 0.4985 - val_loss: 0.2525 - val_root_mean_squared_error: 0.5030\n",
            "Epoch 57/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2461 - root_mean_squared_error: 0.4963 - val_loss: 0.2489 - val_root_mean_squared_error: 0.4993\n",
            "Epoch 58/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2485 - root_mean_squared_error: 0.4971 - val_loss: 0.2493 - val_root_mean_squared_error: 0.4996\n",
            "Epoch 59/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2490 - root_mean_squared_error: 0.4979 - val_loss: 0.2499 - val_root_mean_squared_error: 0.5004\n",
            "Epoch 60/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2442 - root_mean_squared_error: 0.4940 - val_loss: 0.2518 - val_root_mean_squared_error: 0.5024\n",
            "Epoch 61/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2466 - root_mean_squared_error: 0.4960 - val_loss: 0.2486 - val_root_mean_squared_error: 0.4989\n",
            "Epoch 62/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2446 - root_mean_squared_error: 0.4950 - val_loss: 0.2494 - val_root_mean_squared_error: 0.5000\n",
            "Epoch 63/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2465 - root_mean_squared_error: 0.4967 - val_loss: 0.2482 - val_root_mean_squared_error: 0.4984\n",
            "Epoch 64/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.2431 - root_mean_squared_error: 0.4956 - val_loss: 0.2566 - val_root_mean_squared_error: 0.5075\n",
            "Epoch 65/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2464 - root_mean_squared_error: 0.4972 - val_loss: 0.2510 - val_root_mean_squared_error: 0.5013\n",
            "Epoch 66/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2416 - root_mean_squared_error: 0.4945 - val_loss: 0.2487 - val_root_mean_squared_error: 0.4993\n",
            "Epoch 67/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2461 - root_mean_squared_error: 0.4969 - val_loss: 0.2481 - val_root_mean_squared_error: 0.4984\n",
            "Epoch 68/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2461 - root_mean_squared_error: 0.4960 - val_loss: 0.2494 - val_root_mean_squared_error: 0.5000\n",
            "Epoch 69/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2455 - root_mean_squared_error: 0.4949 - val_loss: 0.2515 - val_root_mean_squared_error: 0.5017\n",
            "Epoch 70/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2458 - root_mean_squared_error: 0.4961 - val_loss: 0.2511 - val_root_mean_squared_error: 0.5019\n",
            "Epoch 71/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2442 - root_mean_squared_error: 0.4939 - val_loss: 0.2480 - val_root_mean_squared_error: 0.4984\n",
            "Epoch 72/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2437 - root_mean_squared_error: 0.4954 - val_loss: 0.2502 - val_root_mean_squared_error: 0.5011\n",
            "Epoch 73/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2446 - root_mean_squared_error: 0.4941 - val_loss: 0.2480 - val_root_mean_squared_error: 0.4986\n",
            "Epoch 74/200\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.2502 - root_mean_squared_error: 0.4988 - val_loss: 0.2507 - val_root_mean_squared_error: 0.5015\n",
            "Epoch 75/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2436 - root_mean_squared_error: 0.4929 - val_loss: 0.2461 - val_root_mean_squared_error: 0.4969\n",
            "Epoch 76/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2431 - root_mean_squared_error: 0.4937 - val_loss: 0.2462 - val_root_mean_squared_error: 0.4971\n",
            "Epoch 77/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2429 - root_mean_squared_error: 0.4930 - val_loss: 0.2465 - val_root_mean_squared_error: 0.4971\n",
            "Epoch 78/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.2421 - root_mean_squared_error: 0.4929 - val_loss: 0.2474 - val_root_mean_squared_error: 0.4984\n",
            "Epoch 79/200\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.2430 - root_mean_squared_error: 0.4936 - val_loss: 0.2486 - val_root_mean_squared_error: 0.4994\n",
            "Epoch 80/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2432 - root_mean_squared_error: 0.4917 - val_loss: 0.2438 - val_root_mean_squared_error: 0.4947\n",
            "Epoch 81/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2433 - root_mean_squared_error: 0.4932 - val_loss: 0.2469 - val_root_mean_squared_error: 0.4982\n",
            "Epoch 82/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2394 - root_mean_squared_error: 0.4907 - val_loss: 0.2468 - val_root_mean_squared_error: 0.4976\n",
            "Epoch 83/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2435 - root_mean_squared_error: 0.4936 - val_loss: 0.2454 - val_root_mean_squared_error: 0.4961\n",
            "Epoch 84/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2397 - root_mean_squared_error: 0.4909 - val_loss: 0.2425 - val_root_mean_squared_error: 0.4929\n",
            "Epoch 85/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2408 - root_mean_squared_error: 0.4907 - val_loss: 0.2435 - val_root_mean_squared_error: 0.4945\n",
            "Epoch 86/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2407 - root_mean_squared_error: 0.4910 - val_loss: 0.2501 - val_root_mean_squared_error: 0.5014\n",
            "Epoch 87/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2416 - root_mean_squared_error: 0.4905 - val_loss: 0.2440 - val_root_mean_squared_error: 0.4947\n",
            "Epoch 88/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2415 - root_mean_squared_error: 0.4902 - val_loss: 0.2431 - val_root_mean_squared_error: 0.4938\n",
            "Epoch 89/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2401 - root_mean_squared_error: 0.4896 - val_loss: 0.2447 - val_root_mean_squared_error: 0.4957\n",
            "Epoch 90/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2415 - root_mean_squared_error: 0.4898 - val_loss: 0.2452 - val_root_mean_squared_error: 0.4962\n",
            "Epoch 91/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2406 - root_mean_squared_error: 0.4895 - val_loss: 0.2443 - val_root_mean_squared_error: 0.4948\n",
            "Epoch 92/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2450 - root_mean_squared_error: 0.4936 - val_loss: 0.2558 - val_root_mean_squared_error: 0.5068\n",
            "Epoch 93/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2401 - root_mean_squared_error: 0.4907 - val_loss: 0.2432 - val_root_mean_squared_error: 0.4944\n",
            "Epoch 94/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2381 - root_mean_squared_error: 0.4884 - val_loss: 0.2453 - val_root_mean_squared_error: 0.4961\n",
            "Epoch 95/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2399 - root_mean_squared_error: 0.4889 - val_loss: 0.2497 - val_root_mean_squared_error: 0.5010\n",
            "Epoch 96/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2413 - root_mean_squared_error: 0.4911 - val_loss: 0.2423 - val_root_mean_squared_error: 0.4929\n",
            "Epoch 97/200\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.2384 - root_mean_squared_error: 0.4876 - val_loss: 0.2488 - val_root_mean_squared_error: 0.4994\n",
            "Epoch 98/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2396 - root_mean_squared_error: 0.4884 - val_loss: 0.2421 - val_root_mean_squared_error: 0.4929\n",
            "Epoch 99/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2364 - root_mean_squared_error: 0.4876 - val_loss: 0.2532 - val_root_mean_squared_error: 0.5041\n",
            "Epoch 100/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2365 - root_mean_squared_error: 0.4884 - val_loss: 0.2478 - val_root_mean_squared_error: 0.4983\n",
            "Epoch 101/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2377 - root_mean_squared_error: 0.4877 - val_loss: 0.2415 - val_root_mean_squared_error: 0.4924\n",
            "Epoch 102/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2370 - root_mean_squared_error: 0.4870 - val_loss: 0.2442 - val_root_mean_squared_error: 0.4948\n",
            "Epoch 103/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2400 - root_mean_squared_error: 0.4911 - val_loss: 0.2388 - val_root_mean_squared_error: 0.4894\n",
            "Epoch 104/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2387 - root_mean_squared_error: 0.4893 - val_loss: 0.2489 - val_root_mean_squared_error: 0.4996\n",
            "Epoch 105/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2405 - root_mean_squared_error: 0.4895 - val_loss: 0.2412 - val_root_mean_squared_error: 0.4917\n",
            "Epoch 106/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2352 - root_mean_squared_error: 0.4873 - val_loss: 0.2409 - val_root_mean_squared_error: 0.4916\n",
            "Epoch 107/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2375 - root_mean_squared_error: 0.4868 - val_loss: 0.2398 - val_root_mean_squared_error: 0.4901\n",
            "Epoch 108/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2375 - root_mean_squared_error: 0.4877 - val_loss: 0.2486 - val_root_mean_squared_error: 0.4990\n",
            "Epoch 109/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2379 - root_mean_squared_error: 0.4878 - val_loss: 0.2394 - val_root_mean_squared_error: 0.4899\n",
            "Epoch 110/200\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.2368 - root_mean_squared_error: 0.4871 - val_loss: 0.2439 - val_root_mean_squared_error: 0.4949\n",
            "Epoch 111/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2375 - root_mean_squared_error: 0.4861 - val_loss: 0.2412 - val_root_mean_squared_error: 0.4914\n",
            "Epoch 112/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2374 - root_mean_squared_error: 0.4871 - val_loss: 0.2434 - val_root_mean_squared_error: 0.4940\n",
            "Epoch 113/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2373 - root_mean_squared_error: 0.4871 - val_loss: 0.2427 - val_root_mean_squared_error: 0.4932\n",
            "Epoch 114/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2347 - root_mean_squared_error: 0.4865 - val_loss: 0.2391 - val_root_mean_squared_error: 0.4896\n",
            "Epoch 115/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2365 - root_mean_squared_error: 0.4877 - val_loss: 0.2434 - val_root_mean_squared_error: 0.4943\n",
            "Epoch 116/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2381 - root_mean_squared_error: 0.4872 - val_loss: 0.2396 - val_root_mean_squared_error: 0.4899\n",
            "Epoch 117/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2347 - root_mean_squared_error: 0.4860 - val_loss: 0.2541 - val_root_mean_squared_error: 0.5049\n",
            "Epoch 118/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2372 - root_mean_squared_error: 0.4876 - val_loss: 0.2396 - val_root_mean_squared_error: 0.4899\n",
            "Epoch 119/200\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.2364 - root_mean_squared_error: 0.4868 - val_loss: 0.2559 - val_root_mean_squared_error: 0.5066\n",
            "Epoch 120/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2377 - root_mean_squared_error: 0.4855 - val_loss: 0.2416 - val_root_mean_squared_error: 0.4917\n",
            "Epoch 121/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2370 - root_mean_squared_error: 0.4855 - val_loss: 0.2481 - val_root_mean_squared_error: 0.4986\n",
            "Epoch 122/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2378 - root_mean_squared_error: 0.4881 - val_loss: 0.2382 - val_root_mean_squared_error: 0.4884\n",
            "Epoch 123/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2374 - root_mean_squared_error: 0.4890 - val_loss: 0.2420 - val_root_mean_squared_error: 0.4923\n",
            "Epoch 124/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2374 - root_mean_squared_error: 0.4867 - val_loss: 0.2466 - val_root_mean_squared_error: 0.4970\n",
            "Epoch 125/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2352 - root_mean_squared_error: 0.4857 - val_loss: 0.2417 - val_root_mean_squared_error: 0.4915\n",
            "Epoch 126/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2348 - root_mean_squared_error: 0.4862 - val_loss: 0.2497 - val_root_mean_squared_error: 0.5000\n",
            "Epoch 127/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2351 - root_mean_squared_error: 0.4844 - val_loss: 0.2396 - val_root_mean_squared_error: 0.4896\n",
            "Epoch 128/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2346 - root_mean_squared_error: 0.4832 - val_loss: 0.2390 - val_root_mean_squared_error: 0.4892\n",
            "Epoch 129/200\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.2337 - root_mean_squared_error: 0.4838 - val_loss: 0.2500 - val_root_mean_squared_error: 0.5002\n",
            "Epoch 130/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2345 - root_mean_squared_error: 0.4847 - val_loss: 0.2415 - val_root_mean_squared_error: 0.4916\n",
            "Epoch 131/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2333 - root_mean_squared_error: 0.4835 - val_loss: 0.2400 - val_root_mean_squared_error: 0.4903\n",
            "Epoch 132/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2360 - root_mean_squared_error: 0.4865 - val_loss: 0.2427 - val_root_mean_squared_error: 0.4925\n",
            "Epoch 133/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2350 - root_mean_squared_error: 0.4853 - val_loss: 0.2431 - val_root_mean_squared_error: 0.4932\n",
            "Epoch 134/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2367 - root_mean_squared_error: 0.4846 - val_loss: 0.2433 - val_root_mean_squared_error: 0.4938\n",
            "Epoch 135/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2336 - root_mean_squared_error: 0.4843 - val_loss: 0.2376 - val_root_mean_squared_error: 0.4876\n",
            "Epoch 136/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2351 - root_mean_squared_error: 0.4842 - val_loss: 0.2414 - val_root_mean_squared_error: 0.4915\n",
            "Epoch 137/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2357 - root_mean_squared_error: 0.4849 - val_loss: 0.2451 - val_root_mean_squared_error: 0.4954\n",
            "Epoch 138/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2331 - root_mean_squared_error: 0.4831 - val_loss: 0.2414 - val_root_mean_squared_error: 0.4917\n",
            "Epoch 139/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2363 - root_mean_squared_error: 0.4850 - val_loss: 0.2414 - val_root_mean_squared_error: 0.4917\n",
            "Epoch 140/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2340 - root_mean_squared_error: 0.4842 - val_loss: 0.2447 - val_root_mean_squared_error: 0.4953\n",
            "Epoch 141/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2353 - root_mean_squared_error: 0.4861 - val_loss: 0.2430 - val_root_mean_squared_error: 0.4931\n",
            "Epoch 142/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2353 - root_mean_squared_error: 0.4828 - val_loss: 0.2472 - val_root_mean_squared_error: 0.4974\n",
            "Epoch 143/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2378 - root_mean_squared_error: 0.4843 - val_loss: 0.2427 - val_root_mean_squared_error: 0.4929\n",
            "Epoch 144/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2363 - root_mean_squared_error: 0.4861 - val_loss: 0.2474 - val_root_mean_squared_error: 0.4979\n",
            "Epoch 145/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2346 - root_mean_squared_error: 0.4857 - val_loss: 0.2423 - val_root_mean_squared_error: 0.4924\n",
            "Epoch 146/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2339 - root_mean_squared_error: 0.4838 - val_loss: 0.2444 - val_root_mean_squared_error: 0.4943\n",
            "Epoch 147/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2315 - root_mean_squared_error: 0.4819 - val_loss: 0.2418 - val_root_mean_squared_error: 0.4921\n",
            "Epoch 148/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2349 - root_mean_squared_error: 0.4840 - val_loss: 0.2417 - val_root_mean_squared_error: 0.4917\n",
            "Epoch 149/200\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.2333 - root_mean_squared_error: 0.4822 - val_loss: 0.2395 - val_root_mean_squared_error: 0.4901\n",
            "Epoch 150/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2353 - root_mean_squared_error: 0.4840 - val_loss: 0.2485 - val_root_mean_squared_error: 0.4988\n",
            "Epoch 151/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.2371 - root_mean_squared_error: 0.4869 - val_loss: 0.2373 - val_root_mean_squared_error: 0.4879\n",
            "Epoch 152/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2340 - root_mean_squared_error: 0.4854 - val_loss: 0.2492 - val_root_mean_squared_error: 0.4991\n",
            "Epoch 153/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2343 - root_mean_squared_error: 0.4847 - val_loss: 0.2439 - val_root_mean_squared_error: 0.4941\n",
            "Epoch 154/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2293 - root_mean_squared_error: 0.4799 - val_loss: 0.2421 - val_root_mean_squared_error: 0.4924\n",
            "Epoch 155/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.2301 - root_mean_squared_error: 0.4793 - val_loss: 0.2458 - val_root_mean_squared_error: 0.4961\n",
            "Epoch 156/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2313 - root_mean_squared_error: 0.4820 - val_loss: 0.2465 - val_root_mean_squared_error: 0.4965\n",
            "Epoch 157/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2314 - root_mean_squared_error: 0.4808 - val_loss: 0.2476 - val_root_mean_squared_error: 0.4980\n",
            "Epoch 158/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2334 - root_mean_squared_error: 0.4810 - val_loss: 0.2447 - val_root_mean_squared_error: 0.4946\n",
            "Epoch 159/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2314 - root_mean_squared_error: 0.4809 - val_loss: 0.2463 - val_root_mean_squared_error: 0.4964\n",
            "Epoch 160/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2308 - root_mean_squared_error: 0.4799 - val_loss: 0.2393 - val_root_mean_squared_error: 0.4894\n",
            "Epoch 161/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2279 - root_mean_squared_error: 0.4803 - val_loss: 0.2457 - val_root_mean_squared_error: 0.4959\n",
            "Epoch 162/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2302 - root_mean_squared_error: 0.4815 - val_loss: 0.2518 - val_root_mean_squared_error: 0.5024\n",
            "Epoch 163/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2321 - root_mean_squared_error: 0.4826 - val_loss: 0.2391 - val_root_mean_squared_error: 0.4893\n",
            "Epoch 164/200\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.2406 - root_mean_squared_error: 0.4876 - val_loss: 0.2455 - val_root_mean_squared_error: 0.4959\n",
            "Epoch 165/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.2320 - root_mean_squared_error: 0.4808 - val_loss: 0.2429 - val_root_mean_squared_error: 0.4931\n",
            "Epoch 166/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2305 - root_mean_squared_error: 0.4804 - val_loss: 0.2353 - val_root_mean_squared_error: 0.4857\n",
            "Epoch 167/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2326 - root_mean_squared_error: 0.4822 - val_loss: 0.2432 - val_root_mean_squared_error: 0.4938\n",
            "Epoch 168/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2296 - root_mean_squared_error: 0.4799 - val_loss: 0.2395 - val_root_mean_squared_error: 0.4896\n",
            "Epoch 169/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2350 - root_mean_squared_error: 0.4837 - val_loss: 0.2485 - val_root_mean_squared_error: 0.4990\n",
            "Epoch 170/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.2317 - root_mean_squared_error: 0.4825 - val_loss: 0.2447 - val_root_mean_squared_error: 0.4947\n",
            "Epoch 171/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2309 - root_mean_squared_error: 0.4804 - val_loss: 0.2428 - val_root_mean_squared_error: 0.4927\n",
            "Epoch 172/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2319 - root_mean_squared_error: 0.4813 - val_loss: 0.2351 - val_root_mean_squared_error: 0.4851\n",
            "Epoch 173/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2301 - root_mean_squared_error: 0.4802 - val_loss: 0.2415 - val_root_mean_squared_error: 0.4920\n",
            "Epoch 174/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2302 - root_mean_squared_error: 0.4799 - val_loss: 0.2411 - val_root_mean_squared_error: 0.4915\n",
            "Epoch 175/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2310 - root_mean_squared_error: 0.4823 - val_loss: 0.2533 - val_root_mean_squared_error: 0.5034\n",
            "Epoch 176/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2301 - root_mean_squared_error: 0.4796 - val_loss: 0.2374 - val_root_mean_squared_error: 0.4874\n",
            "Epoch 177/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2314 - root_mean_squared_error: 0.4815 - val_loss: 0.2476 - val_root_mean_squared_error: 0.4978\n",
            "Epoch 178/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2321 - root_mean_squared_error: 0.4820 - val_loss: 0.2372 - val_root_mean_squared_error: 0.4872\n",
            "Epoch 179/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2303 - root_mean_squared_error: 0.4826 - val_loss: 0.2370 - val_root_mean_squared_error: 0.4874\n",
            "Epoch 180/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2316 - root_mean_squared_error: 0.4808 - val_loss: 0.2536 - val_root_mean_squared_error: 0.5040\n",
            "Epoch 181/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2316 - root_mean_squared_error: 0.4825 - val_loss: 0.2407 - val_root_mean_squared_error: 0.4910\n",
            "Epoch 182/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2287 - root_mean_squared_error: 0.4790 - val_loss: 0.2380 - val_root_mean_squared_error: 0.4884\n",
            "Epoch 183/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2327 - root_mean_squared_error: 0.4822 - val_loss: 0.2449 - val_root_mean_squared_error: 0.4953\n",
            "Epoch 184/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.2332 - root_mean_squared_error: 0.4827 - val_loss: 0.2397 - val_root_mean_squared_error: 0.4902\n",
            "Epoch 185/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2290 - root_mean_squared_error: 0.4786 - val_loss: 0.2504 - val_root_mean_squared_error: 0.5007\n",
            "Epoch 186/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2322 - root_mean_squared_error: 0.4801 - val_loss: 0.2448 - val_root_mean_squared_error: 0.4950\n",
            "Epoch 187/200\n",
            "11/11 [==============================] - 0s 16ms/step - loss: 0.2287 - root_mean_squared_error: 0.4781 - val_loss: 0.2469 - val_root_mean_squared_error: 0.4969\n",
            "Epoch 188/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2334 - root_mean_squared_error: 0.4814 - val_loss: 0.2440 - val_root_mean_squared_error: 0.4944\n",
            "Epoch 189/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2314 - root_mean_squared_error: 0.4805 - val_loss: 0.2387 - val_root_mean_squared_error: 0.4889\n",
            "Epoch 190/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2295 - root_mean_squared_error: 0.4790 - val_loss: 0.2410 - val_root_mean_squared_error: 0.4909\n",
            "Epoch 191/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2296 - root_mean_squared_error: 0.4789 - val_loss: 0.2499 - val_root_mean_squared_error: 0.5004\n",
            "Epoch 192/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2321 - root_mean_squared_error: 0.4826 - val_loss: 0.2614 - val_root_mean_squared_error: 0.5114\n",
            "Epoch 193/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2310 - root_mean_squared_error: 0.4805 - val_loss: 0.2480 - val_root_mean_squared_error: 0.4982\n",
            "Epoch 194/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2310 - root_mean_squared_error: 0.4793 - val_loss: 0.2390 - val_root_mean_squared_error: 0.4889\n",
            "Epoch 195/200\n",
            "11/11 [==============================] - 0s 15ms/step - loss: 0.2283 - root_mean_squared_error: 0.4783 - val_loss: 0.2416 - val_root_mean_squared_error: 0.4917\n",
            "Epoch 196/200\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.2314 - root_mean_squared_error: 0.4812 - val_loss: 0.2416 - val_root_mean_squared_error: 0.4920\n",
            "Epoch 197/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2275 - root_mean_squared_error: 0.4781 - val_loss: 0.2476 - val_root_mean_squared_error: 0.4979\n",
            "Epoch 198/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2274 - root_mean_squared_error: 0.4789 - val_loss: 0.2483 - val_root_mean_squared_error: 0.4988\n",
            "Epoch 199/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2273 - root_mean_squared_error: 0.4794 - val_loss: 0.2602 - val_root_mean_squared_error: 0.5099\n",
            "Epoch 200/200\n",
            "11/11 [==============================] - 0s 14ms/step - loss: 0.2343 - root_mean_squared_error: 0.4808 - val_loss: 0.2385 - val_root_mean_squared_error: 0.4889\n",
            "0.1359846293926239\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEJCAYAAACOr7BbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npZRT/w+g2mbuB025BAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluate the linear regression model against the test set:\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2316 - root_mean_squared_error: 0.4755\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2316265106201172, 0.4754888713359833]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    }
  ]
}